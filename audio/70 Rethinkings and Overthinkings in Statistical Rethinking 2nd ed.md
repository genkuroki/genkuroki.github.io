この度は、マクエルリース著「統計的再考 第2版：RとStanの例によるベイズ統計学コース」について、その内容、特に「Rethinking（再考）」と「Overthinking（深掘り）」と題されたコラムの包括的な要約をご提供いたします。この書籍は、従来の統計的推論に対する批判的な視点を提供し、**ベイズ統計学**を主要なツールとして、より堅牢で解釈しやすいモデルの構築方法を教えることを目的としています。

マクエルリースは、統計モデルを、ラビ・ユダヤのゴーレムに例えています。これらの「統計的ゴーレム」は、私たちに代わって計算を行い、明らかなパターンを発見する強力な補綴（ほてつ）具ですが、それ自体に知恵はなく、文脈の不適切さを識別できません。著者は、統計学を数学や科学というよりも、一種の工学と捉えるべきだと主張しています。

この書籍の中心的メッセージの一つは、**「すべてのモデルは間違っているが、役に立つものもある」**という格言に集約されます。これは、モデルが現実世界を完璧に描写することは決してないが、それでも有用な推論や予測を生成できることを意味します。

それでは、章ごとに内容を整理し、特に「Rethinking」と「Overthinking」のコラムについて詳しく説明していきます。

---

### 第1章：プラハのゴーレム

第1章では、統計モデルを「統計的ゴーレム」と表現し、その力強さと危険性の両面を論じています。多くの科学分野では、関心のある現象を測定するためにモデルを使用することが不可欠であり、モデルは私たちに代わって印象的な計算を実行し、隠れたパターンを見つけ出します。しかし、ゴーレムには知恵がなく、文脈の不適切さを判断できません。従来の入門統計学のコースが混乱を招きやすいのは、単一のモデル構築方法ではなく、目的別に事前に構築された「検定法」と呼ばれている事前に作られたゴーレム達の動物園を提供するためだと指摘しています。著者は、従来の統計ツールが柔軟性に欠け、現実の研究状況に適用すると予測不可能な形で失敗する可能性があると批判しています。

また、この章では、統計的推論における誤解、特に**帰無仮説有意性検定（NHST）**が批判されています。著者は、問題はp値そのものにあるというよりも、その周囲に進化してきた奇妙な儀式と、他の有用なツールの排除にあると述べています。科学は仮説を反証することで進歩するというカール・ポパーの考え方が多くの科学者に影響を与えていますが、著者はこれを「民俗ポパー主義」と呼び、厳密な反証はほとんどの科学的文脈で不可能だと主張します。

統計的推論を改善するためには、統一された「ゴーレム工学」の理論、つまり特殊な統計的プロシージャを設計、構築、改良するための原則が必要だと提唱し、そのためのツールとして**ベイズデータ分析**、**モデル比較**、**多階層モデル**、**グラフィカル因果モデル**の4つを導入しています。

#### Rethinking: Is NHST falsificationist?（NHSTは反証主義的か？）
帰無仮説有意性検定（NHST）は、しばしば反証主義的、またはポパー主義的な科学哲学と同一視されます。しかし、通常NHSTは、実際の研究仮説ではなく、**帰無仮説を反証するために使用されます**。このため、反証は説明モデルそのものに対して行われているわけではなく、カール・ポパーの哲学とは逆のように見えます。

#### Rethinking: Entropy and model identification.（エントロピーとモデルの同定）
統計モデルが多くの異なる詳細なプロセスモデルに対応することが多い理由の一つは、それらが**正規分布、二項分布、ポアソン分布**などの分布に依存しているからです。これらの分布は**指数型分布族**のメンバーです。自然はエントロピーを好むため、これらはすべて**最大エントロピー分布**です。この説明から自然界の人格化を除外することは、第10章まで待つことになります。実際的な意味合いとしては、**身長が正規分布しているという事実から発達プロセスを推測できないのと同様に、べき乗則から進化プロセスを推測することはできません**。この事実は、本書の主要部分である典型的な回帰モデルが、メカニズム的プロセスについて私たちに教えられることについて、謙虚であるべきだということを示しています。一方で、これらの分布の最大エントロピーの性質は、基盤となるプロセスを特定できない場合でも、有用な統計的作業を行うためにこれらを使用できることを意味します。特定できないだけでなく、そうする必要もありません。

#### Rethinking: Probability is not unitary.（確率は単一ではない）
「確率」を定義する方法が複数あるという提案は、一部の読者に不快感を与えるかもしれません。数学的概念は唯一無二に正しいのではないか、と。そうではありません。ある一連の前提、つまり公理を採用すれば、数学システムではすべてが論理的に導き出されます。しかし、**公理自体は議論や解釈の対象となります**。したがって、「ベイズ的」と「頻度主義的」な確率があるだけでなく、異なる議論に基づいてベイズ的確率の異なるバージョンさえ存在します。より高度なベイズ統計の教科書では、ブルーノ・デ・フィネッティ、リチャード・T・コックス、レナード・“ジミー”・サベージといった名前が出てくるでしょう。これらの人物はそれぞれ、ベイズ確率の概念をわずかに異なって捉えています。他にもあります。本書は主に、コックスの「論理的」（またはラプラス＝ジェフリー＝コックス＝ジェインズ）解釈に従います。この解釈は次章から提示されますが、第10章で完全に展開されます。

#### Rethinking: A central role for likelihood.（尤度の中心的役割）
ベイズデータ分析と非ベイズデータ分析がどのように異なるかに焦点を当てて多くのインクが費やされてきました。違いに焦点を当てることは有用ですが、時には根本的な類似点から目をそらさせてしまいます。特に、ベイズモデルと多くの非ベイズモデルの両方において最も影響力のある仮定は、**データに割り当てられた分布、すなわち尤度関数です**。尤度はデータのすべての部分に推論を及ぼし、サンプルサイズが増加するにつれて尤度はますます重要になります。このことが、ベイズ推論と非ベイズ推論がしばしば非常に類似している理由を説明するのに役立ちます。**「ベイズ」をその一側面だけで定義するとすれば、事前分布ではなく、尤度について記述すべきでしょう**。

#### Rethinking: A little history.（少し歴史の話）
**ベイズ統計的推論は、入門統計学の典型的なツール（そのほとんどは20世紀初頭に開発されたもの）よりもはるかに古いものです**。ベイズ的アプローチのバージョンは、1700年代後半に科学研究に適用され、19世紀にも繰り返し用いられました。しかし、第一次世界大戦後、ロナルド・フィッシャーのような反ベイズ主義の統計学者が、このアプローチを周縁化することに成功しました。フィッシャーは、彼の影響力のある1925年のハンドブックでベイズ分析（当時は逆確率と呼ばれていました）について次のように述べているだけでした。

「…逆確率の理論は誤謬に基づいており、完全に拒否されなければならない。」

ベイズデータ分析は、それが誤謬に基づいているわけではないことが証明されたため、20世紀後半に統計学の中で受け入れられるようになりました。哲学はさておき、それはうまくいったのです。1990年代に入ると、新しい計算アプローチによりベイズ法の適用が急速に増加しました。しかし、ベイズ法は依然として計算コストが高いため、ゲノム解析で数百万行が一般的になったように、データセットが大規模化するにつれて、ベイズ推論の代替または近似が重要であり続け、おそらく常にそうでしょう。

---

### 第2章：小さな世界と大きな世界

第2章では、モデルという「小さな世界」と現実という「大きな世界」の概念を導入します。ベイズ推論は、ボルヘスの有名な小説**「分岐する小道の庭」**に由来する**「分岐するデータの庭」**という比喩を用いて説明されます。これは、実際に起こったことについて推論するために、起こり得たすべての可能性を考慮するという考え方です。データが収集されるにつれて、これらの可能性のいくつかは「剪定」され、最終的には論理的に矛盾しないものだけが残ります。

この章では、地球上の水の割合を推測する球体投げの例を通して、ベイズモデルの構築と評価の基本が示されます。モデルは、データストーリー（データがどのように生成されたかについての仮説）から形式的な確率モデルへと変換されます。ベイズ推論は、どのようなサンプルサイズであっても有効であり、その推論は明確で有効な解釈を持ちますが、その代償として**事前分布**への依存が生じます。

モデルの評価においては、モデルの確実性がモデルの良さを保証するものではないこと、モデルの仮定が完全に正しいわけではないこと、そしてモデルの目的への適切性を確認することが重要だと強調されます。

#### Rethinking: Fast and frugal in the large world.（大きな世界における速くて倹約的）
自然界は複雑であり、科学を行おうとすることがそれを思い出させます。しかし、謙虚なダニから勤勉なリス、怠惰なナマケモノまで、あらゆるものが頻繁に適応的な意思決定をしています。しかし、ほとんどの動物はベイズ的ではないと考えるのが妥当でしょう。なぜなら、ベイズ的であることはコストがかかり、良いモデルを持つことに依存するからです。代わりに、動物は環境（過去または現在）に適した様々なヒューリスティクスを使用します。これらのヒューリスティクスは適応的な近道を取り、情報収集と処理のコスト（および過剰適合、第6章）を考慮に入れると、厳密なベイズ分析よりも優れたパフォーマンスを発揮することがあります。**一度無視すべき情報や注意すべき情報が分かってしまえば、完全にベイズ的であることは無駄です**。実際の動物が示すように、それは良い意思決定をするために必要でも十分でもありません。しかし、人間にとっては、ベイズ分析は関連情報を発見し、論理的に処理するための一般的な方法を提供します。それが唯一の方法だとは考えないでください。

#### Rethinking: The value of storytelling.（ストーリーテリングの価値）
データストーリーは、たとえそれをすぐに放棄してモデル構築や新しい観測のシミュレーションに使用しなくても価値があります。実際、最終的にはストーリーを破棄することが重要です。なぜなら、多くの異なるストーリーが常に同じモデルに対応するからです。その結果、モデルがうまく機能することを示しても、それは私たちのデータストーリーを独自に裏付けるものではありません。それでも、ストーリーには価値があります。なぜなら、ストーリーを概説しようとすると、追加の質問に答える必要があることに気づくことがよくあるからです。ほとんどのデータストーリーは、データ収集を促す口頭仮説よりもはるかに具体的です。仮説は、「暖かい日には雨が降りやすい」といった漠然としたものであることがあります。サンプリングと測定を考慮し、気温が雨をどのように予測するかを正確に述べようとすると、多くのストーリーと結果として生じるモデルが同じ漠然とした仮説と矛盾しなくなります。その曖昧さを解消することは、モデルをデータに適合させる前に、重要な気づきやモデルの修正につながることがよくあります。

#### Rethinking: Sample size and reliable inference.（サンプルサイズと信頼できる推論）
有用な統計的推定には最低限の観測数が必要だという話をよく耳にします。例えば、ガウス分布を使用する前に30の観測が必要だという広く信じられている迷信があります。なぜでしょうか？**非ベイズ統計的推論では、プロシージャはしばしば、非常に大きなサンプルサイズ（いわゆる漸近的振る舞い）での方法の振る舞いによって正当化されるため、小さなサンプルサイズでのパフォーマンスは疑問視されます**。対照的に、**ベイズ推定は任意のサンプルサイズで有効です**。これは、より多くのデータが役に立たないという意味ではありません—それは確かにそうです。むしろ、推定はサンプルサイズに関係なく、明確で有効な解釈を持ちます。しかし、この力の代償は、初期の妥当性、つまり**事前分布**への依存です。事前分布が悪ければ、結果として得られる推論は誤解を招くでしょう。世界について学ぶことに関しては、**「無料のランチはない」**のです。ベイズのゴーレムは初期の妥当性を選択しなければならず、非ベイズのゴーレムは推定量を選択しなければなりません。どちらのゴーレムも、その仮定によってランチの代金を払うのです。

#### Rethinking: Justification.（正当化）
庭を通るパスの数を相対的妥当性の尺度として使用することは、いくつかの方法で正当化できます。ここでの正当化は論理的です。もし私たちが妥当性について推論し、通常の論理（真偽についての記述）と一貫性を保ちたいのであれば、この手順に従うべきです。同じ数学的手順につながる他のいくつかの正当化もあります。哲学的にどのように正当化するかに関わらず、それが実際に機能することに注目してください。正当化と哲学は手順を動機付けますが、重要なのは結果です。ベイズ推論の多くの成功した現実世界への応用は、あなたが必要とする唯一の正当化かもしれません。20世紀のベイズデータ分析の反対者は、ベイズ推論は正当化しやすいが、適用が難しいと主張しました。それは幸いにももはや真実ではありません。実際、逆のことがしばしば当てはまります—科学者たちは、自分が望むモデルを使用できるため、ベイズアプローチに切り替えています。ただし、ベイズ推論が正当化されるからといって、他のアプローチも正当化されないと仮定しないように注意してください。ゴーレムには多くの種類があり、すべての種類のゴーレムの一部は有用です。

#### Rethinking: Original ignorance.（根源的な無知）
推測について事前の情報がない場合、どのような仮定を使用すべきでしょうか？最も一般的な解決策は、データを見る前に各推測が同じ数の方法で正しいとすることです。これは**「無差別の原則」**として知られることもあります。ある推測が別の推測よりも妥当であると主張する理由がない場合、すべての推測を平等に扱う、というものです。**この本では「無知の事前分布」を使用したり推奨したりしません**。後の章で見るように、モデルの構造と科学的文脈は常に、無知よりも優れた方法を可能にする情報を提供します。

#### Rethinking: Prior, prior pants on fire.（事前分布、事前分布、嘘つき）
歴史的に、ベイズ推論の一部の反対者は、事前分布の恣意性を批判しました。事前分布は非常に柔軟であり、多くの異なる情報の状態を符号化できるのは事実です。事前分布が何でもありなら、望む答えを何でも得ることができるのではないでしょうか？確かにそうです。しかし、数百年間のベイズ計算の後、人々が嘘をつくために事前分布を使用することは判明していません。もし統計で嘘をつくことが目標なら、事前分布を使うのは愚かでしょう。なぜなら、そのような嘘は簡単に見破られるからです。より不透明な尤度の仕組みを使う方がましです。あるいはもっと良い方法としては、このアドバイスは実際には無視してください！—データを調整したり、「外れ値」を削除したり、その他動機付けられたデータ変換を行ったりすることです。

#### Rethinking: Bayesian data analysis isn’t about Bayes’ theorem.（ベイズデータ分析はベイズの定理に関するものではない）
ベイズデータ分析、ひいてはベイズ推論全般についてよくある誤解は、それがベイズの定理の使用によって区別されるというものです。これは間違いです。**どのような確率の概念の下での推論であっても、最終的にはベイズの定理を使用します**。HIVやDNA検査に関する一般的な入門的な「ベイズ」分析の例は、ベイズに固有のものではありません。計算のすべての要素が観測の頻度であるため、非ベイズ分析でもまったく同じことをするでしょう。むしろ、ベイズのアプローチは、パラメータやモデルのように、観測できない理論的な実体に関する不確実性を定量化するために、ベイズの定理をより一般的に使用できるのです。ベイズ確率の概念と非ベイズ確率の概念の両方において、強力な推論を生み出すことができますが、異なる正当化と犠牲が必要です。

#### Rethinking: How you fit the model is part of the model.（モデルの適合方法もモデルの一部である）
この章の冒頭で、私はモデルを事前分布と尤度の複合体として暗黙的に定義しました。この定義は典型的です。しかし、実用的な観点からは、**データをモデルに適合させる方法もモデルの一部と見なすべきです**。この章で扱っている球体投げの例のような非常に単純な問題では、事後分布の計算は些細で失敗することはありません。しかし、中程度に複雑な問題でさえ、データをモデルに適合させる詳細なプロセスは、私たちの数値的手法が推論に影響を与えることを認識させます。これは、異なる手法で異なる種類の誤りや妥協が生じるためです。同じモデルを同じデータに異なる手法で適合させると、異なる答えが得られることがあります。何か問題が発生した場合、機械のすべての部分が疑われる可能性があります。したがって、私たちのゴーレムは、私たちがプログラムする事前分布と尤度に従属するのと同じくらい、その更新エンジンにも従属しているのです。

#### Rethinking: Maximum likelihood estimation.（最尤推定）
**一様事前分布**、または大量のデータを用いた**二次近似**は、しばしば最尤推定（MLE）とその標準誤差に相当します。最尤推定は、非常に一般的な非ベイズパラメータ推定です。ベイズ近似と一般的な非ベイズ推定量のこの対応関係は、祝福でもあり、呪いでもあります。それは祝福です。なぜなら、幅広い範囲の公開された非ベイズモデル適合をベイズ的な観点から再解釈できるからです。それは呪いです。なぜなら、最尤推定にはいくつかの奇妙な欠点があり、二次近似もそれらを共有する可能性があるからです。これらについては後の章で詳しく説明します。

---

### 第3章：想像上のサンプリング

第3章では、**事後分布**からサンプルを生成し、それらを用いて推論を要約し、予測をシミュレーションするための基本的な手法を学びます。ベイズ統計学では、推論の対象は事後確率分布であり、これはデータに対する考えられる各原因の相対的な妥当性を示します。

この章では、**相性区間**（compatibility interval）という概念が導入されます。これは、特定の確率質量を含むパラメータ値の範囲を示し、**「信用区間（credible interval）」**という用語を避け、**「信頼区間（confidence interval）」**とは異なるものとして区別されます。特に、**最高事後密度区間（HPDI）**が、特定の確率質量を含む最も狭い区間として紹介され、パーセンタイル区間（PI）と比較されます。

また、モデルの出力をシミュレーションするためにサンプルを使用する**事後予測チェック**の重要性も強調されます。これにより、ソフトウェアが正しく機能しているかを確認し、モデルがデータをどの程度うまく記述しているかを評価することができます。

#### Rethinking: Why statistics can’t save bad science.（なぜ統計学は悪い科学を救えないのか）
この章の冒頭の吸血鬼の例は、多くの信号検出問題と同じ論理構造を持っています。(1) 隠された二値の状態が存在する。(2) その隠された状態の不完全な手がかりを観測する。(3) その手がかりが不確実性に与える影響を論理的に推測するために、**ベイズの定理**を使用すべきである。

科学的推論も同様の観点から捉えられることがあります。(1) 仮説は真か偽かである。(2) 統計的手順を使用して、仮説の偽りについての不完全な手がかりを得る。(3) その手がかりが仮説の状態に与える影響を論理的に推測するために、**ベイズの定理**を使用すべきである。

しかし、3番目のステップはほとんど行われることがありません。しかし、おもちゃの例でそれを行ってみましょう。統計的手順（ベイズ的であろうとなかろうと）が私たちにとってどれほどわずかな助けしかしないかを見ることができます。仮説が真である場合に陽性の結果が得られる確率がPr(sig|true) = 0.95だと仮定します。これは検定の**検出力**です。仮説が偽である場合に陽性の結果が得られる確率がPr(sig|false) = 0.05だと仮定します。これは**偽陽性率**であり、従来の有意性検定の5%に相当します。最後に、仮説が真である**ベース率**を述べなければなりません。例えば、100個の仮説のうち1つだけが真であると仮定します。つまりPr(true) = 0.01です。この値を知っている人はいませんが、科学史はそれが小さいことを示唆しています（詳細は第17章を参照）。ここでベイズの定理を使って事後確率を計算します。

Pr(true|pos) = Pr(pos|true)Pr(true) / Pr(pos)
= Pr(pos|true)Pr(true) / (Pr(pos|true)Pr(true) + Pr(pos|false)Pr(false))

適切な値を代入すると、答えはPr(true|pos) ≈ 0.16になります。したがって、陽性の結果は、仮説が真である確率が16%にすぎないことを意味します。これは、医療（および吸血鬼）検査に適用される**低いベース率現象**と同じです。偽陽性率を1%に下げても、この事後確率は0.5までしか上がりません。コイン投げと同じくらいしか良くないのです。**最も重要なことは、ベース率Pr(true)を改善することであり、それには「検定」ではなく「思考」が必要です**。

#### Rethinking: Sampling distributions.（サンプリング分布）
多くの読者はすでにシミュレートされた観測を見たことがあるでしょう。**サンプリング分布は、一般的な非ベイズ統計的伝統の基礎です**。それらのアプローチでは、パラメータに関する推論はサンプリング分布を通して行われます。この本では、パラメータに関する推論はサンプリング分布を通して直接行われることはありません。事後分布はサンプリングされるのではなく、論理的に導き出されます。そして、この章の冒頭のように、事後分布からサンプルを抽出して推論を助けることができます。どちらの場合も、「サンプリング」は物理的な行為ではありません。どちらの場合も、それは単なる数学的な装置であり、**小さな世界**（第2章）の数値を生成するだけです。

#### Rethinking: Why 95%?（なぜ95%？）
自然科学および社会科学で最も一般的な区間質量は**95%区間**です。この区間は5%の確率を外部に残し、パラメータが区間内に存在しない確率が5%であることに対応します（ただし以下を参照）。この慣習的な区間は、統計的有意性の慣習的な閾値である5%またはp < 0.05を反映しています。**95%（5%）という選択を、慣習への嘆願以外で擁護することは容易ではありません**。ロナルド・フィッシャーはこの選択の責任を負わされることがありますが、彼の広く引用された1925年の記述は熱心なものではありませんでした。

「P = .05、つまり20分の1となる（標準偏差の）数値は1.96、あるいはほぼ2である。この点を、逸脱が有意であるか否かを判断する際の限界として採用することは便利である。」

ほとんどの人は「便利さ」を真剣な基準とは考えません。フィッシャーはキャリアの後半で、常に同じ有意性閾値を使用することに積極的に反対しました。では、どうすべきなのでしょうか？コンセンサスはありませんが、**「思考」は常に良いアイデアです**。もしある区間がある値を含まないことを伝えたいのであれば、その値を除外する最も広い区間を使用するかもしれません。多くの場合、**相性区間**が果たす唯一の役割は、分布の形状を伝えることです。その場合、単一の区間よりも、一連の入れ子になった区間の方が有用かもしれません。例えば、なぜ67%、89%、97%の区間を中央値とともに提示しないのでしょうか？これらの値の理由は？理由はありません。それらは素数なので覚えやすいです。しかし、重要なのは、事後分布の形状を示すのに十分な間隔で配置されていることです。そして、これらの値は95%を避けています。なぜなら、従来の95%区間は、多くの読者に無意識の仮説検定を促すからです。

#### Rethinking: What do compatibility intervals mean?（相性区間は何を意味するか？）
95%の「信頼」区間は、真のパラメータ値がその区間内に95%の確率で存在するという意味だとよく耳にします。**厳密な非ベイズ統計的推論においては、そのような記述は決して正しくありません。なぜなら、厳密な非ベイズ推論は、パラメータに関する不確実性を測定するために確率を使用することを禁じているからです**。代わりに、次のように言うべきです。もし私たちが研究と分析を非常に多数回繰り返した場合、計算された区間の95%が真のパラメータ値を含むだろうと。もしこの区別があなたにとって完全に明確でないとしても、あなたは良い仲間です。ほとんどの科学者は信頼区間の定義を困惑させるものだと感じており、その多くは無意識のうちにベイズ的な解釈に滑り込んでしまいます。

しかし、ベイズ的な解釈をするかどうかにかかわらず、**95%区間は95%の確率で真の値を「含む」わけではありません**。科学史は、信頼区間が**慢性的な過信**を示すことを教えてくれます。**「真の値を含む」という記述では、「真」という言葉は何か問題があるというアラートを発するはずです**。95%は小さな世界の数字（第2章の冒頭を参照）であり、モデルの論理的な世界でのみ真です。したがって、現実の、または大きな世界に正確に適用されることはありません。それはゴーレムが信じていることですが、あなたは他の何かを信じる自由があります。いずれにせよ、区間の幅とそれがカバーする値は、貴重なアドバイスを提供することができます。

---

### 第4章：天動説モデル

第4章では、**線形回帰**が「応用統計学の天動説モデル」として紹介されます。これは、**ガウス分布**を仮説の骨格として用いるシンプルな統計モデルであり、その柔軟性と汎用性が強調されます。ガウス分布が「普通」である理由として、**本体論的**（多くの自然現象で近似的に見られる）と**認識論的**（最大エントロピー原理により、特定の情報の下で最も保守的な分布である）な二つの正当化が挙げられます。

線形モデルの戦略は、ガウス分布の平均パラメータ µ を予測変数の線形関数にすることです。これにより、モデルはデータに対する各パラメータ値の組み合わせの事後妥当性をランク付けし、特定の関連性の強さに関する事後分布を提供します。著者は、予測変数を標準化することの重要性や、**対数正規事前分布**の使用が合理的でない関係を排除するのに役立つことを示しています。

また、**線形モデル**が必ずしも直線的な関係を意味するものではなく、**多項式回帰**を用いることで曲線的な関連性を構築できることも説明されています。この章では、統計モデルの解釈において、単なる数値の表だけでなく、事後推論をデータと共にプロットすることの重要性が繰り返し強調されています。

#### Rethinking: Heavy tails.（厚い裾）
ガウス分布は自然界で非常に一般的であり、いくつかの優れた統計的特性も持っています。しかし、デフォルトのデータモデルとして使用することにはいくつかのリスクがあります。分布の極端な端は**「裾（tails）」**として知られています。そして、ガウス分布は非常に**薄い裾**を持っており、そこにはほとんど確率がありません。代わりに、ガウス分布の質量のほとんどは平均の1標準偏差内にあります。多くの自然（および不自然）なプロセスは、はるかに**厚い裾**を持っています。これらのプロセスは、極端な事象を生成する確率がはるかに高いのです。現実的で重要な例は金融時系列です。株式市場の浮沈は短期的にはガウス的に見えるかもしれませんが、中長期的には極端なショックがガウスモデル（およびそれを使用するすべての人）を愚かに見せます。歴史的な時系列も同様に振る舞う可能性があり、例えば戦争の傾向に関する推論は厚い裾の驚きに陥りやすいです。ガウス分布の代替案については、後で検討します。

#### Rethinking: Independent and identically distributed.（独立同分布）
上記の簡潔なモデルは、しばしば**「値hiが独立同分布であると仮定される」**と記述され、iidまたはIIDと略されることがあります。同じモデルが次のように書かれているのを目にすることもあるかもしれません。

hi iid∼ Normal(µ, σ).

「iid」は、各値hiが、他のh値とは独立して、同じパラメータを使用して、同じ確率関数を持つことを示します。少し考えれば、これは物理的な意味ではほとんど真実ではないことがわかります。同じ距離を繰り返し測定する場合でも、身長の集団を研究する場合でも、すべての測定値が互いに独立していると主張することは困難です。例えば、家族内の身長は、最近の共通の祖先を通じて共有された対立遺伝子のために相関しています。

しかし、「iid」の仮定は、**確率がゴーレムの中にあり、世界の外にはないことを覚えていれば、不自然に感じる必要はありません**。iidの仮定は、**ゴーレムが不確実性をどのように表現するか**についてのものです。それは**認識論的仮定**です。あなたがそう主張しない限り、それは世界に関する物理的仮定、つまり**存在論的仮定**ではありません。E. T. Jaynes（1922-1998）は、これを**「心の投射の誤謬」**と呼びました。認識論的主張と存在論的主張を混同する過ちです。

重要なのは、認識論が現実を凌駕すると言うことではなく、むしろそのような相関を無視する場合、最も保守的な分布はiidであるということです。この問題は第10章で再び取り上げられます。さらに、分布全体の形状にほとんど影響を与えないが、値が出現する正確な順序にのみ影響を与える多くの種類の相関があります。例えば、姉妹の身長は非常に強く相関しています。しかし、女性の身長の全体的な分布はほぼ完全に正規分布のままです。そのような場合、iidは、相関を無視しているにもかかわらず、完全に有用なままです。例えば、マルコフ連鎖モンテカルロ（第9章）が、非常に強く相関した逐次サンプルを使用して、私たちが好きな任意のiid分布を推定できることを考えてみてください。

#### Rethinking: What’s the correct prior?（正しい事前分布とは？）
人々は、与えられた分析に対して**「正しい事前分布」**とは何かをよく尋ねます。この質問は、しばしば、任意のデータセットに対して、使用しなければ分析が無効になるような唯一無二の正しい事前分布が存在するという意味を含んでいます。**これは間違いです**。唯一無二に正しい事前分布が存在しないのと同様に、唯一無二に正しい尤度も存在しません。**統計モデルは推論のための機械です**。多くの機械が機能しますが、中にはよりうまく機能するものもあります。**事前分布は間違っている可能性がありますが、それはテーブルを作るためのハンマーの種類が間違っているのと同じ意味合いでしかありません**。

事前分布を選択する際には、始めるための簡単なガイドラインがあります。事前分布は、データを見る前の情報の状態を符号化します。したがって、事前分布は、異なる情報から始めることの結果を探求することを可能にします。身長と体重の負の相関のように、特定のパラメータ値の妥当性を割り引く良い事前情報がある場合、その情報を事前分布に直接符号化できます。そのような情報がない場合でも、通常は妥当な値の範囲について十分に知っています。そして、事前分布を変更し、分析を繰り返すことで、初期の情報の異なる状態が推論にどのように影響するかを研究できます。多くの場合、事前分布には多くの合理的な選択肢があり、それらすべてが同じ推論を生成します。そして、従来のベイズ事前分布は、従来の非ベイズアプローチと比較して保守的です。この保守主義が第7章でどのように生じるかを見ていきましょう。

選択を行うことは初心者を緊張させる傾向があります。デフォルトの手順は、事前分布の選択のようにユーザーの選択を必要とする手順よりも客観的であるという幻想が時々あります。もしそれが真実なら、「客観的」とは単に「誰もが同じことをする」という意味にすぎません。それは現実性や正確性の保証を伴いません。

#### Rethinking: Prior predictive simulation and p-hacking（事前予測シミュレーションとPハッキング）
現代の応用統計学における深刻な問題は**「Pハッキング」**です。これは、望ましい結果を得るためにモデルやデータを調整する行為です。望ましい結果は通常、5%以下のp値です。問題は、観測データに基づいてモデルが調整されると、p値が元の意味を失うことです。誤った結果が予想されます。この本ではp値には一切注意を払いません。しかし、観測されたサンプルに条件付けて事前分布を選択し、望ましい結果を得るために調整する場合、危険は残ります。この章で実行した手順は、データに関する事前の知識（その制約、範囲、理論的関係）に基づいて事前分布を選択することでした。これが、前のセクションで実際のデータが表示されなかった理由です。私たちは、サンプルではなく、一般的な事実に対して事前分布を評価しているのです。次に、モデルが実際のデータに対してどのように機能するかを見ていきます。

#### Rethinking: Everything that depends upon parameters has a posterior distribution.（パラメータに依存するすべてのものが事後分布を持つ）
上記のモデルでは、パラメータµはもはやパラメータではありません。なぜなら、それはパラメータαとβの関数になったからです。しかし、パラメータαとβが同時事後分布を持つので、µも同様に持ちます。この章の後半では、µがもはやパラメータでなくても、その事後分布を直接扱います。**パラメータが不確実であるため、それに依存するすべて（µのような統計量だけでなく、モデルベースの予測、適合度測定、パラメータを使用するその他すべてを含む）も不確実です**。事後分布からサンプルを扱うことで、任意の量における事後不確実性を説明するために、事後分布の各サンプルについてその量を計算するだけです。その結果得られる量（事後サンプルごとに1つ）は、その量の事後分布を近似します。

#### Rethinking: Overconfident confidence intervals.（過信した信頼区間）
図4.9の回帰直線の**信頼区間**は、MAP（最大事後確率）の直線に密着しています。したがって、平均体重の関数としての平均身長についてはほとんど不確実性がありません。しかし、これらの推論は常に**モデルに条件付けられている**ことを覚えておく必要があります。非常に悪いモデルであっても、非常に狭い信頼区間を持つことがあります。図4.9の回帰直線は、「身長と体重が直線関係にあるという仮定に条件付ければ、これが最も妥当な直線であり、これらがその妥当な範囲である」と述べていると考えるのが役立つかもしれません。

#### Rethinking: Linear, additive, funky.（線形、加法的、そして奇妙）
上記のµiの放物線モデルは、その方程式が明らかに直線ではないにもかかわらず、依然として平均の「線形モデル」です。残念ながら、「線形」という言葉は文脈によって異なる意味を持ち、同じ文脈でも人によって使い方が異なります。この文脈での「線形」とは、**µiが任意の単一パラメータの線形関数である**ことを意味します。このようなモデルには、データに適合させやすいという利点があります。また、パラメータが平均に独立して作用すると仮定するため、解釈しやすいことも多いです。しかし、非常に慣習的であるという欠点があります。それらはしばしば無思慮に使われます。研究システムについて真の知識がある場合、線形モデルよりも優れた方法で作業できることがよくあります。これらのモデルは天動説的なエンジンであり、変数間の部分的な相関を記述するための装置です。それらが提供する現象論的な説明に満足しないように、それらを使用することを恥ずかしく思うべきです。

#### Overthinking: Getting your hands dirty.（手を汚す）
これらのセクション（**Overthinkingセクション**）は、より小さな活字で記述されており、コードや数学のより詳細な説明を提供します。この内容は本文を理解する上で必須ではありませんが、特に2回目の読書では非常に価値があります。例えば、計算の実行方法が重要な場合があります。数学的には、これら2つの表現は等価です。

*p1 = log(0.01200)*
*p2 = 200× log(0.01)*

しかし、Rを使って計算すると、異なる答えが出ます。

#### Overthinking: Units and regression models.（単位と回帰モデル）
物理科学で伝統的な訓練を受けた読者は、このような方程式を通じて単位を扱う方法を知っているでしょう。彼らのために、簡潔にするために事前分布を省略したモデルを、各記号の単位を加えて再度示します。

#### Overthinking: Sample size and the normality of σ’s posterior.（サンプルサイズとσの事後分布の正規性）
二次近似（**quap**）を推論の近道として使用する前に、上記の身長データ分析を、元のデータの一部のみを使用して繰り返す価値があります。これを行う理由は、原理的に、事後分布が常にガウス形状であるとは限らないことを示すためです。平均µについては問題ありません。ガウス尤度とµに対するガウス事前分布の場合、事後分布はサンプルサイズに関係なく常にガウス分布になります。問題を引き起こすのは標準偏差σです。したがって、σを気にする場合（しばしばそうではありませんが）、二次近似を濫用しないように注意する必要があります。

#### Overthinking: Start values for quap.（quapの開始値）
**quap**は、丘を登るように事後分布を推定します。これを行うためには、あるパラメータ値の組み合わせから登り始める必要があります。特に指定しない限り、**quap**は事前分布からサンプリングされたランダムな値から開始します。しかし、モデル内の任意のパラメータの開始値を指定することも可能です。前のセクションの例では、それはパラメータµとσを意味します。この場合、良い開始値のリストは次のとおりです。

#### Overthinking: Logs and exps, oh my.（対数と指数、ああ）
私の経験では、多くの自然科学者や社会科学者は、かつて知っていた対数に関する知識を自然に忘れてしまいます。対数は応用統計学では常に登場します。y = log(x) を、yにxの**桁数**を割り当てるものとして有用に考えることができます。関数x = exp(y) はその逆で、桁数を値に変換します。これらの定義は数学者を悲鳴を上げさせるでしょう。しかし、私たちの計算作業の多くは、これらの直感にのみ依存しています。

これらの定義により、βに対する**対数正規事前分布**を別の方法でコーディングできます。パラメータβを定義する代わりに、βの対数であるパラメータを定義し、それに正規分布を割り当てます。そして、線形モデル内で対数を逆変換できます。

#### Overthinking: How link works.（linkの仕組み）
関数**link**は実際にはそれほど洗練されていません。それは、モデルを適合させたときに提供した式を使用して、線形モデルの値を計算するだけです。それは、事後分布させたいのは、各サンプルセットに対して身長をシミュレートし、それを各体重値に対して行うことです。

#### Overthinking: Model definition to Bayes’ theorem again.（モデル定義からベイズの定理へ再び）
前ページからのモデル定義が、どのように事後分布を構築するのに役立つかを見てみましょう。高さモデルは、そのµとσの事前分布とともに、この事後分布を定義します。

Pr(µ, σ|h) = ∏i Normal(hi|µ, σ)Normal(µ|178, 20)Uniform(σ|0, 50) / ∫ ∫ ∏i Normal(hi|µ, σ)Normal(µ|178, 20)Uniform(σ|0, 50)dµdσ

---

### 第5章：多くの変数と偽のワッフル

第5章では、**複数の回帰**の重要性を探ります。複数の回帰は、統計的「制御」を通じて交絡因子を処理したり、複数の原因を測定したり、変数間の相互作用を考慮したりするのに役立ちます。

章の冒頭では、ワッフルハウスの密度と離婚率の間の**見せかけの相関**という例が提示されます。これは、両方の変数に影響を与える未観測の共通の原因（例えば、**南方性**）によって引き起こされる**交絡**の典型例として用いられます。この種の相関は、統計的に識別可能であるにもかかわらず、因果関係を示さないため、見せかけの相関と真の因果関係を区別するためのツールが必要であることが強調されます。

**グラフィカル因果モデル（DAGs）**は、変数間の仮説的な因果関係を表現するためのツールとして導入され、モデルの**条件付き独立性**という検証可能な意味合いを導き出すのに役立ちます。

また、この章では、線形モデルの予測を視覚化するための**事後予測プロット**と**反事実プロット**の重要性が強調されます。事後予測プロットはモデルの適合性をチェックするために使用され、反事実プロットは仮説的な介入の結果として何が起こるかをモデルに尋ねることで因果的意味合いを探るのに役立ちます。

#### Rethinking: Causal inference.（因果推論）
その中心的な重要性にもかかわらず、科学や統計学において**因果推論**への統一されたアプローチはまだありません。因果そのものは存在しない、単なる心理的な幻想だ、と主張する人々さえいます。そして、複雑な動的システムでは、すべてが他のすべてを引き起こしているように見えます。「因果」は直感的な価値を失います。しかし、一つだけ一般的に合意されていることがあります。**因果推論は常に検証不可能な仮定に依存する**、ということです。言い換えれば、どれほど慎重に設計や分析を行っても、因果に関するあなたの推論が誤っていると想像できる方法は常に存在するということです。この障壁にもかかわらず、多くのことが達成できます。

#### Rethinking: “Control” is out of control.（「制御」は制御不能）
多くの場合、上記の質問は**「統計的制御」**、つまりある変数の効果を推定しながら別の変数の効果を制御すること、として語られます。しかし、これは曖昧な言葉であり、あまりにも多くを意味します。統計的制御は実験的制御とはかなり異なり、これについては次章でさらに詳しく検討します。ここでの目的は言葉を管理することではなく、**小さな世界**と**大きな世界**の解釈の違いを観察することです。統計を使用する人のほとんどが統計学者ではないため、「制御」のような曖昧な言葉は、解釈の曖昧な文化を助長する可能性があります。このような文化は統計的手法の力を過大評価する傾向があるため、それに抵抗することは困難です。あなた自身の言葉を律するだけで十分かもしれません。他人の言葉を律することは、この章がそうであるように、小うるさい批判者のように見えることなく行うのは難しいことです。

#### Rethinking: Stats, huh, yeah what is it good for?（統計学って、結局何に役立つの？）
人々はしばしば、統計モデリングができないことを統計モデリングに期待します。例えば、ある効果が「実在する」のか、それとも見せかけなのかを知りたいと願います。残念ながら、**モデリングは、モデルが問題を理解する正確な方法で不確実性を定量化するにすぎません**。通常、真実や因果関係に関する大きな世界の問いへの答えは、モデルに含まれていない情報に依存します。例えば、結果と予測変数の間に観測された相関は、別の予測変数がモデルに追加されると排除されたり逆転したりする可能性があります。しかし、正しい変数を見つけられなければ、私たちはそれに気づかないかもしれません。したがって、**すべての統計モデルは、その推定値の精度や予測の見かけの正確さに関わらず、批判にさらされ、批判を要求します**。モデル批判と改訂の繰り返しこそが、科学的仮説の真の検証を具現化します。真の仮説は、受け入れられるまでに多くの統計的「検定」を通過し、また失敗するでしょう。

#### Overthinking: Never use residuals as data.（残差をデータとして決して使用しない）
特に生物学の一部には、**あるモデルの残差を別のモデルのデータとして使用する**という慣習があります。例えば、生物学者が脳サイズを体サイズに対して回帰させ、その脳サイズの残差を別のモデルのデータとして使用することがあります。**この手順は常に間違いです**。残差は既知ではありません。それらはパラメータであり、観測されていない値を持つ変数です。それらを既知の値として扱うことは、不確実性を捨て去ることを意味します。体サイズを制御する正しい方法は、それを同じモデルに含めることです。できれば、明示的な因果同定戦略に基づいて設計されたモデルが望ましいです。

#### Overthinking: Simulating spurious association.（見せかけの関連性のシミュレーション）
予測変数と結果の間に**見せかけの関連性**が生じる一つの方法は、真に因果的な予測変数（xrealと呼びましょう）が結果（y）と見せかけの予測変数（xspur）の両方に影響を与える場合です。これは混乱を招く可能性がありますが、このシナリオをシミュレートし、見せかけのデータがどのように生じるか、そして多重回帰が信頼できる形で正しい予測変数であるxrealを示すことができることを自分で証明するのに役立つかもしれません。非常に基本的なシミュレーションを以下に示します。

#### Overthinking: Simulating counterfactuals.（反事実のシミュレーション）
このセクションの例では、詳細を隠すために**sim()**関数を使用しましたし合うデータをシミュレートすることは役立つかもしれません。前のセクションでは、これと矛盾しない3つのDAGを示しました。最初のDAGと矛盾しないデータをシミュレートするには：

---

### 第6章：憑依されたDAGと因果の恐怖

第6章では、**マルチコリニアリティ（多重共線性）**、**処置後バイアス（post-treatment bias）**、**コライダーバイアス（collider bias）**といった、統計モデルにおける一般的な問題について掘り下げます。これらの問題は、複数の回帰を使用する際に生じ、因果推論を誤った方向に導く可能性があります。

**マルチコリニアリティ**は、2つ以上の予測変数の間に非常に強い相関がある場合に発生し、結果として、実際にはすべての変数が結果と強く関連しているにもかかわらず、事後分布がどの変数も結果と信頼できる関連性がないかのように示唆する現象です。著者は、これがモデルの予測能力を損なうわけではないが、個々の変数の重要性を理解する上で混乱を招くと説明します。

**処置後バイアス**は、因果関係を推定しようとする際に、治療の後に発生した変数をモデルに含めることによって生じるバイアスです。

**コライダーバイアス**は、複数の原因の共通の結果（コライダー）に変数を条件付ける（モデルに含める）ことによって生じます。これにより、実際には独立しているはずの変数間に見せかけの相関が誘導され、誤った推論につながります。章の冒頭では、グラント審査での**新奇性**と**信頼性**の間の負の相関の例が示され、これは選択プロセス（グラントやジャーナルのレビュー）が両方を重視するために生じる**選択歪み効果**（selection-distortion effect）として説明されます。

これらの問題を克服するためのフレームワークとして、**有向非巡回グラフ（DAGs）**が再び強調されます。DAGsを用いて、因果パスを特定し、交絡パス（**バックドアパス**）を閉じるために制御すべき変数と、開いておくべきパスを特定する方法が示されます。

#### Rethinking: Model selection doesn’t help.（モデル選択は助けにならない）
次章で、**情報量規準達**を用いた**モデル選択**について学びます。他のモデル比較や選択スキームと同様に、これらの基準はモデル構造の比較や選択に役立ちます。しかし、これらは、先ほど提示された例（処置後バイアスの例）では何の役にも立ちません。なぜなら、真菌を含むモデルは、サンプルによりよく適合し、**サンプル外予測**もより優れているからです。モデルm6.7は、それが間違った質問をしているのであって、予測が悪いからではないため、誤解を招きます。第1章で議論したように、予測と因果推論は同じタスクではありません。**科学的知識とそれへの注意に代わる統計的手順はありません**。私たちは、因果パスを理解するために複数のモデルが必要であり、予測のために一つを選ぶだけでは不十分です。

#### Rethinking: Statistical paradoxes and causal explanations.（統計的パラドックスと因果的説明）
祖父母の例は、**シンプソンのパラドックス**の一例として機能します。これは、別の予測変数（この場合はP）を含めることで、ある予測変数（G）と結果（C）の間の関連性の方向が逆転する現象です。通常、シンプソンのパラドックスは、新しい予測変数を含めることが私たちに役立つ場合に提示されます。しかし、この場合は、私たちを誤解させます。シンプソンのパラドックスは統計的な現象です。関連性の逆転が因果関係を正しく反映しているかどうかを知るためには、統計モデル以上のものが必要です。

#### Rethinking: DAGs are not enough.（DAGsだけでは不十分）
もしあなたのシステムに関する真の、メカニズム的なモデルがないのであれば、**DAGs**は素晴らしいツールです。少なくとも、彼らは多重回帰を理論の代わりとして使うという一般的なアプローチに対する警告を与えてくれます。しかし、DAGsは目的地ではありません。システムの動的モデルを持っているなら、DAGsは必要ありません。実際、多くの動的システムは、初期条件に敏感な複雑な振る舞いをするため、DAGsで有用に表現することはできません。しかし、これらのモデルは依然として分析でき、それらから因果的介入を設計できます。DAGsがすべてに役立つわけではないという事実は、彼らに対する議論ではありません。すべての理論ツールには限界があります。因果推論の仕組みと障害を教える上で、DAGsよりも優れたツールはまだ見たことがありません。

#### Overthinking: Simulated science distortion.（シミュレートされた科学の歪み）
このようなシミュレーションは、いくつかの例を見れば、Rや他のスクリプト言語で簡単に行うことができます。このシミュレーションでは、提案のサンプルについていくつかのランダムなガウス基準を抽出し、複合スコアの上位10%を選択します。

---

### 第7章：ユリシーズのコンパス

第7章では、**モデル選択**における**過剰適合**と**過少適合**のトレードオフをナビゲートするためのツールに焦点を当てます。著者は、コペルニクスの地動説がプトレマイオスの天動説よりも単純であったことになぞらえ、モデルの**「単純さ」**が重要であることを指摘します。しかし、現実には単純さと予測精度を両立させる必要があり、**「オッカムの剃刀」**だけでは不十分だと述べ、ホメロスの叙事詩「オデュッセイア」の英雄ユリシーズが怪物の間を航海した物語になぞらえ、**「ユリシーズのコンパス」**という比喩を用いてこのトレードオフを説明します。過剰適合（スキュラ）はデータから学びすぎることによる予測の質の低下を、過少適合（カリュブディス）は学びが足りないことによる予測の質の低下を意味します。

この章で紹介される主要なツールは、**正則化事前分布（regularizing prior）**と、**情報量規準達（information criteria）**や**交差検証（cross-validation）**といったスコアリングデバイスです。**正則化事前分布**は、モデルがデータに過剰に興奮するのを防ぎ、**過剰適合**を減らすのに役立ちます。一方、**情報量規準達**は、**Kullback-Leibler情報量**を用いて、**サンプル外逸脱度（out-of空を眺める）
科学者たちが最も一般的に行う**モデル選択**は、すべての係数が統計的に有意であるモデルを探すことです。統計学者たちは、推定値の後に続くアスタリスク（**）を探すことに例えて、これを**星空を眺める（stargazing）**と呼ぶことがあります。星でいっぱいのモデルが最良である、という考え方です。

しかし、**そのようなモデルが最良であるとは限りません**。帰無仮説有意性検定全般についてどう思うかにかかわらず、（OLSとベイズ的反本質主義）
これらの脳サイズモデルの事後分布を得るために、非ベイズ的な**最小二乗法（OLS）**の戦略を使用することも可能です。例えば、Rの単純な**lm**関数を使ってm6.1の事後分布を得ることができます。ただし、sigmaの事後分布は得られません。

事前分布が曖昧である限り、回帰直線に対する二乗偏差の合計を最小化することは、事後平均を見つけることと等価です。実際、カール・フリードリヒ・ガウスは元々、手順に具体化されることもあります。**ベイズ推論は事後分布を近似することを意味します**。その近似がどのように行われるかは指定されていません。

#### Rethinking: What is a true model?（真のモデルとは何か？）
**「真の」確率**を定義することは困難です。なぜなら、**すべてのモデルは誤っている**からです。では、この文脈で「真実」とは何を意味するのでしょうか？それは、私たちの無知な状態を考慮した上で、正しい確率を意味します。確率はモデルの中にあり、世界の中にはありません。予測**最大エントロピー（maxent）**、別名マクセンです。最大エントロピーは、知識の状態と最も整合性の高い確率分布を見つけるための手法群です。言い換えれば、私たちが知っていることを考慮すると、最も驚きが少ない分布は何でしょうか？この問いに対する答えの一つは、**事前知識を制約として使用して、情報エントロピーを最大化すること**であることが判明しています。これを行うと、実際に事後分布が得られます。したがって、**ベイズ更新はエントロピー最大化です**。最大エントロピーは第10章で大きく取り上げられ、**一般化線形モデル（GLMs）**の構築に役立ちます。

#### Rethinking: Information criteria and consistency.（情報量規準達と整合性）
前述のように、AICやWAICのような**情報量規準達**は、常に「真の」モデルに最適な期待されるDtestを割り当てるわけではありません。統計学の専門用語では、**情報量規準達はモデル同定において整合性がない**とされます。これらの基準は、**サンプル外逸脱度**によって判断される最高の予測を生成するモデルを指名することを目的としているため、それらが設計されていないことを行わないことは驚くべきことではありません。しかし、モデル比較のための他の基準は整合性があります。では、情報量規準達は壊れているのでしょうか？

もしあなたが**予測**を重視するなら、それらは壊れていません。整合性のような問題は、ほとんどの場合、漸近的に評価されます。これは、サンプルサイズNが無限大に近づくと想像し、そのとき手順がどのように振る舞うかを問うことを意味します。実番目の予測変数の後の係数がほぼゼロであることを示します。したがって、「正しい」モデルを特定できないことは、少なくともこの意味では私たちを傷つけません。さらに、自然科学および社会科学では、検討中のモデルがデータ生成モデルであることはほとんどありません。**「真の」モデルを特定しようとすることはほとんど意味がありません**。

#### Rethinking: What about BIC and Bayes factors?（BICとベイズ因子について）
**ベイズ情報量規準（BIC）**、別名**シュワルツ規準**は、より一般的に**AIC**と並置されます。**BIC**か**AIC**（またはどちらでもない）かの選択は、ベイズ的であるかないかではありません。両方を動機付けるベイズ的および非ベイズ的な方法があり、厳密であるかどうかにかかわらず、どちらもベイズ的ではありません。BICは線形モデルの平均尤度の対数と関連しています。平均尤度はベイズの定理の分母であり、事前分布にわたって平均された尤度です。ベイズ推論には、モデルを比較する手段として平均尤度を比較するという由緒ある伝統があります。平均尤度の比率は**ベイズ因子**と呼ばれます。対数スケールでは、これらの比率は差であり、したがって平均尤度の差を比較することは、**情報量規準達**の差を比較することに似ています。平均尤度は事前分布にわたって平均されるため、より多くのパラメータは複雑さに自然なペナルティを課します。これは**過剰適合**を防ぐのに役立ちますが、厳密なペナルティは情報量規準達とは異なります。

多くのベイズ統計学者はベイズ因子アプローチを好みませんし、全員がその使用には技術的な障害があることを認めています。一つの問題は、平均尤度の計算が難しいことです。事後分布を計算できる場合でも、平均尤度を推定できないことがあります。もう一つの問題は、事前分布が弱く、モデル内の事後分布にほとんど影響を与えない場合でも、事前分布がモデル間の比較に大きな影響を与える可能性があることです。

しかし、ベイズ的か否かの選択が、情報量規準達とベイズ因子のどちらを選ぶかを決定するわけではないことを認識することが重要です。さらに、実際には選択する必要はありません。私たちは常に両方を使用し、それらが一致するか、どのように異なるかから学ぶことができます。そして、**情報量規準達**も**ベイズ因子**も純粋に予測的な基準であり、**交絡したモデルでも喜んで選択するでしょう**。それらは因果関係について何も知りません。

#### Rethinking: Diverse prediction frameworks.（多様な予測フレームワーク）
この章で使ってきた「訓練とテスト」という賭けは、訓練サンプルと同じサイズと性質のテストサンプルを予測することを意味します。これは、情報量規準達が訓練と同じサイズのサンプルを予測する計画がある場合にのみ使用できるという意味では決してありません。同じサイズは、単にサンプル外逸脱度を同様にスケーリングするだけです。有用なのは、モデル間の距離であって、逸脱度の絶対値ではありません。また、**交差検証**や**情報量規準達**は、データ生成モデルが検討中のモデルのいずれかである必要もありません。これは私たちのシミュレーションでは当てはまりましたが、予測のための良いモデルを特定するのに役立つための要件ではありません。

しかし、「訓練とテスト」の予測タスクは、私たちがモデルでやりたいことのすべてを代表するものではありません。例えば、一部の統計学者は、訓練サンプル全体の累積学習誤差に基づいてモデルを判断する**「事前的な（prequential）フレームワーク」**で予測を評価することを好みます。そして、**多階層モデル**を使い始めると、「予測」はもはや一意に定義されなくなります。なぜなら、テストサンプルは、一部のパラメータ推定値の使用を禁じるような方法で訓練サンプルと異なる可能性があるからです。この問題については、第13章で検討します。

おそらくより大きな懸念は、私たちの「訓練とテスト」の思考実験が、訓練サンプルとまったく同じプロセスからテストサンプルを抽出していることです。これは、**「均一説」の仮定**の一種であり、将来のデータが過去のデータと同じプロセスから生じ、ほぼ同じ範囲の値を持つと期待されるものです。これは問題を引き起こす可能性があります。例えば、体重を使って身長を予測する回帰を適合させたとします。訓練サンプルは貧しい町の人々から得られ、ほとんどの人がかなり痩せています。身長と体重の関係は正で強いことが判明します。次に、予測目標が、はるかに裕福な別の町の身長を推測することだとします。裕福な個人の体重を、貧しい個人に適合させたモデルに代入すると、とてつもなく背の高い人々を予測するでしょう。その理由は、体重が十分に大きくなると、身長との関係が実質的になくなるからです。WAICは自動的にこの問題を認識したり解決したりしません。他のいかなる単独の手順も同様です。しかし、モデルの適合、予測の試み、モデル批判の繰り返しを通じて、このような限界を克服することは可能です。いつものことながら、**統計学は科学の代わりにはなりません**。

#### Rethinking: WAIC metaphors.（WAICの比喩）
WAIC（または他の情報量規準）を使ってモデルを比較する際の概念を説明するのに役立つ2つの比喩を挙げます。

**モデルを競走馬だと考えてください**。どのレースでも、最高の馬が勝つとは限りません。しかし、最悪の馬よりも勝つ可能性は高いです。そして、勝ち馬が2着の馬の半分の時間でゴールした場合、勝ち馬が最高であるとかなり確信できます。しかし、写真判定で1着と2着がほぼ同着の場合、どちらが最高の馬であるかを確信するのははるかに困難です。WAICの値はこれらのレースタイムに似ています。値が小さいほど良く、馬/モデル間の距離は情報を提供します。赤池重みは、ゴールタイムの差を、将来のデータ/レースで最高のモデル/馬である確率に変換します。しかし、トラックの状態や騎手が変更された場合、これらの確率は誤解を招く可能性があります。単一のレース/適合に基づいて将来のレース/予測を予測することには何の保証もありません。

**モデルを池に石を投げて跳ねさせる石だと考えてください**。どの石も向こう岸には届きません（完璧な予測）。しかし、平均的には、ある種の石は他の石よりも遠くまで行きます（より良いテスト予測をします）。しかし、個々の投擲では、風が強くなったり向きが変わったり、アヒルが石をさえぎったり、投げる人の握りが滑ったりするなど、多くのユニークな条件が利用できます。したがって、どの石が最も遠くまで行くかは不確実です。それでも、各石が到達した相対的な距離は、平均的にどの石が最も良い結果を出すかについての情報を提供します。しかし、石間の距離が非常に大きい場合を除いて、個々の石についてあまり自信を持つことはできません。

もちろん、どちらの比喩も完璧ではありません。比喩は決して完璧ではありません。しかし、多くの人がこれらを**情報量規準達**の解釈に役立つと感じています。

#### Rethinking: The Curse of Tippecanoe.（ティペカヌーの呪い）
**モデル比較**に関する一つの懸念は、予測変数の多くの組み合わせや変換を試せば、最終的に任意の特定のサンプルに非常によく適合するモデルが見つかるかもしれないということです。しかし、この適合は**過剰適合**の特殊なケースであり、新しいデータに一般化する可能性は低いです。そして、WAICや同様の指標は騙されてしまうでしょう。そのため、**あらゆる可能なモデルを試すことに反対する助言**が一般的です。

アナロジーとして、**ティペカヌーの呪い**を考えてみましょう。1840年から1960年まで、0の数字で終わる年に選出された（4年任期で20年ごとに発生する）すべての米国大統領が在任中に死亡しました。ウィリアム・ヘンリー・ハリソンが最初で、1840年に選出され、翌年に肺炎で死亡しました。ジョン・F・ケネディが最後で、1960年に選出され、1963年に暗殺されました。このパターンで7人の米国大統領が連続して死亡しました。ロナルド・レーガンは1980年に選出されましたが、少なくとも一度の暗殺未遂にもかかわらず、任期後も長く生き続け、この呪いを破りました。十分な時間とデータがあれば、このようなパターンはほとんどあらゆるデータで見つけることができます。しかし、このパターンが意味を持つと信じるに足る説得力のある理由がなければ、そのようなパターンが存在することに説得力はありません。**ほとんどの大規模なデータセットには、強く驚くべき相関パターンが含まれています**。十分に探せば、ティペカヌーの呪いを見つけるのは必至です。

多くの予測変数をいじったり構築したりすることは、偶然の一致を見つけるには素晴らしい方法ですが、必ずしも仮説を評価するのに素晴らしい方法ではありません。しかし、最初に変数のリストを絞り込む判断を伴う限り、多くの可能なモデルを適合させることは常に危険なアイデアというわけではありません。この戦略が擁護可能に見えるシナリオが2つあります。第一に、評価すべき明確な仮説がないため、単にデータセットを探求したい場合です。これは、自分で認めなければ**「データマイニング（data dredging）」**と批判的に呼ばれる行為ですが、**モデル平均化**と組み合わせて自由に行うのであれば、将来の調査を刺激する手段となり得ます。第二に、予測にあまり役立たないように見えるため、利用可能なすべての予測変数の組み合わせを試したことを聴衆に納得させる必要がある場合です。

#### Overthinking: More on entropy.（エントロピーについてさらに）
上記で、**情報エントロピー**は平均対数確率であると述べました。しかし、定義には-1も含まれています。平均対数確率に-1を掛けるのは、エントロピーHをゼロから減少させるのではなく、ゼロから増加させるためだけに過ぎません。これは慣例ですが、機能的なものではありません。上記の対数は自然対数（底e）ですが、底を変更しても推論に影響を与えることなくスケーリングされます。二進対数（底2）も同様に一般的です。比較するすべてのエントロピーが同じ底を使用している限り、問題ありません。

Hを計算する唯一の秘訣は、pi = 0の場合にどうするかという避けられない問題に対処することです。log(0) = -∞は困ります。しかし、ロピタルの法則は、lim(pi→0) pi log(pi) = 0であると教えてくれます。したがって、Hを計算する際には、0 log(0) = 0と仮定してください。言い換えれば、決して起こらない事象は脱落するということです。ある事象が決して起こらない場合、それをモデルに含める意味はない、ということを覚えておいてください。

#### Overthinking: The Wallis derivation.（ウォリスの導出）
直感的に、**情報エントロピー**の定義に基づいて**最大エントロピー**を正当化できます。しかし、グレアム・ウォリスに帰属する、**「情報」を全く持ち出さない別の導出**があります。簡単な説明を以下に示します。M個の観測可能な事象があり、それぞれの妥当性を割り当てたいとします。私たちは、これらの事象を生成するプロセスについて、期待値や分散などの制約をいくつか知っています。ここで、M個のバケツを設定し、各石がM個のバケツのいずれかに等しい確率で落ちるように、多数のN個の個々の石をランダムに投げ込むことを想像してください。すべての石が着地した後、各バケツiの石の数niを数え、これらのカウントniを使用して、pi = ni/Nで定義される候補確率分布を構築します。この候補分布が私たちの制約と矛盾しない場合、それをリストに追加します。そうでない場合、バケツを空にしてやり直します。これを何度も繰り返した後、最も多く出現した分布は、私たちが課した制約に従いながらも、最も公平である（石をバケツに投げ込む際に偏りがなかったという意味で）分布となります。

#### Overthinking: Simulated training and testing.（シミュレートされた訓練とテスト）
図7.6を再現するために、**sim.train.test**は5つの各モデルについて10,000回（1e4）実行されます。以下のコードは、すべてのシミュレーションを実行するのに十分です。

#### Overthinking: Pareto-smoothed cross-validation.（パレート平滑化交差検証）
**交差検証（Cross-validation）**は、**サンプル外対数点別予測密度（lppd）**を推定します。もしN個の観測値があり、モデルをN回適合させ、毎回単一の観測値yiを削除した場合、サンプル外lppdは、削除された各yiの平均精度の合計です。

#### Overthinking: WAIC calculations.（WAICの計算）
WAICの計算が実際にどのように機能するかを見るために、**quap**で適合させた単純な回帰を考えてみましょう。

モデルが複雑になるにつれて、通常変化するのは、対数確率（logprob）がどのように計算されるかだけです。

各個々の観測には、上記で計算した**pWAIC**ベクトルに独自のペナルティ項があることに注意してください。これにより、異なる観測が**過剰適合**にどのように寄与するかを研究主なテーマは、予測変数の効果が他の変数の値に**条件付けられる**（依存する）ようなモデル、すなわち**交互作用（interactions）**を持つモデルを構築する方法です。従来の線形モデルは、各予測変数が結果の平均と独立した関連を持つと仮定していますが、例えば乳エネルギーと脳サイズの間の関係が分類群（類人猿、サル、原猿）によって異なる場合など、この仮定が不十分な状況があります。

交互作用モデルを構築する際に、データを異なるグループに分割するのではなく、すべてのデータを使用してモデル内で条件付けを行うことの利点が説明されます。これにより、パラメータ推定の精度が向上し、異なるモデル間での比較が可能になり、**多階層モデル**の利点（異なるカテゴリ間での情報共有）が活用できるようになります。

#### Rethinking: Statistics all-star, Abraham Wald.（統計学のオールスター、エイブラハム・ウォルド）
第二次世界大戦の爆撃機の話は、エイブラハム・ウォルド（1902-1950）の研究です。ウォルドは現在ルーマニアである場所に生まれましたが、ナチスによるオーストリア侵攻後、アメリカ合衆国に移住しました。ウォルドは短い生涯で多くの貢献をしました。現在の資料に最も関連するかもしれませんが、ウォルドは、統計的決定を行うための多くの種類のルールについて、非ベイズ的なルールと同じかそれ以上の良さを持つベイズ的なルールが存在することを証明しました。ウォルドは、驚くべきことに、非ベイズ的な前提から始めてこれを証明したため、反ベイズ主義者はそれを無視できませんでした。この研究は、ウォルドの1950年の著書にまとめられています。ウォルドはインドを旅行中に飛行機事故で若くして亡くなりました。

#### Rethinking: Why 97%?（なぜ97%？）
上記のコードブロック、および図8.4では、期待平均の97%区間を使用しました。これはかなり非標準的なパーセンタイル区間です。では、なぜ97%を使用するのでしょうか？この本では、95%や5%といった慣習が恣意的であることを読者に常に思い出させるために、非標準的なパーセンテージを使用しています。さらに、境界は無意味です。期待値から離れるにつれて、確率は連続的に変化します。したがって、境界の一方の側は、もう一方の側とほぼ同じくらいもっともらしいのです。また、97は素数です。これは、ここでの他のどの数字よりも良い選択であるという意味ではありませんが、片手に5本の指があるからといって5の倍数を使用するよりも愚かなことではありません。**四足動物の暴政に抵抗しましょう**。

#### Overthinking: Practicing for when it matters.（重要な時のために練習する）
図8.3の演習は、この例では実際には必要ありません。なぜなら、十分なデータがあり、モデルが十分に単純であるため、ひどい事前分布でも洗い流されてしまうからです。完全に平坦な事前分布（してはいけません！）を使用しても、すべて問題ないでしょう。しかし、**私たちは常に重要ではないからといって正しいことをしないのではなく、それが重要になるときのために正しいことを練習するのです**。

---

### 第9章：マルコフ連鎖モンテカルロ

第9章では、**マルコフ連鎖モンテカルロ（MCMC）**推定法が導入されます。MCMCは、複雑なモデルの**事後分布**からサンプルを生成するための強力なツールであり、1990年代以降の**ベイズデータ分析**の普及に大きく貢献しました。

著者は、MCMCアルゴリズムの概念的な仕組みを「王マルコフ」の寓話を用いて説明します。王マルコフは、人口の島々の数を推定しようとしますが、直接数える代わりに、異なる島々を訪問し、その訪問回数から推定を行います。これにより、**事後分布**から直接計算や近似を行う代わりに、サンプルを抽出するというMCMCの戦略が視覚化されます。

主要なMCMCアルゴリズムとして、**メトロポリスアルゴリズム**、**ギブスサンプリング**、そして最も一般的な**ハミルトニアンモンテカルロ（HMC）**が紹介されます。特にHMCは、**事後分布**の勾配情報を用いて効率的に探索するため、パラメータ間の相関が高い高次元の問題に優れていると説明されます。

この章では、MCMCチェーンの**収束**を診断することの重要性も強調されます。**n_eff**（有効サンプルサイズ）と**Rhat**（ギルマン＝ルービン収束診断）は、チェーンの効率性と収束を評価するための主要な診断基準として紹介されますが、これらだけに過度に依存しないよう警告されています。また、計算上の問題がある場合、多くの場合モデル自体に問題があるという**「統計的計算の民間定理」**も提示されます。

#### Rethinking: The MCMC horizon.（MCMCの展望）
**マルコフ連鎖モンテカルロ**の背後にあるアイデアは新しいものではありませんが、その広範な使用は20世紀最後の10年間まで遡ります。MCMCアルゴリズムの新しいバリアントや改善は常に現れています。興味深い進歩が訪れると予想でき、現在のツール（例えばギブスサンプリングや第一世代のHMC）は、今後20年でかなり平凡に見えるかもしれません。少なくとも、私たちはそう願うことができます。

#### Rethinking: Convergence diagnostics.（収束診断）
Stanのデフォルトの診断出力には、**n_eff**と**Rhat**という2つの指標が含まれています。前者は**有効サンプルサイズ**の尺度です。後者は**ギルマン＝ルービン収束診断**R̂です。**n_eff**がチェーンの実際の反復回数（ウォームアップを除く）よりもはるかに低い場合、チェーンが非効率的ではあるが、おそらくまだ問題ないことを意味します。**Rhat**が1.00を超えている場合、通常、チェーンがまだ収束していないことを示しており、おそらくサンプルを信頼すべきではありません。より多くの反復回数を描画すれば、問題が解決するかもしれませんが、決して収束しないこともあります。詳細はStanのユーザーマニュアルを参照してください。ただし、これらの診断に過度に依存しないことが重要です。すべてのヒューリスティクスと同様に、それらが不適切なアドバイスを提供するケースもあります。例えば、**Rhat**は無効なチェーンでも1.00に達することがあります。したがって、それは危険の兆候として見るべきですが、決して安全の兆候として見てはいけません。従来のモデルでは、これらの指標は通常うまく機能します。

#### Rethinking: The folk theorem of statistical computing.（統計的計算の民間定理）
上記の例は、**「統計的計算の民間定理」**として知られていることを示しています。**計算上の問題がある場合、しばしばあなたのモデルに問題があるのです**。ソフトウェアを調整したり、より多くの計算能力を問題に注ぎ込む前に、モデルの仕様やデータ自体を再度確認し、問題がサンプリング前の段階にないことを確認することが役立つ場合があります。ベイズモデルで作業していると、サンプリングが遅かったり、ぎこちなかったりする原因が、一つ以上の事前分布を完全に省略したことのような単純なことであることは非常に一般的です。

#### Rethinking: Hamiltonian warnings and Gibbs overconfidence.（ハミルトニアンの警告とギブスの過信）
人々がStanや他のハミルトニアンサンプラーを使い始めると、以前はBUGS、JAGS、MCMCglmmのようなメトロポリス-ヘイスティングスおよびギブスサンプラーで適合させていたモデルがうまく機能しないことに気づくことがよくあります。チェーンは遅く、多くの警告が表示されます。Stanは本当にしつこいツールです。Stanに何か問題があるのでしょうか？

いいえ、それらの問題は、他のツールでも常に存在していた可能性が高いです。しかし、ギブスサンプラーは勾配を使用しないため、ハミルトニアンエンジンが気づくであろういくつかの問題に気づきません。応用統計学では、何百万もの反復で悪いチェーンを非常に長時間実行し、その後積極的に間引いたり、祈ったり、発表したりするという文化が進化してきました。系統発生分析は、ツリー空間が探索するのが非常に困難であるため、この傾向が特に強いかもしれません。**Stanや他のハミルトニアンエンジンは、モンテカルロ近似の精度に関する診断基準をより多く提供するため、信頼できる研究にとって非常に重要です**。そのしつこさに憤慨しないでください。

#### Overthinking: Divergent transitions are your friend.（ダイバージェントトランジションはあなたの友）
**ulam**とStanを使用していると、**ダイバージェントトランジション（Divergent transition）**の警告に頻繁に遭遇するでしょう。それらはあなたの友であり、役立つ警告を提供してくれます。これらの警告は、HMCが使用する数値シミュレーションが不正確な場合に発生します。HMCはこれらの不正確さを検出できます。これは、他のサンプリングアプローチ（そのほとんどは、悪いチェーンを自動的に発見する方法がほとんどない）に対する主な利点の一つです。私たちはこれらのダイバージェントトランジションについて、後の章でさらに詳しく検討します。それらを回避するためのいくつかの賢い方法も見ていきます。

---

### 第10章：大きなエントロピーと一般化線形モデル

第10章は、**最大エントロピー原理**を統計モデリングの選択、特に**尤度関数**と**事前分布**の選択に適用することに焦点を当てています。**最大エントロピー原理**は、既知の制約と矛盾しない最も情報量の少ない（すなわち、最も不確実性の高い）確率分布を選択するというものです。これにより、データに関する特定の制約（例えば、カウントがゼロ以上である、または二値の結果であるなど）を満たす、最も保守的な尤度関数を「自動的に」選択できます。

この章では、**一般化線形モデル（GLMs）**の概念が導入されます。GLMは、線形モデルを**リンク関数**を介して非ガウス的な応答変数に拡張するもので、結果のスケールが線形モデルのスケールと異なる場合に特に有用です。例えば、カウントデータには**ポアソン分布**や**二項分布**が、連続的な正の値には**ガンマ分布**が適切であると説明されます。

重要なのは、**尤度関数**も**事前分布**と同様に選択されるべき仮定であり、**「正しい」尤度関数は存在しない**が、文脈に応じてより良いものと悪いものがあるという考え方です。また、GLMにおけるリンク関数の使用は、回帰係数が結果スケール上で一定の変化をもたらさないことを意味し、すべての予測変数が実質的に互いに**交互作用**するという点で、より複雑な解釈を必要とすると説明されています。

#### Rethinking: What good is intuition?（直感は何の役に立つのか？）
**情報理論**の多くの側面と同様に、**最大エントロピー**はあまり直感的ではありません。しかし、直感はあくまで方法論開発の指針に過ぎないという点に注意してください。**方法が機能するなら、私たちの直感がそれに同意するかどうかはほとんど問題ではありません**。この点は重要です。なぜなら、一部の人々は今でも哲学的原則や直感的魅力に基づいて統計的アプローチを議論しているからです。哲学は重要です。なぜなら、それが開発と応用に影響を与えるからです。しかし、それがアプローチが有用かどうかを判断するのに適した方法であるとは言えません。**結果が重要なのです**。例えば、第6章で情報エントロピーを導き出すために使用された3つの基準は、情報エントロピーを使用する正当化ではありません。正当化はむしろ、他の方法が失敗した多くの問題で、それがこれほどうまく機能してきたという事実です。

#### Rethinking: Conditional independence.（条件付き独立）
常に一定の期待値という話は、重要な疑問を引き起こします。これらの分布は、各観測が他のすべての観測と無相関であると必然的に仮定しているのでしょうか？必ずしもそうではありません。**確率分布における「独立性」が通常意味するのは、対応する予測変数の値がわかっている場合、各観測が他の観測と無相関であるということです**。これは通常、**条件付き独立**として知られており、モデルを介して予測変数の違いを考慮した後も観測が独立しているという主張です。これはモデリング上の仮定です。この仮定がカバーしないのは、観測された事象が次の観測された事象を直接引き起こすような状況です。例えば、私が次のニック・ケイブのアルバムを買うからといってあなたが次のニック・ケイブのアルバムを買う場合、私たちが両方ともその種の音楽が好きであるという事実を条件付けたとしても、あなたの行動は私の行動とは独立していません。

#### Rethinking: The scourge of Histomancy.（ヒストマンシーの災い）
結果の分布を選択する一つの戦略は、結果変数のヒストグラムをプロットし、その「魂」を凝視して、どの種類の分布関数を使用するかを決定することです。この戦略を**「ヒストマンシー（Histomancy）」**と呼びましょう。経験的なヒストグラムから尤度関数を占う古代の技術です。この魔術は、例えば、ノンパラメトリックな手続きを使用するかどうかを決定する前に、正規性を検定する際に使用されます。**ヒストマンシーは偽りの神です**。なぜなら、完璧なガウス変数でさえ、ヒストグラムとして表示されるとガウスに見えないことがあるからです。なぜでしょうか？**ガウス尤度が仮定するのは、集約されたデータがガウスに見えることではなく、モデルを適合させた後の残差がガウスに見えることだからです**。例えば、男性と女性の体重の合計ヒストグラムは、確かにガウス分布ではありません。しかし、それは（近似的に）ガウス分布の混合です。したがって、性別を条件付けた後、残差はかなり正規分布するかもしれません。また、ポアソンモデルを使用しないと決定する人々もいます。なぜなら、集約された結果の分散がその平均を超えるからです（第11章を参照）。しかし、繰り返しますが、ポアソン尤度が仮定するのは、予測変数を条件付けた後に分散が平均と等しくなることだけです。特定の文脈においてガウス尤度やポアソン尤度が不適切な仮定であることは十分にあり得ます。しかし、これをヒストマンシーで簡単に判断することはできません。だからこそ、**最大エントロピー**であれ何であれ、原則が必要なのです。

#### Rethinking: A likelihood is a prior.（尤度は事前分布である）
伝統的な統計学では、**尤度関数**は「客観的」であり、**事前分布**は「主観的」であるとされます。しかし、**尤度自体も事前確率分布です**。それらは、パラメータに条件付けられたデータに対する事前分布なのです。そして、他の事前分布と同様に、「正しい」尤度はありません。しかし、文脈によってより良い尤度と悪い尤度があります。有用な推論は、データ（または残差）が尤度に従って実際に分布していることを必要としないのと同様に、事後分布が事前分布に似ていることを必要としません。尤度と事前分布の**二重性**は、第15章で非常に明確になります。

#### Rethinking: When in doubt, play with assumptions.（疑わしければ仮定で遊んでみる）
**リンク関数**は確かに仮定に相当します。そして、すべての仮定と同様に、それらは異なる文脈で有用です。従来のロジットリンクと対数リンクは広く有用ですが、時には推論を歪めることがあります。もし疑問がある場合、そしてあなたの結論がリンク関数の選択に敏感でないことを確認したい場合、他のモデリングの仮定（尤度、線形モデル、事前分布、さらにはモデルの適合方法）と同じように、**感度分析**を行います。感度分析は、仮定の変化が推論にどのように影響するかを探求します。あなたが検討する代替仮定のどれもが推論に大きな影響を与えない場合、それは報告する価値があります。同様に、あなたが検討する代替仮定が推論に重要な影響を与える場合も、それは報告する価値があります。多くの機械と同様に、極端な条件下でモデルがどのように振る舞うかを探求することは、通常の条件下でそれがどのように振る舞うかを理解するのに役立ちます。

一部の人々は感度分析に神経質になります。なぜなら、それは結果を探すこと、つまり**「Pハッキング」**のように感じるからです。**感度分析の目的は、実際にはPハッキングとは逆です**。Pハッキングでは、多くの正当化可能な分析が試され、統計的に有意になったものが報告されます。感度分析では、多くの正当化可能な分析が試され、それらすべてが記述されます。

#### Overthinking: The Wallis derivation.（ウォリスの導出）
（このコラムは第7章で既出のため、ここでは省略します。書籍内で再掲されている点に注意します。）

#### Overthinking: Parameters interacting with themselves.（パラメータ自身が交互作用する）
**GLMs**がすべての予測変数に自身との**交互作用**を強制するという主張について、数学的に予測変数の値の変化に対する結果の変化率を計算することで、さらなる明確化を図ることができます。まず、古典的なガウスモデルでは平均が次のようにモデル化されることを思い出してください。

µi = α + βxi

これは「exp(α+βx)」を含みます。人々は、非線形効果の解釈を好まないため、非線形モデルを避けることがあります。しかし、実際の現象に非線形性が含まれている場合、これは小さな世界の問題を解決するに過ぎません。

---

### 第11章：神は整数をスパイクした

第11章では、**カウントデータ**のための**一般化線形モデル（GLMs）**、特に**二項回帰**と**ポアソン回帰**に焦点を当てます。著者は、カウントデータは「整数をスパイクする神」という比喩でその複雑さを表現し、そのスケールがパラメータのスケールと異なるため、**潮汐予測エンジン**のように、外観とは異なる内部の仕組みを持つことに例えます。

**二項回帰**は、生存/死亡、承認/拒否などの**二値分類**データをモデル化する際に用いられます。第2章の球体投げのモデルを拡張し、予測変数を導入することで、より複雑な二項過程を分析します。**ロジットリンク関数**が、確率（0から1の範囲）を実数空間に変換するために用いられます。

**ポアソン回帰**は、未知の上限を持つカウントデータ（例：1日の原稿数、工具の種類数）をモデル化するために使用されます。**ポアソン分布**は、二項分布の特殊なケースであり、イベントの確率が非常に小さく、試行回数が非常に多い場合に近似的に成立します。**対数リンク関数**が、ポアソン分布の期待値（常に正である必要がある）を線形モデルの出力に結びつけるために用いられます。

この章では、GLMの文脈における**事前分布**の選択の重要性も再確認されます。対数リンク関数を使用する場合、線形モデルのスケールで平坦な事前分布が、結果のスケールでは非現実的な期待値を生み出す可能性があるため、**事前予測シミュレーション**による慎重な事前分布の設計が推奨されます。

また、**マルコフ連鎖モンテカルロ（MCMC）**推定が、GLMにおける非ガウス事後分布の特性をより正確に捉えるために推奨されますが、**二次近似**も特定の状況では十分機能すると述べられています。

#### Rethinking: Simpson’s paradox is not a paradox.（シンプソンのパラドックスはパラドックスではない）
この経験的例は、統計学教育における有名なものです。これはしばしば**シンプソンのパラドックス**として知られる現象を説明するために使用されます。ほとんどのパラドックスと同様に、論理の違反はなく、単に直感の違反にすぎません。そして、人によって直感が異なるため、シンプソンのパラドックスは人によって異なる意味を持ちます。この場合、**誤解を招く直感とは、集団全体での正の関連性が、各部門内でも成立するはずだというものです**。全体として、このデータでは女性は大学院への入学がより困難でしたが、それは女性が男性であろうと女性であろうと、誰にとっても入学が最も困難な部門に出願したために生じたのです。

#### Overthinking: Adding log-probability calculations to a Stan model.（Stanモデルに対数確率計算を追加する）
**ulam**モデルに**log_lik=TRUE**を追加すると、Stanモデルに、観測された各結果について対数確率を計算するコードブロックが追加されます。これらの計算は、事後分布のサンプルとして返されます。つまり、各観測と各サンプルについて1つの対数確率が得られます。したがって、観測ごとに列があり、サンプルごとに列がある対数確率の行列が最終的に得られます。この行列は、デフォルトでは**precis**や**extract.samples**では表示されません。**extract.samples**に**clean=FALSE**と指定することで抽出できます。

#### Overthinking: Multinomial-Poisson transformation.（多項-ポアソン変換）
**ポアソン分布**は、この章の冒頭で導入されました。タイプ1の事象がy1回発生するポアソン確率は、率λ1と仮定すると、次式で与えられます。

Pr(y1|λ1) = exp(−λ1)λy11 / y1!

この変換の**原典的な引用は見当たらないようです**。一般的な引用はBaker (1994)ですが、彼は多くの先行するアドホックな使用を引用しています。McCullagh and Nelder (1989)は、209ページからこの変換を説明しています。

---

### 第12章：怪物と混合

第12章では、**カウントデータ**や**順序カテゴリデータ**における追加の複雑性、特に**過分散（over-dispersion）**と**ゼロ過剰（zero-inflation）**、**ゼロ増強（zero-augmentation）**を伴うモデルについて掘り下げます。著者は、これらのモデルを**「怪物と混合」**と表現し、これらがデータの特性をより正確に捉えるのに役立つと説明します。

**過分散**は、観測されたデータの分散が、理論的な分布（例えばポアソン分布や二項分布）が仮定する分散よりも大きい場合に発生します。これを扱うためのアプローチとして、**ベータ二項モデル**と**負の二項モデル（ガンマ・ポアソンモデル）**が紹介されます。これらのモデルは、各観測が独自の成功確率またはレートを持つと仮定することで、未測定の変動源に対応します。

**ゼロ過剰**や**ゼロ増強モデル**は、結果変数に予想よりも多くのゼロがある場合に使用されます。これは、ゼロを生成するプロセスが2つある場合に発生します。1つは通常のGLM（例えばポアソン）によって生成され、もう1つはゼロが「追加で」発生する二値プロセスによって生成されます。ゼロ過剰ポアソン（ZIP）モデルの例として、修道士の原稿完成数が示され、飲酒（ゼロを生成するプロセス）と仕事（原稿数を生成するプロセス）という2つのプロセスを分離して推定します。

**順序カテゴリ結果**は、カテゴリ間に明確な順序があるが、間隔が等しいとは限らない結果変数（例：評価尺度、幸福度レベル）をモデル化するために用いられます。**順序ロジットモデル**が、このようなデータをモデル化するための主要な方法として紹介され、累積オッズの対数スケールでパラメータ化されます。これにより、カテゴリ間の相対的な確率を、その順序を尊重しながら推定できます。

#### Rethinking: Breaking the law.（法を破る）
科学界では、統計的推論に関して時々不安な文化があります。かつては、研究者が独自のカスタムモデルを容易に構築・研究できなかったため、適切にモデルを研究してもらうために統計学者に頼らざるを得ませんでした。これは、型破りなモデルに対する懸念、つまり統計学の**「法則を破る」**ことへの懸念につながりました。しかし、統計的計算能力は現在でははるかに優れています。今やあなたは自分自身の**生成過程**を想像し、そこからデータをシミュレートし、モデルを作成し、真のパラメータ値を回復できることを検証することができます。**あなたが必要とするモデルを合法化するために、数学者が待つ必要はありません**。

#### Overthinking: Continuous mixtures.（連続混合）
ベータ二項分布のような分布は**連続混合**と呼ばれます。なぜなら、すべての二項カウントは、それ自身の独立したベータ分布する成功確率を持つと仮定され、ベータ分布は離散的ではなく連続的だからです。したがって、ベータ二項分布のパラメータは、各ケースにおける試行回数（通常の二項分布の「サイズ」nと同じ）と、ベータ分布の形状を記述する2つのパラメータにすぎません。これらすべては、ベータ二項過程から成功数yを観測する確率が次式で与えられることを意味します。

Pr(y|n, α, β) = (n! / y!(n-y)!) * (Γ(α+y)Γ(β+n-y)Γ(α+β) / Γ(α)Γ(β)Γ(α+β+n))

---

### 第13章：記憶を持つモデル

第13章では、**多階層モデル（multilevel models）**、別名**階層モデル（hierarchical models）**または**混合効果モデル（mixed effects models）**が導入されます。これらのモデルは、データがグループやクラスターにネストされている場合に特に有用であり、**「記憶」**を持つモデルとして、異なるクラスターからの情報を共有することで、より正確な推定値を生成します。

中心となる概念は**部分プール（partial pooling）**です。これは、データが少ないクラスターの推定値を、より多くのデータを持つクラスターや全体平均（**グランド平均**）へと「縮小（shrinkage）」させることで、**過剰適合**と**過少適合**の間のトレードオフを最適化します。これにより、個々のクラスターの推定値が改善されるだけでなく、全体的なモデルの予測精度も向上します。

**変数切片（varying intercepts）**は、各クラスターが独自の切片を持つことを可能にし、これらの切片が上位レベルの分布（例えばガウス分布）から生成されると仮定することで、部分プールを実現します。これにより、クラスター間の変動性を推定し、それを個々のクラスターの推定にフィードバックすることができます。

この章では、**ハミルトニアンモンテカルロ（HMC）**サンプリングで発生しがちな**「ダイバージェントトランジション（Divergent transition）」**という問題にも焦点を当てます。これは、**事後分布**の形状が急峻な場合にサンプリングが困難になることで発生し、サンプリングの効率性と信頼性を低下させます。この問題に対処するための主要なテクニックとして、**非中心化パラメータ化（non-centered parameterization）**が紹介されます。これは、モデルの数学的表現を変更することで、HMCサンプラーがよりスムーズに探索できるような事後分布の形状にするものです。

#### Rethinking: A model by any other name.（他の名前のモデル）
**多階層モデル**には多くの異なる名前があり、一部の統計学者は異なる専門的なバリアントに同じ名前を使用したり、すべてを交換可能に使用したりします。**「多階層（multilevel）」**の最も一般的な同義語は、**「階層（hierarchical）」**と**「混合効果（mixed effects）」**です。多階層モデルに現れるパラメータのタイプは、一般的に**「ランダム効果（random effects）」**として知られていますが、これもアナリストや文脈によって意味が大きく異なります。そして、「階層」という無害な用語でさえ、人によって異なる意味を持つことがあります。この語彙の沼地を解決する唯一の方法は、モデルの数学的またはアルゴリズム的な定義を要求することです。さもなければ、常に曖昧さが残るでしょう。

#### Rethinking: Why Gaussian tanks?（なぜガウス分布のタンク？）
**多階層モデル**のオタマジャクシの例では、タンクの集団はガウス分布であると仮定されています。なぜでしょうか？最も不満な答えは「慣習」です。ガウス分布の仮定は極めて一般的です。より満足のいく答えは「実用性」です。ガウス分布の仮定は扱いやすく、複数の次元に容易に一般化できます。この一般化は、次章で傾きの変動を扱う上で重要になります。しかし、私の好む答えは「**エントロピー**」です。もし私たちが分布について、平均と分散しか言及しないのであれば、ガウス分布が最も保守的な仮定です（第10章）。ここでガウス分布を使用しても、結果として得られるαパラメータの事後分布が対称であったり、ガウス形状であったりすることを強制するものではありません。ガウス事前分布（または尤度）に含まれる情報は、有限の分散だけです。分布が対称に見えるのは、非対称性を指定しない場合、対称性が最大エントロピー形状だからです。何よりも、**変動効果のガウス分布を必須とする規則はありません**。したがって、別の分布を使用する正当な理由がある場合は、そうしてください。この章末の実践問題にその例があります。

#### Rethinking: Varying intercepts as over-dispersion.（変動切片と過分散）
前章（381ページ）では、**ベータ二項モデル**と**ガンマポアソンモデル**が、カウントデータの**過分散**に対処する方法として提示されました。**変動切片**も同様の目的を果たし、カウント結果が過分散するのを許容します。これは、観測された各カウントが独自の切片を持つことを許容し、これらの切片が共通の分布を介してプールされることで、ベータ二項モデルやガンマポアソンモデルと同様に過分散を期待する予測を行うためです。ベータ二項モデルやガンマポアソンモデルと比較して、すべての観測結果に変動切片を持つ二項モデルやポアソンモデルは、推定が容易で拡張しやすいことがよくあります。このアプローチの例は、この章の後半で示されます。

#### Rethinking: No free samples.（無料のサンプルはない）
**ハミルトニアンモンテカルロ**が**ダイバージェントトランジション**について不平を言うとき、不平を言わない他のサンプラーに頼りたくなる誘惑に駆られます。**これは間違いです**。例えば、ギブスサンプラーは決して不平を言いません。それはただ静かに失敗するだけです。ギブスサンプリングはHMCが持つ急峻な曲率の問題と同じ問題を抱えていないのは事実です。しかし、ギブスサンプラーも同じ事後分布の問題を抱えています。警告がないだけです。

この一般的な問題（信頼性の低い近似の警告）は、計算統計のすべての部分で発生します。Rパッケージlme4は、**多階層モデル**を適合させるための優れたパッケージです。これはベイズ的ではありませんが、巧妙な非ベイズアルゴリズムを使用しています。時々、そのアルゴリズムは信頼できないことがあり、lme4はユーザーに警告することに非常に優れています。同じ多階層モデルを適合させようとする代替パッケージは、警告をほとんど出さないかもしれません。しかし、それらのパッケージがより信頼できるわけではありません。単に慎重さが足りないだけです。

#### Rethinking: Cross-classification and hierarchy.（交差分類と階層）
データセット**data(chimpanzees)**にあるようなデータ構造は、通常、**交差分類多階層モデル**と呼ばれます。これは、アクターがユニークなブロック内にネストされていないため、交差分類されています。もし各チンパンジーが自分のすべてのプルを、単一のブロック内の単一の日に行っていたとしたら、データ構造は**階層的**だったでしょう。しかし、モデルの仕様は通常同じでしょう。したがって、以下に示すモデル構造とコードは、交差分類された設計と階層的な設計の両方に適用されます。他のソフトウェアでは、MCMCよりもかなり能力の低い条件付けエンジンを使用するため、これらを異なる方法で扱うことを強制される場合があります。**多階層モデル**には他のタイプ（適応的事前分布のための適応的事前分布を作成するタイプ）もあり、これはまるで「無限の亀」のようです（14ページを参照）。その例は次章で示されます。しかし、ほとんどの場合、人々（または彼らのソフトウェア）は、両方のケースでほぼ同じ種類のモデルを使用しています。

#### Overthinking: QUAP fails, MCMC succeeds.（QUAPが失敗し、MCMCが成功する）
なぜ単純な**二次近似（quap）**が**多階層モデル**で機能しないのでしょうか？事前分布自体がパラメータの関数である場合、**不確実性が2つのレベル**に存在します。これは、データがパラメータに条件付けられた確率が、各レベルを平均化しなければならないことを意味します。通常の二次近似は、尤度における平均化を一般的に解析解を導き出せないため、処理できません。これは、対数事後確率を計算するための統一された関数が存在しないことを意味します。したがって、コンピュータは直接その最小値（事後分布の最大値）を見つけることができません。

そのため、他の計算アプローチが必要です。モードを見つける最適化戦略をこれらのモデルに拡張することは可能ですが、私たちは一般的に最適化に固執したくありません。一つの理由は、これらのモデルの事後分布が日常的に**非ガウス型**であることです。もう一つの理由は、最適化アプローチがMCMCよりも脆弱な傾向があることです。Stanには実際、最適化ルーチンがあります（**?optimizing**を参照）。

この適応的**正則化**の影響を理解するために、モデルm13.1とm13.2の事後平均をプロットして比較してみましょう。以下のコードは、情報的なラベルでプロットを装飾するために長いだけです。基本的なコードは、サンプルを抽出し、平均を計算する最初の部分だけです。

#### Overthinking: Priors for variance components.（分散成分の事前分布）
この本の例では、分散成分（データ内のクラスター間の変動を推定するσパラメータ）に**弱情報的な指数事前分布**を使用しています。これらの指数事前分布は、通常の**多階層モデリング**で非常によく機能します。それらは平均標準偏差のラフな概念だけを表現し、ゼロへの**正則化**を行います。しかし、これらが問題となる一般的な文脈が2つあります。第一に、分散を推定するためのデータにあまり情報がない場合です。例えば、クラスターが5つしかない場合、それはデータ点が5つしかない状態で分散を推定しようとするようなものです。この場合、もっと**情報量の多い事前分布**が必要になるかもしれません。第二に、ロジットリンクや対数リンクを持つ非線形モデルでは、**床効果（floor effect）**や**天井効果（ceiling effect）**により、分散の極端な値がより現実的な値と同じくらいもっともらしくなることがあります。

#### Overthinking: Data types and Stan models.（データ型とStanモデル）
Rには、整数と実数値という2つの基本的な数値データ型があります。「3」のような数字はどちらでもあり得ます。コンピュータの内部では、整数と実数（「数値」と呼ばれるもの）は異なる方法で表現されます。例えば、以下のコードは同じ値のベクトルを両方の型で生成します。

通常、Rがこれらの型を管理してくれるため、これらの型を自分で管理する必要はありません。しかし、Stanや他の外部プログラムに値を渡す場合、内部表現が重要になることがよくあります。特に、Stanと**ulam**は明示的な整数を要求することがあります。例えば、二項モデルでは、試行回数を指定する「サイズ」変数は整数型でなければなりません。サイズ変数が「実数型」である場合、Stanは関数が見つからないという不可解な警告メッセージを表示することがあります（Rでは「数値型」と呼ばれます）。データをStanまたは**ulam**に渡す前に**as.integer**を使用することで、この問題は解決されます。

---

### 第14章：共分散の冒険

第14章は、**多階層モデル**をさらに発展させ、**変動する傾き（varying slopes）**と**共分散構造**を組み込む方法を探ります。これにより、クラスターごとに異なる関係の強さをモデル化できるようになります。例えば、カフェの待ち時間と客数の関係がカフェごとに異なる場合など、単一の変動切片だけでは捉えきれない複雑なパターンに対応します。

この章では、**多変量ガウス分布**を使用して、切片と傾きの両方がクラスター間で変動し、それらの間に相関があるような**適応的事前分布**を構築する方法が説明されます。**LKJcorr事前分布**が、相関行列に対する便利な**事前分布**として導入され、**事後分布**の効率的なサンプリングを可能にします。

また、**非中心化パラメータ化**が、**ハミルトニアンモンテカルロ（HMC）**サンプリングにおける**ダイバージェントトランジション**の問題を解決するための強力なテクニックとして再強調されます。**コレスキー分解**を用いることで、共分散行列をパラメータ化し、HMCがより効率的に**事後分布**を探索できるようにします。

因果推論の文脈では、**操作変数（instrumental variables）**が導入されます。これは、交絡パスを閉じることなく因果推論を行うことを可能にする**自然実験**の一種です。教育と賃金の関係の例を通して、操作変数がどのように機能し、その仮定が何であるかがシミュレーションを用いて説明されます。

さらに、**ガウス過程（Gaussian processes）**が、**多階層モデル**の**変動効果**の戦略を、空間的距離、系統発生的距離、ネットワーク距離などの連続的な類似性の次元に拡張する実用的な方法として紹介されます。これにより、データ内の実体間の複雑な共分散パターンをモデル化できるようになります。

#### Rethinking: Why Gaussian?（なぜガウス分布？）
切片と傾きの多変量分布が必ずガウス分布でなければならない理由はありません。しかし、**実用的および認識論的**な正当化があります。実用的な側面では、扱いやすい多変量分布はそれほど多くありません。一般的なのは、多変量ガウス分布と多変量スチューデントt分布だけです。認識論的な側面では、これらの切片と傾きについて、平均、分散、共分散しか言いたくない場合、**最大エントロピー分布は多変量ガウス分布です**。しかし、**薄いガウスの裾**は依然としてリスクを伴います。

#### Rethinking: Simulation and misspecification.（シミュレーションと誤特定）
この演習では、**生成プロセス**からデータをシミュレートし、そのデータに対して、そのプロセスの正しい構造を正確に反映したモデルで分析しています。しかし、現実世界では、私たちは決してそのような幸運に恵まれません。代わりに、私たちは常に**誤特定されたモデル**でデータを分析することを強いられます。真のデータ生成プロセスはモデルとは異なるのです。しかし、**シミュレーションは誤特定の探索に利用できます**。プロセスからデータをシミュレートし、そのデータ生成プロセスと正確には一致しない複数のモデルがどのように機能するかを見るだけです。そして、**ベイズ推論は、尤度などのデータ生成仮定が真実であるかどうかに依存しない**ことを常に覚えておいてください。非ベイズのアプローチは、その推論のために**サンプリング分布**に依存するかもしれませんが、ベイズモデルには当てはまりません。ベイズモデルでは、尤度はデータに対する**事前分布**であり、パラメータに関する推論は、その詳細に驚くほど影響されません。

#### Rethinking: Two-stage worst squares.（2段階最悪二乗法）
**操作変数モデル**は、しばしば**2段階最小二乗法（2SLS）**として知られる推定手順とともに議論されます。この手順には2つの線形回帰が含まれます。最初の回帰の予測値がデータとして2番目の回帰に供給され、その後、標準誤差が意味をなすように調整が行われます。驚くべきことに、好条件であれば、この手順は機能します。それは**大標本近似**に依存しており、よく知られた問題があります。すべてのゴーレムと同様に、責任を持って使用する必要があります。人々は時々、2SLSの手順を操作変数モデルと誤解します。それらは同じものではありません。**どんなモデルでも、それぞれ利点とコストを持つ多くの異なる手順で推定できます**。2SLSは非常に限定的です。カウント結果、測定誤差、欠損値がある場合、または**変動効果**が必要な場合、2SLSは疑わしいです。より高性能な手順が存在するようになった今、操作変数モデルを適合させるのはより容易になりました。しかし、それでも困難な場合があります。DAGが可能であると示唆しているからといって、効果を推定できる保証はありません。事後分布をどのように近似しても常に残るもう一つの問題は、操作変数が優れていることを確認することが非常に難しいことです。

#### Rethinking: Non-centered parameterization of the multilevel model.（多階層モデルの非中心化パラメータ化）
チェーンが非効率な場合、チェーンを十分に長く実行することで、事後分布から信頼できるサンプルが得られることがよくあります。これは、本文中のm14.2の場合がそうでした。しかし、これは非効率的であり、信頼性もありません。チェーンは、検出が難しい微妙な方法で依然として偏っている可能性があります。**前述のセクションで説明したように、再パラメータ化する方が良いです**。共分散行列の場合、これはどのように機能するのでしょうか？

最後に、すべてのモデル構造とデータの組み合わせが**非中心化パラメータ化**の恩恵を受けるわけではありません。中心化されたバージョン、つまり平均と標準偏差を**事前分布**に入れる方が良い場合もあります。したがって、個人的に最も自然な形式を試してみるのが良いでしょう。問題が発生した場合は、代替形式を試してみてください。経験を積むにつれて、同じモデルの異なる形式が馴染み深いものになるでしょう。この章の最後に、役立つかもしれない練習問題があります。

---

### 第15章：欠損データとその他の機会

第15章では、**測定誤差（measurement error）**と**欠損データ（missing data）**という、統計モデリングにおける一般的な問題に**ベイズ推論**を適用する方法を探ります。著者は、これらの問題に対処する際に「賢くなる」必要はなく、単に私たちの情報状態（仮定）を明確に定義すれば、確率のルールが残りの作業を行うと主張します。

**測定誤差**は、観測されたデータが真の値とは異なる場合に発生します。ベイズモデルでは、真の値を未知のパラメータとして扱い、その測定誤差の分布をモデルに含めることで、不確実性を考慮に入れた推定を可能にします。これにより、測定誤差を無視した場合に生じるバイアスを回避できます。

**欠損データ**は、データセット内の特定の値が観測されていない場合に発生します。ベイズ**帰属（imputation）**は、欠損値を、モデルが持つ情報に基づいて**事後分布**から推定することで「埋める」方法です。このアプローチは、欠損データが「意味のあるデータ」であるという考えに基づいています。つまり、データが欠損しているという事実自体が、欠損のプロセスに関する情報を提供し、これをモデルに組み込むことで、より正確な推論が可能になります。

この章では、霊長類の乳データにおけるネオコルテックスの欠損値の例を用いて、**完全ケース分析（complete case analysis）**（欠損値のあるケースを単に削除する）と比較して、**ベイズ帰属**がどのように情報損失を防ぎ、より堅牢な推定を提供するかを示します。

#### Rethinking: Generative thinking, Bayesian inference.（生成思考、ベイズ推論）
**ベイズモデルは生成的であり、パラメータを推定するのと同じくらい、観測をシミュレートするのにも使用できます**。この事実の利点の一つは、データがどのように生じたかを深く考えることで統計モデルを開発できることです。これには、私たちが研究しているプロセスの性質だけでなく、サンプリングや測定も含まれます。そして、ベイズ更新にその影響を発見させましょう。これらの影響には、データから生成プロセスを推測できないことも含まれるかもしれません。ベイズは誠実なパートナーです。あなたの感情を傷つけることを恐れません。

#### Rethinking: Missing data are meaningful data.（欠損データは意味のあるデータ）
変数が観測されていないという事実は、それでも観測です。それはデータであり、非常に特殊な値を持つだけです。この値の意味は文脈によって異なります。例えば、個人所得に関するアンケートを考えてみましょう。もし一部の人が所得を記入することを拒否した場合、これは低所得（または高所得）と関連している可能性があります。したがって、欠損値を予測しようとするモデルは、啓発的である可能性があります。生態学では、ある種の観測がないことは、微妙な種類の観測です。それは、その種がそこにいないことを意味するかもしれません。あるいは、そこにいるが、あなたが見なかったことを意味するかもしれません。この二重性を考慮に入れるために、**占有モデル（occupancy models）**というモデルのカテゴリ全体が存在します。**欠損値は常に何らかのプロセスによって生成され、そのプロセスについて考えることで、大きな問題を解決できることがあります**。

#### Rethinking: Naming completely at random.（完全にランダムという命名）
統計用語は非常に混乱を招くことがあります。この分野は、通常の言葉を非常に専門的な方法で使用します。**尤度、有意、信頼**といった言葉の日常的な意味は、統計的な定義とはほとんど似ていません。**欠損データ**のトピックも同様です。犬の宿題のシナリオ（図15.4）は、時々、**「完全にランダムに欠損（MCAR）」、**「ランダムに欠損（MAR）」、そして驚くほど不条理な**「ランダムに欠損していない（MNAR）」**という役に立たない名前で呼ばれることがあります。ランダムと完全にランダムの間の意味的な違いは、ほとんどの人にとって重要ではありません。誰もこれらの用語を好きではありませんが、それでも使用されているのを目にするでしょう。これらの用語を覚えるのが簡単だったとしても、欠損データをどのように扱うかを決定するのに十分ではありません。シナリオ（b）と（c）の違いが示すようにです。**分類については心配しないでください。因果モデルをスケッチし、次の行動を考えましょう**。

#### Rethinking: Multiple imputations.（多重帰属）
**欠損データ帰属**には複雑な歴史があります。多くの種類の帰属があり、それらのほとんどは確率論に強力な基礎を持たないアドホックな方法です。ホットデッキ帰属、コールドデッキ帰属、平均代入、確率的帰属などです。これらの手順は今日ではどれも尊敬されていません。一般的な非ベイズ手順に**多重帰属（multiple imputation）**があります。多重帰属はアンケートの無回答の文脈で開発され、実際にはベイズ的な正当化を持っています。しかし、デスクトップでのベイズ帰属が非実用的だった時代に発明されたため、「ランダムに欠損」という欠損モデルに対する完全なベイズ解を近似しようとします。もし不完全なケースを削除するのに抵抗があるなら、多重帰属を使用するのにも抵抗があるべきです。この手順は、欠損値の近似的な事後分布から複数のサンプルを抽出し、これらのサンプルで別々の分析を実行し、その後、完全なベイズ帰属を近似する方法で分析を結合します。多重帰属は完全なベイズ帰属よりも限定的であるため、現在は実際のベイズ帰属を使用しています。しかし、多くの非ベイズ分析では依然として多重帰属が使用されています。**頻度主義統計は、推定値をどのように生成するかという理論ではなく、単にそれらをどのように評価するかという理論であることを覚えておいてください**。

---

### 第16章：一般化線形モデルの狂気

第16章では、従来の**一般化線形モデル（GLMs）**の限界を超え、**科学的文脈**が**統計モデル**に命を吹き込む「特注（bespoke）」モデルの構築に焦点を当てます。著者は、GLMを「天動説的な装置」と呼び、それらが相関関係を記述するのに優れている一方で、真の因果メカニズムや科学的知識を直接組み込むには不十分であると指摘します。

この章では、3つの具体的な例を通して、**科学的知識に基づいた生成モデル**を設計し、それを統計推定に変換する戦略が示されます。

1.  **幾何学的な人間（Geometric people）**：身長と体重の生物学的な関係を、人が円筒形であるという**「球形牛（spherical cow）」**のような簡略化された仮定（比喩的な表現）を用いてモデル化します。このアプローチは、パラメータに物理的な意味を持たせることで、より**情報量の多い事前分布**を設定し、データの限界がある場合でも有用な推定を可能にします。
2.  **隠れた戦略の子供たち（Children with hidden strategies）**：子供たちが集団の大多数の選択をコピーする行動の裏にある、未観測の異なる学習戦略をモデル化します。これは、行動と戦略を混同しないようにする**隠れた状態モデル（hidden state models）**の一例です。
3.  **個体群動態（Population dynamics）**：ロトカ・ヴォルテラモデルを用いて、捕食者と被食者（例：オオカミとウサギ）の個体群の動態をモデル化します。この例では、**測定誤差**や**欠損データ**を考慮に入れながら、動的システムをベイズ的な枠組みで推定する方法が示されます。

これらの例を通じて、著者は、科学的に導かれたモデルが、パラメータに明確な意味を与えることで、**事前分布**の選択をより適切に行えるようになること、そして、**過剰適合**を防ぎ、より洞察に富んだ推論を可能にするという利点を強調しています。また、**autoregressive models**が予測には有用であるかもしれないが、因果的な解釈には適さない場合が多いと批判されています。

#### Rethinking: Bespoken for.（特注の）
大量生産にはいくつかの利点がありますが、私たちの服をひどくフィットさせることにもつながります。既製の衣服は、あなたのために、特定の体型を持つ特定の人のために作られたものではありません。それらは**特注品（bespoke products）**ではありません。完璧に平均的な体型を持っている幸運な人でない限り、より良いフィットを得るためには仕立て屋が必要です。

統計分析も似ています。**一般化線形モデル**は既製品であり、多様な目標を持つせっかちな研究者の消費者市場のために大量生産されています。科学界は統計学者に、どこでも使えるツールを求めました。そして、彼らはそれを提供しました。しかし、常に服が体に合うわけではありません。

既製のモデルの問題の一つは、**専門知識を阻害する**ことです。典型的な研究者は、自分の主題について多くの知識を持っています。他の専門分野の誰かが自分の主題について理論モデルを構築しようとすると、科学者が詳細な反論をするのがその証拠です。しかし、その後、その科学者たちが自分たちのデータを分析しようとすると、その知識の使用を禁じるツールを使用します。標準的なGLMでは、それを組み込む方法がありません。さらに悪いことに、研究者がGLM（またはGLMM）しか教えられない場合、これらのモデルが、情報に基づいた特注の科学モデルの形成を阻害してしまう可能性があります。

**GLMは不合理なほど強力です**。しかし、それらが通常は**天動説的な装置**に過ぎないことを覚えておくべきです。より良い特注モデルは、より良い適合とより良い推論の両方のために、最終的には必要となります。

#### Rethinking: Spherical cows.（球形の牛）
有用な数学的モデリングには、通常、**とんでもない仮定**が伴います。例えば、人間が円筒形をしているという上記の仮定です。この種の仮定は、**「球形牛（spherical cow）」**と呼ばれます。**戦略的な、単純化された仮定は、すべての有用なモデルの特徴です**。まず単純化されたモデルを理解することで、後に、単純なモデルの欠点がどの詳細が関連しているかを決定するのに役立つ場合に、関連する詳細を追加するのが容易になります。非数学的モデルも単純化ですが、通常、その単純化は明示されていません。そのため、それらの欠点を特定するのがより困難になります。

#### Rethinking: Priors are never arbitrary.（事前分布は決して恣意的ではない）
**ベイズが恣意的であるという恐ろしい主張をよく耳にします**。統計学は事前分布が恣意的であるため信頼できないと。人々が事前分布をそのように扱うことがあるのは事実です。しかし、**事前分布は、科学者が領域知識を無視する場合にのみ恣意的になります**。GLMに固執する場合でも、**事前予測シミュレーション**は、有用で恣意的ではない事前分布を作成するために背景知識と向き合うことを私たちに強制します。より科学的に根拠のあるモデルを持つ場合、パラメータはさらに意味を持ちます。円筒形の例のpとkパラメータには、物理的に測定することもできる**事前分布**を割り当てられる科学的な意味があります。この例で、無知に対する形而上学的コミットメントから、**一様平坦事前分布**を使用することは間違いでしょう。

---

### 第17章：ホロスコープ

第17章は、科学における**統計的推論**の役割をより広範な科学的実践の文脈に位置づけ、科学的発見の**「失敗と愚行」**、特に再現性の問題に焦点を当てます。著者は、「ランセット」編集長のリチャード・ホートンによる「科学文献の多く、おそらく半分は単純に真実ではないかもしれない」という指摘を引用し、**小さなサンプルサイズ、わずかな効果、無効な探索的分析、利益相反、流行の追求**がその原因であると述べています。

この章では、科学を**「変動と選択的保持の集団レベルのプロセス」**として捉える見方が提示されます。これは、個々の仮説ではなく、仮説の集団レベルで機能するという考え方です。**統計分析は科学全体のプロセスの一部に過ぎず、その成功や失敗、愚行のすべてを統計分析だけに帰することはできないと強調されます**。

また、この章では、統計学が数学とどのように異なるかについての興味深い比喩が提示されます。「統計学と数学の関係は、料理と化学の関係に近い」というテリー・スピードの言葉を引用し、統計学がその基礎となる数学から十分に抽象化されており、**実践の多くは文脈や人間の心理、文化といった要因に依存する**と説明します。

#### Rethinking: Statistics is to math as cooking is to chemistry.（統計学は数学にとって、料理が化学にとってであるように）
**「統計学は数学にとって、料理が化学にとってであるように、それほど近くはない」**とテリー・スピードは述べました。これは、それぞれの分野が別の分野に基礎を置いているにもかかわらず、それぞれの分野がその基礎から十分に抽象化されており、その実践のほとんどが他の要因に依存していることを意味します。料理では、抽象的なヒューリスティクスがそれらを説明する化学法則よりも有用であり、人間の心理や文化が支配的になることがあります。**統計学では、文脈が王様です**。一般的な数学的考察は常に重要ですが、数学的基礎は、研究の文脈で私たちが直面する偶発的な問題のほとんど、またはすべてを解決するわけではありません。

---

以上が、マクエルリース著「統計的再考 第2版」における主要な概念と、「Rethinking」および「Overthinking」のコラムの詳細な要約です。本書が統計的推論への思考方法を深く「再考」することを促し、読者がより堅牢で洞察に富むモデルを構築できるようになることを願っています。