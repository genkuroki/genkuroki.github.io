この音声概要では、サンダー・グリーンランド教授が執筆した疫学ハンドブック第3版からの抜粋「統計的手法：基本概念、解釈、および注意点」の内容を、冒頭から詳細にわたってご紹介します。この章は、統計的手法の利用において、その基本概念から生じる誤解や問題点に焦点を当て、より適切で堅実な解釈方法を提唱するものです。

この章の目的は、関連性の研究とその因果的説明という、分野を超えて方法論が大きく異なる中心的な研究活動において、統計的手法の基礎が著しく多様であり、論争の的となっているという現状を認識することです。教科書や学術誌のガイドラインでは、採用されている規範が議論の余地のないものであるかのように書かれていることが多く、この多様性や論争はしばしば隠蔽されています。さらに、人間の限界や専門分野の広大さを考えると、誰もがすべてのサブフィールドで専門知識を持つことは不可能であり、特にヒト集団の研究においては、解釈が研究の限界によって厳しく制約されます。

この章では、このような問題を最初から認識する統計的手法へのアプローチを概説しています。これは、「統計的有意性」や「信頼性」といった統計的検定や区間推定に通常付随する主張のように、問題が存在しないと仮定するのではなく、問題を正面から捉えるものです。具体的には、モデルと統計量をデータ記述に基づいて構築し、それらからの推論を、分析データを用いて完全に検証またはチェックできない仮定に基づく**憶測**として扱うことを提案しています。

この章で扱われる主要なキーワードには、**バイアス、因果推論、適合性、信頼区間、P値、統計的推論、統計的情報、統計的有意性、統計的検定**が含まれます。

それでは、各セクションについて詳しく見ていきましょう。

---

### **1. 序論：従来の統計手法の根本的な問題点**

まず、従来の統計的手法が抱える根本的な問題点から説明を始めます。

従来の統計手法は、いくつかの**理想的な前提**の上に成り立っています。具体的には、測定された共変量レベル内で、データが**純粋な無作為抽出**による調査から得られたものであること、または、研究者が分析に参加した人々や彼らがどのように扱われたかについて完全に制御し理解している、**純粋な無作為な治療割り当て**による実験から得られたものであること を仮定しています。これらの仮定が満たされるのは、論理的に健全な推論が可能な**理想的なケース**においてのみです。

しかし、現実の世界、特に私たちの実際の不完全な応用では、これらの理想的な前提が満たされることはめったにありません。例えば、調査への実際の参加や治療への割り当てが無作為ではない場合でも、これらの手法は広く適用され、誤って解釈されています。研究の限界に関する議論では、これらの問題が部分的にしか考慮されていないことが多いと指摘されています。場合によっては、データの生成における非無作為な（系統的な）側面について、**憶測的なモデル**を用いてさらに分析されることもあります。

本章は、読者が基本的な統計手法の紹介を受けていることを前提としています。そして、これらの手法を、研究のコンテキストや統計を**日常言語で記述**することに基づいて、前述の根本的な問題を直接的に認識する方法で再解釈する方法を示します。これは、通常誤解されている「統計的有意性」や「信頼性」といった専門用語が、**研究に制御不能な問題がないことを暗黙のうちに仮定している**ことに対立するものです。章は、データの記述から始まり、なぜ研究データがそのように現れたのかを説明するのに役立つ文脈的要因を明確にしていきます。これには、選択、治療、測定、項目欠損、または観察からの喪失（打ち切り）に影響を与える可能性のある要因や共変量が含まれます。このような共変量情報がなければ、統計的な出力は**単なるデータ要約**としてしか解釈できないと述べられています。

この導入部分だけでも、従来の統計学が持つ限界と、それに対する筆者の問題意識が強く伝わってきます。特に、現実の研究における複雑性や不完全性を、統計モデルが単純化しすぎているという批判は、この章全体の基盤となっています。

---

### **2. 文脈的記述と統計的定式化**

統計的手法を正しく活用するためには、研究者がその手法を用いて答えようとする問いを、**明確な文脈的記述**として、**日常言語で表現する**ことが不可欠であると強調されています。これは、非専門家（例えば、「この治療法は血圧にどれくらい影響するだろうか？」といった問いに関心を持つ一般の人々）にとっても、その質問が明確に理解できるような形であるべきです。

こうした一般的な質問は、次に、研究対象となった具体的な人物や、より精密な数量へと**翻訳**されなければなりません。例えば、「この治療法は、研究に参加した患者の平均的な拡張期および収縮期血圧をどれくらい変化させたのか？」といった具体的な問いです。さらに、研究参加者の選択と継続に関する**プロトコルの詳細な記述**も必要です。これには、研究に選ばれた人々の情報だけでなく、参加を拒否した人々や、募集後に追跡不能になった人々について分かっていることも含めるべきです。

しかし、統計的手法の数学的な側面には、**実用上の限界**が伴います。これらの数学は、通常、**人工的で過剰に単純化**されており、研究の実際の実施、分析、そしてその対象に関する重要な詳細を省略してしまう傾向があります。この単純化は、**過度に自信過剰な結果**を生み出す原因となると指摘されています。たとえば、多くの統計的手法は平均的な結果に焦点を当てますが、このアプローチは、治療が一部の患者には利益をもたらし、他の患者には害を及ぼすような状況を**不明瞭にしてしまう**可能性があります。また、研究に参加しなかった人々の効果を**誤って表現する**ことにもつながりかねません。

このような統計結果は、**不適切な一般化**を招く危険性があります。例えば、「この治療法は、研究に参加した人々の平均的な反応を改善した」という正確な報告が、誤って「この治療法は有益であることが証明された」という**無条件の声明**として伝えられることがあります。

統計的手法の**避けられない過剰単純化**を考慮すると、それらを安全に利用するためには、その出力結果を、**理想的なケースでの推論のためのガイドライン**として扱うべきであり、文脈的な質問に対する**「正解」として扱ってはならない**と強く推奨されています。

結果の**感度**（特定の仮定や方法の変化によって結果がどれだけ影響を受けるか）に部分的に対処するために、**異なる統計的手法を並行して使用し、その結果を比較検討し、統合することで、推論と意思決定を改善する**ことができます。これは、統計学者間の様々な学派（例えば、**頻度論者とベイズ主義者**）がそれぞれ独自の手法を持っていることと関連付けられています。しかし、どちらの学派の手法も、通常提示されるような**推論や決定のための「ルール」**としてではなく、**データと元の文脈的な質問との関係についての異なる視点**として扱うべきであり、最終的には**証拠の統合**、すなわち**「三角測量」（triangulation）**へと統合されるべきだと提案されています。

統計的手法を、**非公式な文脈的推論の中に subsume する**（含める、従属させる）という助言の歴史は長く、例えば Skellam (1969), DeFinetti (1975), Box (1990) などが挙げられています。しかし、従来のメソドロジーは、これらの懸念を脇に置き、**広範な単純化された仮定に基づいて推論を強制する**計算手法の開発に焦点を当てています。これらの仮定は、文脈的な記述に正確に翻訳すると、**非現実的に見える**ことがあります。

さらに問題を複雑にしているのは、多くの分析選択が従来の手法では具体的に指定されておらず、**研究チームや彼らが従う権威に委ねられている**点です。これは、カテゴリ境界の設定方法やモデルの構築方法など、研究者が多くの選択肢を持つ**「分岐する小道の庭」（garden of forking paths）**、すなわち**研究者の自由度（researcher degrees of freedom）の高さ**につながります。これらの非公式な選択は研究間で大きく異なり、結果を大きく左右する可能性があります。さらに悪いことに、これらの選択は、調査者が**期待する、あるいは望む結果を支持するように、意図的または無意識的に導かれる**ことさえあります。

このような研究の現実は、ほとんどの統計的手法によって無視されています。これらの手法は、すべてのステップがプログラム可能で、生のデータをコンピュータに入力するだけで分析全体が実行され、無限の精度で再現できるほど、**明確に定義され、詳細なプロトコルが事前に設定されている**と仮定しています。たとえこれが実行されたとしても、異なる研究チームはそれぞれの方法論的訓練に基づいて異なるプログラムを使用するでしょうし、統一されたプロトコルを強制することが、そのプロトコルの欠陥を見過ごすことにつながるだけではないか、という疑問も投げかけられています。

前述の問題を踏まえ、最近の研究では、**同じデータセットを異なる資格のある研究チームに与える**という試みが行われています。その結果、予想通り、異なるチームからの結果は大きく異なり、時には**矛盾する結論**に達することさえありました。このことから、以下の二つの結論が導かれます:
*   統計的な提示は、**データが示していること**として解釈されるべきではなく、むしろ**アナリストが彼らの好むデータへのアプローチに基づいてデータが示していると主張すること**として解釈されるべきである。
*   他の合理的なアナリストは、**同等に弁護可能なアプローチ**を用いて、**全く異なる結論**に到達する可能性がある。

このセクションは、統計手法が現実世界の複雑さを単純化する中で生じる限界と、その単純化が結果の解釈にどのように誤解を生み出すかについて深く掘り下げています。特に「分岐する小道の庭」という概念は、研究者の恣意的な選択が結果に与える影響の大きさを強調しており、統計的結果を鵜呑みにすることの危険性を警告しています。

---

### **3. 統計的手法の架空の世界と過剰単純化**

前述の注意点を心に留めながら、私たちはそれぞれの統計分析を、**単純化された仮定によって厳しく制限された架空の「小さな世界」または「おもちゃの例」における思考実験**として捉えることができます。研究を動機付けた質問は、この架空の世界に適切に翻訳される必要があります。統計的手法は、これらの仮定から数学的な演繹によって、その質問に答えることになります。

しかし、その答えは、**すべての仮定が成立する架空の世界においてのみ、論理的な強制力をもって適用される**のです。したがって、重要な仮定が設計や状況によって完全に強制されていない場合、その答えが現実とどれほどよく対応しているかを判断することが、**極めて重要な課題**となります。

一般的な工学用語では、この仮定の集合全体を**モデル**と呼ぶことがあり、この章でもその略語が使用されます。これは、統計学におけるモデルの狭い用法（通常は、ある測定変数を他の測定変数と未測定の**ランダム誤差（ノイズ）変数**の関数として表す方程式）とは異なります。この方程式は、多くの仮定を代数的に操作しやすい形で要約しますが、その形式は非常にコンパクトで抽象的であるため、**研究者によって最も重要な仮定の一部が見過ごされがち**です。

モデルから得られた答えは、たとえモデルの仮定が不正確であっても、研究が対象とする現実に関する**有用な洞察やヒント**を提供することはあります。しかし、モデルに基づく結論を、あたかも**現実世界に直接適用されるかのように扱う**のは、よくある**誤謬**です。これは、統計的な**フィクションを現実と混同する**ことの例であり、時には**「モデルの現実との混同」（model reification）**と呼ばれます。そして、その結果は、通常、**その現実に関する推論がひどく過剰に自信過剰になる**ことです。

このセクションは、統計モデルが「現実の忠実な写し」ではなく、特定の目的のために「現実を単純化したもの」であるという重要な視点を提供しています。モデルの仮定を理解し、その限界を認識することなしには、誤った結論を導き出してしまう危険性があることを強調しています。特に、「モデルの現実との混同」という概念は、統計的結果を解釈する上で常に意識すべきポイントと言えるでしょう。

---

### **4. 関連性モデルと因果分析：記述と因果の違い**

統計モデルは、変数間の関係を記述する際に、大きく分けて**記述的（関連性）モデル**と**因果モデル**に分類されます。

まず、**関連性モデル（associational models）**は、単に変数間の関係がどのように存在するかを示します。これには、変数間の時間的な順序や、一方が他方の原因であるという因果関係は含まれません。

これに対し、**縦断的モデル（longitudinal models）**は、変数の時間的な順序を示しますが、これをもって必ずしも因果関係を示すものではありません。

そして、**因果モデル（causal models）**は、異なる介入や決定がどのように異なる結果をもたらすのか、そして関連性がどのように因果経路によって決定されるのかを示します。因果モデルは、真の因果関係を理解し、将来の介入の効果を予測するために不可欠です。

関連性モデルが最も正当化されるのは、**統計調査**においてであり、その目的が、ターゲット母集団の特性について推論を行うことであり、変数間の因果関係を研究することではない場合です。例えば、大麻使用に関する調査などがこれに該当します。しかし、たとえ記述目的であっても、調査参加者を超えて、その参加者が抽出された母集団について推論を行う場合には、**因果的仮定が必要**になります。これらの仮定は、しばしば明示的にラベル付けされたり、認識されたりすることさえありません。

統計的手法がサンプルを超えて推論を行うための**主要な仮定**は、**母集団からの無作為抽出**です。これは、乱数生成器が母集団からの選択に使用された場合を除き、分析への参加の原因が存在しないという仮定です。例えば、大麻の例で言えば、最終的な600人が分析に含まれるのは、その人だけが分析に選択された場合です。もし、このような無作為抽出が実際に行われていない場合、あるいは拒否率や無回答率が高い場合、推論は、選択を予測する変数の正確かつ完全な測定と、それらによる**調整（adjustment）**に依存します。つまり、私たちは、選択の原因を考慮に入れることを試みる必要があるのです。

しかし、たとえ無作為抽出が行われたとしても、関連性モデルからの統計的推論は、**あくまで関連性のみ**を指し、**原因と結果は指しません**。それらから因果的推論を行うには、**データを超えた考慮事項**が必要です。因果モデルがより一般的になりつつあるものの、ほとんどの統計分析は、因果推論が目標である場合でも、依然として関連性モデルを中心に構築されています。この慣行は、ユーザーが因果推論に必要な**追加の仮定**、例えば因果図で示されるような仮定を**明示し、批判する**ことに注意を払う場合にのみ、安全に行うことができます。

このセクションは、単なる「関連性」と「因果性」の区別が、統計的推論においていかに重要であるかを明確にしています。特に、無作為抽出が理想的な仮定であり、それが満たされない場合にどのような問題が生じるか、そして因果推論にはデータだけでは不十分であり、追加の仮定と批判的思考が不可欠であることを強調しています。

---

### **5. 統計的過剰単純化の仮想例：大麻使用と精神衛生**

医療アドバイスや健康政策にとって喫緊の課題として、「**大麻使用が精神衛生にどのような影響を与えるか？**」という問いが挙げられます。この問いに関して、いくつかの重要な点が指摘されています。

1.  **関心の中心は因果的であること**。つまり、「大麻使用が精神衛生の問題を引き起こすのか？」という問いであり、単に「大麻使用者と非使用者の間に精神衛生の問題の関連性があるのか？」という問いではありません。
2.  最も直接的に関連する長期データは**観察研究**によるものとなるでしょう。なぜなら、大麻使用に関する長期的な無作為化比較試験は存在せず、倫理的・実用的な観点から実行不可能だからです。
3.  この問いが対象とする**因果変数（通常「曝露」または「治療」と呼ばれる）は「大麻使用」**です。しかし、「大麻使用」とは非常に複雑な概念であり、様々な可能性を含んでいます。例えば、ごくたまにの使用から毎日の継続的な使用まで、喫煙からベイピング、摂取まで、低効力から高効力な源まで、狭い範囲から広い範囲のカンナビノイド混合物まで、そして高純度から農薬、真菌毒素、化学残留物、未表示の精神作用性混入物でひどく汚染された源まで、多岐にわたります。
4.  大麻使用のあらゆる側面は、**時間とともに、しばしば劇的に変動**し、年齢や地域の法律といった変数と強く関連します。

さらに、**精神医学的診断**もまた、アモチベーション症候群や社会的引きこもりから、明らかな認知障害や精神病に至るまで、**複雑な精神状態と行動の集合体**です。

このような現実の複雑性を背景に、基本的な統計分析で行われる典型的な単純化を説明するために、「表1」として、自己申告による大麻使用（X：0がなし、0より大が一部あり）と、その後の深刻な精神医学的診断（Y：0がなし、1が該当）の架空の2x2分割表が提示されています。この単純化の最たるものは、使用カテゴリと診断カテゴリをそれぞれ**二項指標XとYに集約している**ことです。

このような集約（**情報の粗粒化**）は、統計的変動を減らし、提示を単純化するためによく行われます。しかし、これは**誤解を招く**可能性があります。なぜなら、研究対象となっている関係における**重要な詳細やバリエーションを隠してしまう**可能性があるからです。分析は、多次元表や多重回帰を用いて、これらの詳細をさらに探求すべきであると提案されています。ただし、これらの方法を用いる際にも、**相関係数、「説明された分散」、そして「標準化された」係数**は、関心のある効果と無関係な研究の特徴を混同してしまうため、注意が必要です。

また、**制御されていない統計的バイアスの発生源**を分析することも推奨されています。これらの発生源を無視する統計分析は、データ生成プロセスによって生み出された測定値間の**関連性に関する推論のみを提供**すると見なされるべきであり、それらの測定値は、関心のある効果と制御されていないバイアス源の混合物を表しています。

**表1：自己申告による月間大麻使用量と精神医学的診断のクロス集計**

| Xカテゴリ:        | X = 0 (なし) | X > 0 (あり) | 合計 |
| :---------------- | :----------- | :----------- | :--- |
| **診断された (Y = 1):** |              |              |      |
| 観測値            | 16           | 10           | 26   |
| H0（独立性）下での期待値 | 20.8         | 5.2          | 26   |
| **診断なし (Y = 0):** |              |              |      |
| 観測値            | 464          | 110          | 574  |
| H0（独立性）下での期待値 | 459.2        | 114.8        | 574  |
| **合計**          | 480          | 120          | 600  |
| **診断割合**        | 16/480 = 0.033 | 10/120 = 0.083 | 26/600 = 0.043 |
| **診断パーセント**    | 3.3%         | 8.3%         | 4.3% |
| H0下での期待パーセント | 4.3%         | 4.3%         | 4.3% |
| **リスク差 RD**     | 0            | 0.050        |      |
| **リスク比 RR**     | 1            | 2.5          |      |
| **オッズ比 OR**     | 1            | 2.6          |      |


この2x2分割表が示す**極端な文脈的単純化**にもかかわらず、このような提示は依然として一般的であり、統計的手法の基本的な概念、方法、解釈、そして従来の利用における誤解を説明するのに役立ちます。堅実な分析は、データの単純な記述から始まります。

表1において、調査で**使用を報告した人々の間で診断された割合は0.083（8.3%）**であり、**使用を報告しなかった人々の間では0.033（3.3%）**です。これに対応する診断のオッズは、それぞれ0.083/(1-0.083) = 0.0909 と 0.033/(1-0.033) = 0.0345 となります。

これらの値から、以下の関連性指標が算出されます:
*   **リスク差 (RD)**: 0.083 - 0.033 = **0.050 または 5%**。
*   **リスク比 (RR)**: 0.083 / 0.033 = **2.5**。
*   **オッズ比 (OR)**: 0.0909 / 0.0345 = **2.6**。

これらの「診断割合」である0.083と0.033は、二項指標Yの平均値であるため、リスク差（RD）はX群間のYの平均値の差に相当します。

しかし、これらの関連性指標は、**実際の使用効果と、選択的な調査参加、使用への自己選択、そして使用と診断の誤報告または誤コーディングによるバイアスが混ざり合ったもの**を表している点に注意が必要です。

表1は、いずれの指標で見ても、使用とリスクとの間に**関連性があること**を示しています。この関連性が「ヘビーユーザー」における診断に起因するかどうかを検討するには、例えば「月に4回以下」と「月に4回以上」というように、より軽い使用とより重い使用を比較する2x2分類を検証することも考えられます。

しかし、**すべての基本的な統計手法は、分析が事前に指定されたものであることを前提としています**。つまり、分析の選択が、それらが生成する結果に関係なく行われたと仮定しているのです。関連性を**最大化する**ように変数や統計量を選択すると、**推定値が大きくなりすぎ、P値が小さくなりすぎる**結果を生みます。逆に、関連性を**最小化する**ように選択すると、**推定値が小さくなりすぎ、P値が大きすぎる**結果を生みます。いずれの場合も、結果として得られる**区間推定値は狭すぎ**、したがって結果に関する適切な不確実性のレベルを**過小評価してしまう**ことになります。

このセクションは、大麻使用と精神衛生の例を通して、現実の複雑な現象を統計的に分析する際に、いかに多くの単純化が行われ、それが結果の解釈にどのような問題をもたらすかを具体的に示しています。特に、分析者の選択が結果に与える影響の大きさ、そしてそれが推定値の偏りやP値の歪みにつながる可能性を指摘しており、統計的結果を鵜呑みにせず、その背後にある仮定や選択を批判的に検討することの重要性を浮き彫りにしています。

---

### **6. P値、統計的検定、および区間推定**

P値、統計的有意性検定、そしてそれに関連する区間推定値（通常「信頼区間」と呼ばれるもの）に関する理論と用語は非常に混乱しており、その結果、これらは**科学史上最も誤解され、誤って教えられ、誤用されている手法である可能性**があります。調査によると、ほとんどのユーザーがこれらの概念のいずれも正しく定義または解釈できず、多くの入門書が誤った記述をしていることが示されています。たとえ技術的に正しい定義を与えている文章であっても、これらの手法が、ヒト集団に関する研究ではしばしば**あり得ない仮定**に依存していることを強調しないことがよくあります。したがって、この章では、これらの適切な使用と解釈を促すための枠組みと言語を提供します。

#### **6.1. 調査における選択**

まず、より大規模な対象母集団の特性について推論することを目的とした調査を考えます。この調査では、各人について一連の共変量が測定されます。統計調査法の**中心的な仮定**は、**選択が条件付きで無作為であること**、またはそれに機能的に等価な仮定です。これは、母集団内のすべての人について、最終的な分析に含まれる可能性が既知であるか、少なくとも比例定数まで**偏りなく推定できる**ことを意味します。この仮定は、研究への人の選択と、その人のデータが分析に含まれる結果となるその後の事象の両方に言及します。したがって、大麻の例では、分析に選択されたことを示す指標SがS=1となるのは、最終的に分析に含まれた600人についてのみです。

例えば、対象者が健康維持機構（HMO）の母集団から無作為に抽出された1,000人のサンプルであったとします。しかし、最終的に分析に含まれた600人が、招待された1,000人や、母集団全体から無作為に抽出されたサンプルであると考えるのは、**非常に信じがたい**ことです。また、分析への含まれる確率が、HMOデータベースで利用可能な共変量から偏りなく推定できると考えるのも困難です。したがって、大麻使用に関する通常の統計的推論は、**招待された場合に使用可能なデータを提供したであろうHMO集団内の人々に限定される**ことになります。この制約は、「推論は、分析データ内の人物と**交換可能な（exchangeable）**人々に限定される」と要約されることがあります。このような交換可能な人々の仮想的な集合は、**データのソース母集団（source population）**と呼ばれることがあります。残念ながら、このソース母集団の形態と元の対象母集団との関係を完全に特定できるのは、測定された共変量が参加を正確に予測できる場合に限られます。

#### **6.2. 因果関係の実験的研究**

次に、異なる治療選択がその後の健康結果に与える影響について推論することを目的とした実験を考えます。実験者はまず、実験者によって治療が割り当てられ、実験者によって結果と関連する共変量が得られることに同意した人々からなる**研究母集団**を募集しなければなりません。募集された母集団は非常に選択的であるため（例えば、年齢や健康上の制限のため）、一部の方法論者は、この募集された母集団を因果推論の対象として扱います。

治療効果を推定するための統計的手法の**中心的な仮定**は、**治療割り当てが条件付きで無作為である**、またはそれに機能的に等価な仮定です。これは、実験のすべての人について、特定の治療に割り当てられる可能性が既知であるか、既知の情報（例えば、測定された前治療共変量に対する回帰分析によって）から**偏りなく推定できる**ことを意味します。この要件は、**「条件付き交換可能性」（conditional exchangeability）**または**「治療割り当ての条件付き無視可能性」（conditional ignorability of treatment assignment）**、あるいは**「測定されていない交絡因子がない」（no unmeasured confounding）**と呼ばれることがあります。

しかし、たとえ割り当てが条件付きで無作為であったとしても、実験母集団を超えた治療効果に関する通常の統計的推論は、**募集と維持に必要なすべての条件を満たし、識別され、同意したであろう人々に限定されます**。この限界もまた、「統計的推論は、分析データ内の人物と交換可能な人々に限定される」と要約されます。募集制限は、実験者によって測定された共変量（年齢や病歴など）に基づいて課されるため、これらの制限を満たす人々を特定することはできます。しかし、調査のケースと同様に、測定された共変量が参加を正確に予測できる場合にのみ、交換可能な母集団を完全に特定できます。さらに、この母集団の構成、したがってそこでの治療効果は、**実用的に関心のある母集団とは大きく異なる可能性**があります。現代の文献では、実験からの因果推論の一般化に関するこの問題は、**「転送可能性」（transportability）**というトピックの下で扱われます。

調査と実験の無作為化に関する仮定には論理的な類似性があり、調査分析の特定の手法が実験にも適用できます。各治療群を、募集された実験母集団からのサンプルと考えることができ、各サンプルは他のサンプルとは異なる治療を受けることになります。この意味で、各治療群は、募集された人々で構成される小さな列挙された母集団からのサンプルであり、治療が無作為化されている場合、各群はその母集団からの無作為サンプルになります。調査との違いは、実験ではすべての母集団メンバーがいずれかのサンプルに含まれ、治療を割り当てられるという点です。

調査と同様に、実験でも募集後に追跡不能になるなどして、結果が不明になる**脱落（attrition）**がしばしば発生します。この場合、その結果は**「打ち切り」（censored）**されたと言われます。また、追跡は継続されているものの、割り当てられた治療を中止する（例えば、負担が大きい、不快な副作用があるなど）人もおり、この場合は**「非遵守」（non-adherent）**であると言われます。標準的な手法では、これらの人々を分析に含めることがありますが、その際には**「条件付き無作為打ち切り」（conditionally random censoring）**という仮定が置かれます。これは、分析に参加するすべての人について、打ち切りや非遵守の可能性が、彼らについて知られている情報（共変量）から既知であるか、少なくとも比例定数まで偏りなく推定できるという仮定です。これらの手法の仮定と分析の詳細は、非常に複雑になることがあります。

#### **6.3. 非実験的（観察）研究における因果関係**

多くの重要な問いに対して、ヒトを対象とした実験は、**非現実的、非倫理的**、またはその両方です。例えば、大麻使用が健康に与える影響に関して、長期間にわたって割り当てられた使用レベルに従うことに同意する人は少なく、そのような実験は承認されないでしょう。それでも、研究の必要性は議論の余地がありません。

そこで喫緊の問いは、「**純粋な観察研究から何を学ぶことができるのか？**」というものです。その答えは、**研究デザイン、測定の正確性、および分析方法**に決定的に依存し、これらによって測定された共変量から対象とする曝露と結果をどれだけ正確に予測できるかが決まります。観測された関連性に影響を与え、研究対象のパラメータの推定値を歪める可能性のある要因をモデル化することに基づき、これらの問題に対処するための多くの特殊な方法が開発されてきました。

これらのバイアス源には、**交絡因子（confounders）、分析のための非無作為選択、非無作為欠測データ、測定誤差と分類誤差、データの粗粒化、データの疎密、不正確な調整**が含まれます。

バイアス源の特定は、特に無作為化が行われておらず、その問題に対処するための利用可能なデータが不十分な場合に、**妥当な分析と解釈の中心**となります。**因果図（causal diagrams）**は、バイアス源を認識する上で特に役立ちます。一方、**制御不能なバイアスの大きさ**は、仮定への推論の感度分析やバイアス分析によって対処できます。

表1の例では、使用が精神医学的結果に与える影響を超えて、見かけの関連性に寄与した可能性のある多様な要因を想像すべきです。例えば、**調査前の医療状態（精神医学的なものを含む）**が、使用と精神医学的結果の両方に影響を与えたと予想すべきです。その結果、関連性の全部ではないにしても一部は、**先行する状態の効果と大麻の効果が混ざり合った「交絡」（confounding）**によるものである可能性があります。

その他の寄与する交絡因子には、年齢、他の薬物（娯楽用または医療用）およびアルコールの使用が含まれる可能性があります。正確に測定された交絡因子の交絡効果は、マッチング、層化、統計モデリングを含む膨大な種類の「交絡制御」方法によって**ブロックまたは除去（調整）できます**。しかし、年齢の正確な測定は簡単ですが、娯楽用薬物やアルコールについては困難または不可能である可能性があり、交絡因子の測定誤差は交絡制御方法の性能を低下させます。**測定されていない交絡因子**は、さらに解決が困難な問題をもたらします。

使用と、不参加（最初の拒否またはその後の情報提供の失敗）および精神医学的診断の両方との関連性は、別のバイアス源です。不参加と使用の関連性の一部は、両方に影響を与える共変量（例えば、年齢）によるものである可能性があります。この種の**選択バイアス（selection bias）**は交絡に類似しており、その共変量を制御すれば、その共変量の効果による関連性の成分が除去されます。残念ながら、大麻の効果が参加に影響を与えるような源から生じる選択バイアスは、**修復不可能**である可能性があります。

主要な研究変数（ここでは使用と結果）における**測定誤差**の影響は複雑であり、制御および分析することは極めて困難です。非常に古い経験則では、これらの誤差が**純粋に無作為**である場合、その影響は通常、観測された関連性を**減弱させる**とされています。しかし、変数間の誤差が相互に、また基礎となる変数と関連している場合（質問票項目では通常そうであるように）、この経験則は失敗します。例えば、報告された大麻使用の誤差は、基礎となる精神医学的状態と関連している可能性が高いため、この例ではこの経験則は正当化されないでしょう。

さらなる複雑化は、表1における**粗粒化**です。Xは、使用がどのように決定されるか、あるいはX>0という非常に広範なカテゴリ内でどのように分布しているかを指定しないため、治療指標ではありません。しかし、関連性は、この分布に敏感です。したがって、この関連性が別の母集団に適用されると期待すべきではありません。なぜなら、後者の母集団では、ユーザー間の使用の分布が大きく異なる可能性があるからです。さらに、大麻の効果が表1に見られる関連性に寄与したとしても、研究参加者間での使用の正確な分布に特有の場合を除いて、**使用と非使用の効果であるとは言えません**。因果推論の文献では、この問題は**「因果一貫性」（causal consistency）**というトピックの下で取り上げられています。

このセクションは、観察研究における因果推論の難しさと、その複雑性に起因する様々なバイアス源について具体的に解説しています。特に、測定誤差やデータの粗粒化といった、見過ごされがちな問題が結果に与える影響の大きさを強調しており、統計的結果を解釈する際に、これらのバイアス源を徹底的に検討することの重要性を示唆しています。

---

### **7. P値とその関連推定値および検定の基本理論**

P値の概念は1700年代初頭にまで遡ることができ、1800年代初頭にはその名称ではなかったものの一般的な統計的装置となりました。そして、「統計的に有意な」結果という概念は1880年代までに登場しました。20世紀初頭までに、「Pの値」や「P値」という用語が現れ、同じ概念に対して「有意水準」という用語も使われるようになりました。

ピアソン (1900) やフィッシャー (1934) の形では、P値は**データ生成プロセスの挙動に関するモデルや仮説と、データとの間の適合性、協調性、または一貫性の指標**です。例えば、大麻使用が精神医学的問題のリスクを高めるというモデルなどです。また、モデルとデータとの**適合度（goodness of fit）**を示すものとしても解釈できます。このタイプのP値は、0（完全に不適合または完全な不適合）から1（完全に適合または完全な適合）にスケールされます。

この**適合性（compatibility）**の用法において非常に重要な点は、**高い、あるいは完璧な適合性や適合度であっても、データがそのモデルや仮説を支持することを意味するわけではない**ということです。なぜなら、データは常に、その生成のための**無限の他のモデルと高度に適合する**ためです。逆に、**低い適合性も、それ自体で仮説やモデルが不正確であることを意味するわけではありません**。例えば、データが仮説やモデルと低い、または高い適合性を示すように、データが変更されたり、捏造されたりした物理的な可能性は常にあります。これはデータ開示の要求によって時々発見されます。そのような事例は、統計的手法のほとんどの応用において、**データに対する信頼の仮定**が根底にあることを示しています。

たとえそのような問題がなかったとしても、P値とその関連する統計量は、**本来支持しない推論**、例えば仮説の確率などを表したり示唆したりするものとして**頻繁に誤解されています**。したがって、以下のセクションでは、これらの統計量が実際に何を表しているのかを詳しく説明します。

#### **7.1. モデル、統計的仮説、および補助仮定**

P値を正しく理解し使用するには、ほとんどのユーザーには馴染みのない**抽象的な理論**が必要です。元の理論を概説するために、**分析モデルM**を、データ生成プロセスの挙動に関する仮定の集合と定義します。これらの仮定には、研究対象となる**統計的仮説H**が含まれる場合があります。この仮説は、**ターゲット仮説（target hypothesis）**または**検定仮説（test hypothesis）**とも呼ばれます。

大麻研究の例では、報告された使用Xと精神医学的結果Yが**ソース母集団において関連性がない**という**帰無仮説（null hypothesis）**が考えられます。これは、RDpop = 0、RRpop = 1、またはORpop = 1 と同等に表現できます。別の例としては、Hが「毎月の使用頻度fについて、頻度f+1を報告する人は、診断（Y=1）のオッズが使用頻度xを報告する人よりも4%高い」という仮説も考えられます。

多くの統計文献が、あらゆる統計的仮説を「帰無仮説」と呼んでいることに注意すべきです。しかし、この用法は、通常の英語で「null」が「何もない」や「ゼロ」を意味することとは矛盾しています。したがって、他の文献や本章では、「ターゲット仮説」という用語を使用し、「帰無仮説」という用語は、**関連性がない、または効果がないと主張する仮説**のために予約しています。

この用法における**非帰無（non-null）ターゲット仮説**の例には、以下が含まれます:
*   使用者における診断のオッズが非使用者におけるそれの2倍である（ORpop = 2）。
*   使用者におけるオッズが非使用者におけるそれの半分から2倍の間である（½ ≤ ORpop ≤ 2）。
*   使用者におけるオッズが非使用者におけるそれより高くない（ORpop ≤ 1）。
*   使用者におけるオッズが非使用者におけるそれより20%を超えて高くない（ORpop ≤ 1.2）。

ORpop = 1、ORpop = 2、および ½ ≤ ORpop ≤ 2 という仮説は、**両側仮説（two-sided hypotheses）**の例です。一方、ORpop ≤ 1 および ORpop ≤ 1.2 は、**片側（または方向性）仮説（one-sided (or directional) hypotheses）**の例です。ORpop = 1 および ORpop = 2 という仮説は、ターゲットパラメータの可能な値が一つしかなく、通常**点仮説（point hypotheses）**と呼ばれます。特に断りのない限り、本章の残りの部分ではHが点仮説であると仮定しています。

ターゲット仮説Hの他に、モデルにはP値と推定値を計算するために使用される**重要な補助仮定A**も含まれます。これらの仮定のセット全体はAと表記されます。一般的な補助仮定の一つは、最終的なデータがHが適用されるターゲット母集団からの**層化無作為抽出（stratified random sample）**であるというものです。この仮定は、対象となる変数（上記では大麻使用と診断）の両方が参加への同意や最終的な分析データへの含まれることに影響する場合、不正確になります。

別の一般的な補助仮定は、**結果が個人間で独立している**というものです。この仮定は、研究に参加している人々が互いに影響を与え合う（「干渉する」）ような方法で互いの結果に影響を与える場合（例えば、一人の診断が他の人々の診断に影響を与える場合など）は不正確になります。その場合、干渉がないという仮定を使用して計算されたP値は無効になります。

さらに、回帰分析で用いられる補助仮定として、ソース母集団における**結果の傾向が回帰モデルによって指定された形状に従う**というものがあります。例えば、オッズの傾向のP値を計算する際には、通常ロジスティック形状が仮定されます。

#### **7.2. 不一致統計量と参照分布**

**完全な分析モデルM**は、ターゲット仮説Hと補助仮定Aの組み合わせであり、M = H & A または M = (H, A) と表記されます。この完全なモデルは、モデルが正しい場合にデータに何を期待すべきかについて**具体的な予測**を行うために使用されます。これらの予測とデータから、モデルは、データとモデル予測との間の**不一致（discrepancy）または乖離（divergence）を要約する統計量T**（データに適用される式）を導き出すために使用されます。次に、モデルは、Mが正しい場合にTが**無作為標本間でどのように変動すると予想されるかを示す参照分布（reference distribution）またはサンプリング分布（sampling distribution）**を導き出すために使用されます。伝統的にTは「検定統計量」と呼ばれますが、TとそのP値は関連性と効果の尺度を推定するために使用できるため、ここではその用法は避けています。

データとモデル予測との乖離を要約する方法は数多く存在します。統計量Tは通常、Aが正しい、または「与えられた」と見なされる場合に、Hの違反に対して**最も敏感な（または「最も強力な」）**ものとして選択されます。これは、それらの違反から生じる不一致がTを最大限に膨張させるという意味です。残念ながら、H違反に対する感度のみに基づいてTを選択することは、Aに誤った仮定が含まれている場合に悪影響をもたらす可能性があります。例えば、Tが線形トレンドに最も敏感に選択された場合、U字型のトレンドに対する感度は劣ります。

Tの例には、Z統計量、χ2（カイ二乗）、F、スチューデントのt統計量、およびデータとMが予測したものとの間の不一致を測定するための他の多くの式が含まれます。これらの名前は、それらの従来の参照分布から取られています。

**例：ピアソンχ2統計量**

例えば、Tが、2方向表のJ行とK列の分類がソース母集団で独立であるという仮説H0を評価するための**ピアソンχ2統計量**であるとします。H0の添え字ゼロは「関連性がない」ことを意味します。Tの式はΣ(O – E)2/Eであり、Oは観測されたセルカウント、EはM = (H0, A) から予測されたカウント、Σはすべてのセルにわたる合計を表します。もしH0を仮定することに加えて、個人間の結果に干渉がなく、データ整合性に問題がないという補助仮定（A）を置くならば、このχ2統計量は、(J−1)(K−1)自由度のχ2分布に近似的に従います。

大麻の例では、行と列の分類は診断と大麻使用であり、合計は4つのセルにわたります。H0は、使用と診断が関連性がないこと（つまり、ORpop = 1）を意味します。H0の下で期待されるセルは表1に示されており、それらは行と列の合計を総数600で割った積です。これらから、ピアソンχ2の式は5.79の値を与え、近似参照分布は1自由度のχ2分布です。同じ一般的なピアソン式は、非帰無仮説、例えばORpop = 2などの場合にも使用できますが、その場合、期待値Eの計算はより複雑になります。

**P値の伝統的な定義**

点仮説H、データとHが導く期待値との不一致を測定する統計式T、そしてデータから計算されたTの観測値 t があるとします。このとき、参照分布は、Tが観測された t と同等またはそれ以上に極端になる近似確率 p を示します。ただし、これは分布を計算するために使用されたすべての仮定（HとAの両方を含む）が正しい場合です。これが、P値の伝統的な**「裾確率」（tail-probability）定義**です。

「極端な」が極めて大きなTに対応する場合、この裾確率pは、モデルM = (H, A) にエンコードされた仮定が与えられた場合に、Tが観測された値 t 以上になる確率として抽象的に定義できます:
p = Pr(T ≥ t | M) = Pr(T ≥ t | H, A)。

したがって、表1の統計量5.79を1自由度のχ2参照分布に照らすと、p = Pr(T ≥ t | M) = **0.016**が得られます。

これらのすべての場合において、裾確率P値pは、ピアソン (1900) やフィッシャー (1934, 1936) によって定義された観測された「Pの値」または「有意水準」であり、1920年代にはP値と呼ばれるようになりました。そして、これがほとんどの応用統計学でP値が定義されている方法です。残念ながら、一部の数理統計学のテキストでは、仮説検定の決定ルールに基づいてP値を再定義していますが、実際には、点仮説の場合、2つの定義は通常、数値的に同じP値になります。しかし、区間仮説（例：½ ≤ ORpop ≤ 2）のような他のケースでは、裾確率P値が決定P値よりも大きくなることがあります。

また、モデルがTの非常に小さな値が起こりにくいことを示唆している場合（自由度が3以上のχ2統計量の場合など）、「極端な」が極めて小さなTに対応する場合があることにも注意すべきです。この状況は、モデルがデータに**適合しすぎている**という懸念がある場合に生じ、データ操作を示唆します。これらの場合、P値は下裾確率 p = Pr(T ≤ t | M) となります。

#### **7.3. 近似参照分布と正確参照分布**

2x2分割表のような基本的なデータ構造以外では、Tの**正確な参照分布**を見つけてP値を計算することは困難な場合があります。したがって、従来の参照分布はしばしば**「大標本」近似**であり、結果として得られるP値は、tがより極端になるか、サンプルサイズが小さくなるにつれて不正確になります。

例えば、ピアソンχ2統計量T = Σ(O – E)2/E は、その従来の参照分布であるχ2確率分布にちなんで名付けられています。この近似は、各観測カウントが平均E、分散Eの正規分布に従ってランダムサンプル間で変動するという仮定に基づいています。モデルが正しい場合、近似は期待値Eが増加するにつれてより正確になります。しかし、Oがカウントであるため、それらは完全に正規であることはなく、したがってχ2分布はピアソン統計量の**近似P値のみを提供します**。

繰り返しになりますが、表1の場合、χ2参照分布は1自由度であり、観測された近似P値はp = 0.016です。したがって、Tがt = 5.79 と同等またはそれ以上になる確率 Pr(T ≥ 5.79 | H, A) は、HとAが実際に正しい場合、**約1.6%**です。しかし、2x2分割表の場合、Tの**正確な参照分布（超幾何分布と呼ばれる）**は、**フィッシャーの正確P値**として0.041、つまり**4.1%**を生成します。ピアソンP値のような近似値を正確なP値に近づけるように調整することは可能ですが、現代の計算能力によって可能になったより一般的な代替手段は、**ブートストラップなどのシミュレーション方法を使用すること**です。

#### **7.4. パーセンタイルと驚き度によるP値の解釈**

正しい解釈は、P値が提供する情報の**固有の非対称性**を理解することによって助けられます。P値は、それから導き出された仮説Hの**確率ではありません**。代わりに、それは統計量Tが参照分布の中で落ちた**「クォンタイル」または「パーセンタイル」にすぎず**、その分布は、HとTを導き出すために使用されたすべての補助仮定が正しかった場合に、Tがどれほど異常または驚くべきであるかを測るために使用されます。したがって、統計量tを使用して乖離を測定する場合、100pは、データがモデル予測からパーセンタイルの観点からどれだけ乖離しているかを示します。例えば、100p = 4% は、tが可能な乖離の上位4%に達したことを示します。

これを試験を受けた人のパーセンタイルに例えると、理解が深まります。事前に、この人が典型的な受験者と比較して試験のトピックについてせいぜい平均的な理解を持っていると考えていたとします。もしその人の試験のスコアの上位パーセンタイルが4.1%であり、スコア分布の上位5%に位置していたら、私たちは驚くかもしれません。同様に、調査回答者間で大麻使用と精神医学的結果が関連性がないと事前に考えていた場合（H0に従う）、表1の正確な統計量がその参照分布の上位4.1パーセンタイル、つまりその分布の上位5%に落ちたら、私たちは驚くかもしれません。

P値の驚き度をより具体的に理解するために、**公正なコイン投げのメカニズム**を想像し、n回の投げでメカニズムがすべて表を出した場合、どれほど驚くかを問うことができます。ここでnは、n回の投げですべて表が出る確率（½n）が観測されたP値 p に最も近いように選択されます。p = 0.041 の場合、このnは5です。なぜなら ½5 = 0.031 であり、½4 = 0.063 だからです。したがって、表1からの正確なP値は、公正な5回の投げで5回の表を見るよりも少し驚きが少ない、と言うことができます。

より一般的には、P値 p が与えられたとき、**S値 s = −log2(p)** に最も近いnを探します。これは、P値 p によって提供されるモデルM = (H, A) に対する**驚き度（surprisal）またはシャノン情報**としても知られています。ここでpは、モデルの下での参照分布でTが落ちたパーセンタイルです。このS値は、データとモデル間の**不適合性（incompatibility）**の尺度としても使用できます。バイナリ驚き度の単位は、コンピューター科学や電子工学で用いられる**ビット**であり、そのスケールは0（モデルに対してTによって伝えられる情報がないことを表す）から上限なしに増加します。

1ビットの情報は非常に小さく、1回のコイン投げによって伝えられる公平性に関する情報に相当します。n回コインが投げられ、表が出ることへのバイアスがないという仮説に反して、すべて表が出たときに伝えられる情報が、S値sで測定されます。表1の場合、s = −log2(0.041) = **4.6**です。したがって、t = 5.79 を見ると、補助仮定Aが与えられた場合、独立性H0（ORpop = 1）に対して**4.6ビットの情報**が提供されることになります。この結果は、5回の公正な投げで5回の表を見ることで、表が出ることへのバイアスがないという情報よりもわずかに少ない情報を伝えています。比較として、p = 0.05 のS値は4.3であり、4回の投げで4回の表が、表へのバイアスがないことに対して提供する情報とほとんど変わりません。

多くの研究者は、大麻と精神医学的結果の間に多くの関連性を想像できることを考えると、関連性がないとは予想していなかったでしょう。したがって、帰無仮説H0は「**藁人形**」であり、そのP値0.041は、実際の背景（文脈的）期待を考えると、驚くべきものと見なすべきではありません。しかし、私たちはより文脈的に合理的な仮説に対してP値を計算することができます。例えば、使用者における診断のオッズが非使用者と比較して2倍になると予想していたとします。対応する統計的仮説Hは、表1のソース母集団におけるオッズ比ORpopが2に等しい（ORpop = 2）というものです。この仮説に対する正確なP値はp = **0.644**です。この結果は、文脈的にも統計的にも驚くべきものではありません。s = −log2(0.644) = **0.6ビット**であり、1回のコイン投げに含まれる公平性に関する情報よりも少なく、表1がORpop = 2に対して取るに足らない情報しか含んでいないことを示しています。

#### **7.5. 統計的情報の狭さ**

T、そしてそのP値とS値によって測定される情報は**非常に狭い**ことに注意すべきです。Tは、観測された結果と予測された結果の乖離など、完全なモデルが予測するデータからの可能な不一致の一つの次元のみを表します。結果の観測された分散と予測された分散の比較など、**他の多くの次元も確認されるべき**であり、しばしば確認されます。量的結果の場合、**過小分散**は、結果の値が予測よりも集中しているように見えることを指し、干渉（例えば伝染）の存在を示唆する可能性があります。一方、**過大分散**は、結果の値が予測よりも広範囲に分布しているように見えることを指し、重要な制御されていない結果予測因子の存在を示唆する可能性があります。

さらに、TとそのP値、S値は、**完全なモデルMとデータとの関係に関する演繹的（純粋に論理的）情報のみを要約**し、Mに捕捉されたもの以外の**文脈的（背景）情報**は計算に利用しません。特に、Mが因果的主張を含まない場合、それから導かれる統計量は**関連性に関する情報のみを要約**します。逆に、統計量が因果情報を要約するためには、完全なモデルMに因果的記述が含まれている必要があります。例えば、表1からの統計量は、使用者と非使用者が結果に影響を与える可能性のある多くの点で異なる（つまり、潜在的な交絡因子が異なる）という文脈的情報を利用していません。したがって、p = 0.041 は、大麻使用と結果がソース母集団において関連性がないというMにおける仮説H0にのみ言及していると見なすべきです。

もしH0が、大麻使用が結果に影響を与えないという因果帰無仮説である場合、p = 0.041 がH0に言及していると主張するには、**補助仮定（A）に大麻使用が無作為化されていたことが含まれている必要**があり、これは文脈的に**不合理**です。したがって、より賢明な解釈は、p = 0.041 を「関連性がない」ことにのみ言及するように限定し、「効果がない」ことには言及しないことです。

#### **7.6. 区間推定とP値の関係**

誤解を避けるために、ORpopのような関連性指標の複数の値に対してP値を計算し、それらを関連性の値に対して**表またはプロットすることで、P値（または適合性）関数**を作成できます。同様に、結果として得られるS値を関連性の値に対してプロットすることで、**S値（または驚き度）関数**を作成できます。このような表やグラフは非常に情報量が多いですが、複数の関連性が含まれる報告ではかさばりすぎる可能性があります。そのため、通常は、**事前に指定されたP値を持つ関連性の値が提示されます**。

その一つが**点推定値（point estimate）**であり、これはP値が最大となる（通常p = 1）関連性の値です。表1では、ORpop = **2.64**がそれに該当します。もう一つは、P値が**小さな数α**（通常0.05）に等しい関連性の値であり、これらは**αレベル適合性限界（α-level compatibility limits, CL）**と呼ばれ、通常100(1−α)%の「信頼限界（confidence limits）」としてラベル付けされています。これらの限界内の関連性の値は、P値がαより大きいため、もしその基準がp > αであるならば、「データと合理的に適合している」と言えるでしょう。表1の場合、正確なP値が0.05であるオッズ比は1.04と6.36です。したがって、これら2つのオッズ比が**正確な0.05レベルのCL**です。

CL内の範囲は**適合性区間（compatibility interval, CI）**と呼ばれます。適合性区間内の関連性の値はp > αであるため、補助仮定Aがすべて正しく、p > 0.05を「合理的な適合性」の基準として使用した場合、**データと合理的に適合している**と言えます。表1では、1.04から6.36の範囲がORpopの0.05レベルCIであり、ORpopのすべての値が1.04から6.36の間であれば、データと合理的に適合していると言えます。

このセクションは、P値と区間推定の解釈における長年の誤解に焦点を当て、その歴史的背景から、なぜそれが誤解されやすいのか、そしてどのように正しく解釈すべきかについて詳細な解説を提供しています。特に、P値が「仮説の確率」ではないこと、そして「驚き度」や「適合性」という概念を用いることで、その情報内容がより明確になるという提案は、この章の核心的な主張の一つです。また、P値と区間推定が互いに関連し、補完し合う関係にあることも示されています。

---

### **8. カバレッジ（「信頼性」）区間**

1.04から6.36の区間は、より一般的には100(1-0.05)% = **95%「信頼区間」**として知られています。本章では、この用語を避けるべきだと強く主張しています。なぜなら、この言葉は「信頼」の根拠があることを示唆するものの、その根拠が**不確実または誤っている可能性**があるからです。この問題は、Amrheinら(2019a,b)、Rafi & Greenland (2020)、Amrhein & Greenland (2022)、Greenlandら(2022)によっても詳細に議論されています。

たとえ信頼区間を計算する際の前提条件が満たされていたとしても、「信頼」とは、**理想的な研究条件を仮定した思考実験で生成された区間のカバレッジ率（または較正）に関する保証**に過ぎません。

より正確に説明すると、補助仮定Aの下で、観測データがソース母集団からの**無作為抽出**であると想像することができます。この「無作為」の意味は、研究デザインによって具体的に異なります。次に、私たちは、補助仮定Aが正しいと仮定した場合、ソース母集団からの可能なすべての無作為抽出のうち、**どのくらいの割合がP値と区間を特定の結果とともに生成するのか**を問うことができます。例えば、仮定が正しい場合、これらのサンプルの何割が、**ソース母集団全体から計算されたオッズ比ORpopをαレベル適合性区間内に含む（カバーする）のか**、という問いです。区間はP値がαより大きいオッズ比を含むため、このカバレッジの問いは、「Aが正しい場合、無作為抽出の何割がORpopのP値をαより大きくするのか？」という問いと同じ意味になります。

カバレッジが実際に発生するサンプルの割合は、**カバレッジ率**と呼ばれます。カバレッジが失敗する割合は、**誤差率**と呼ばれます。もし、すべての補助仮定が満たされた場合（正確な区間のように）、カバレッジ率が1−α以上である場合、その方法は**保守的に較正されている**、または**仮定の下で保守的なカバレッジ妥当性を持つ**と言われます。この「保守的」という言葉は、妥当性の基準が1−αに等しいのではなく、1−α以上であるという点から来ています。95%レベルでの保守的な妥当性とは、カバレッジが少なくとも95%であることを意味します。

カバレッジ率と誤差率の定義は、**理想的な条件下での、すべての可能な無作為抽出においてその方法が何を生成するか**に言及しており、観測された個々の区間については言及していません。観測された区間（例えば1.04から6.36）について言えるのは、それが**理想的な条件下で保守的なカバレッジを保証するように設計された方法によって生成された**ということだけです。つまり、もしすべての補助仮定が正しければ、その方法によって計算されたすべての可能な無作為抽出からの区間の少なくとも95%がORpopを含むはずです。サンプルサイズが増加するにつれてカバレッジは95%に近づきますが、サンプルが小さい場合やデータが疎な場合は、95%からの乖離が大きくなることがあります。

残念ながら、伝統的に観測された適合性区間は**「信頼区間」**と呼ばれ、1−αはαレベル適合性区間の**「信頼水準」**と呼ばれてきました。これらの用語は、**非常に誤解を招く**可能性があります。なぜなら、「信頼性」は、区間を計算するために使用された仮定の下で、**すべての可能なサンプルにわたってその方法がどのように機能するか**にのみ言及するからです。したがって、例で言えば、95%は**方法のカバレッジ率にのみ言及する**のであり、**観測された区間（1.04, 6.36）がORpopを含む確率を指すものではありません**。その特定の区間（1.04, 6.36）がORpopを含む確率を持つためには、ORpopに**事前分布（prior distribution）**を与える必要があります（ベイズ法のように）。その場合、(1.04, 6.36) がORpopを含む確率は95%に近いとは限りません。したがって、一般的なルールとして、「信頼区間」における「信頼性」を、観測された区間が真のパラメータORpopを含む確率と混同すべきではありません。

関連する問題として、仮定の一部が不確かな状態にある場合、1−αは、その方法に持つべき信頼を**大幅に過大評価する**可能性があるという点があります。言い換えれば、CIは**過信区間**となる可能性があります。したがって、例で言えば、診断が独立していなかったり（例えば、すべて同じ精神科医によって行われたと疑われる場合）、調査参加が使用と診断の両方に関連していたりする場合など、仮定の一部が侵害された場合、カバレッジ率は95%をはるかに下回る可能性があります。

対照的に、仮定が不確かである、あるいは誤りであると考えられていても、**適合性（compatibility）解釈は有効なまま**です。なぜなら、それはデータが仮説とどのように適合しているかのみを指し、区間が対象とする関連性への信頼できるガイドであるか、またはORpopが区間内にあると確信できるか、ということには言及しないからです。そのような信頼性の判断は、研究のデザイン、実施、分析、そしてそのトピックに関する他の研究の詳細な概要に基づいて形成されるべきです。提示者が潜在的な利益相反を抱えている場合、読者は判断を形成する際にそれらの利益相反に留意すべきであり、開示要件があるにもかかわらず、利益相反が言及されない場合があることにも留意すべきです。

このセクションは、「信頼区間」という統計用語がいかに誤解されやすいか、そしてその真の意味が「理想的な条件下での方法の性能保証」に過ぎないことを詳細に解説しています。特に、「信頼区間」が個々の観測された区間が真値を含む確率を示すものではないという点は、非常に重要な誤解の是正点です。「過信区間」という言葉は、仮定が満たされない場合の信頼区間の問題点を端的に表現しており、統計結果を解釈する際の慎重さを促しています。

---

### **9. ベイズ統計**

これまでに説明してきた手法は、時に「頻度論（frequentist）」と称されます。これは、それらの手法が提供する確率が、仮定された条件下での**仮想的な事象の頻度**（例：区間のカバレッジ率）に限定されるためです。

一方、**ベイズ法**は、さらに踏み込んで、対象とする関連性を95%の確率で含むと期待される**観測された区間**を生成しようとします。この区間は「信用区間」（credible interval）と呼ばれます。ベイズ法に関する入門書や書籍は数多く存在しますが、読者は、「ベイズ」とラベル付けされた哲学や手法の間には**重要な違い**があることに注意するよう警告されています。そのため、ベイズ法に関する記述は、その基本概念や限界について、著しく異なる見解を示すことがあります。

残念ながら、ベイズ確率の主張は、**頻度論の「信頼区間」手法と同じ補助仮定に依存している**ため、同様に疑わしいものとなる可能性があります。さらに、ベイズの結果は、従来の頻度論の結果を得るために使用される情報に加えて、**「事前分布」（prior distributions、または「事前情報」）**と呼ばれるものを追加することに依存しています。

ベイズ法の正当性は、**有効な事前情報**が結果の精度を向上させることができる点にあります。しかし、この潜在的な利点には、**潜在的な害**も伴います。つまり、**無効な事前情報**を使用すると、結果の精度が低下する可能性があるのです。また、事前分布が、**望ましい、あるいは既定の結論を支持するように選択された場合**、**循環的推論（circular reasoning）**の危険性も生じます。したがって、ベイズの結果は常に、従来の頻度論の結果の後に提示されるべきであり、読者が追加された事前分布が結果に与える影響を**明確に確認できるようにする**ことが強く推奨されています。

事前分布を**「事前データ」（prior data）**、つまり、完全な無作為調査や完全な無作為化実験から得られたかのように、事前情報が表現されたデータに変換することは、その評価のための別の方法です。例えば、ある研究では、真の率比が1/1.20 = 0.83から1.20の間であると95%以上の確率で主張する率比の事前分布が使用されました。単純なバランスの取れた無作為化試験で、0.83から1.20の95%信頼区間を得るには、各治療群で232例、合計464例の結果が観測される必要があります。したがって、率比が0.83から1.20の間に収まるという95%以上の確信を置く事前分布は、ほとんどの無作為化試験から得られる情報よりもはるかに多くの情報を表しており、そのような試験からのベイズの結果を**支配してしまう**でしょう。つまり、事前分布がデータ情報を圧倒してしまうのです。

事前情報をデータで表現することの強みは、**事前情報が対応する研究規模の観点からどれほど強力であるか**を視覚化できることです。また、現在の研究以前に実際に観測されたことについて、より支配的ではなく、おそらくより慎重な事前分布を開発し使用することも可能になります。さらに、頻度論的分析のベイズ的拡張は、事前データセットを実際のデータセットに連結し、実際のデータと事前データを区別するための指標変数をデータに追加するだけで得られるという利点もあります。

このセクションでは、ベイズ統計学の基本的な考え方と、それが頻度論的アプローチとどのように異なるかについて説明しています。特に、ベイズ法における「事前分布」の役割とその導入に伴う潜在的な問題、例えば循環的推論や事前情報がデータ情報を圧倒してしまう可能性について詳しく解説しており、ベイズ法を適用する際の慎重さを促しています。

---

### **10. 統計ソフトウェアにおける近似**

ほとんどの統計ソフトウェアは、**正規分布（ガウス分布）の近似**に基づいてP値と区間推定を計算します。カバレッジ（「信頼性」）と誤差率（「有意性」）を正当化するためには、これらのプログラムは**無作為抽出や治療のランダム化に加えて、追加の仮定を必要とします**。

1.  **仮定された統計モデルの形式が正しいこと**。
2.  **データセットのサイズが、実用的な目的のために近似を十分に正確にするのに十分大きいこと**。

これら二つの仮定は、**しばしば重要な程度で違反されており**、時には**劇的なバイアス**をもたらす可能性があります。それにもかかわらず、これらはほとんどの研究報告で無視されています。

おそらく最も一般的な近似は、**Zスコア（Z-score）またはワルド法（Wald method）**です。回帰係数βの点推定値bを考えます。ワルド法は、研究デザインが生成し得たすべての可能な無作為抽出にわたるbの標準偏差の推定値を使用します。この推定標準偏差は、ソフトウェア出力では通常**標準誤差（SE）**とラベル付けされます。Hがβが特定の値cに等しいという仮説であるとすると、H: β = c の近似両側P値は、Zスコア |b – c|/SE を正規分布表または関数で調べることによって計算されます。対応するワルド95%区間推定値は、p > 0.05 であるすべての値cの範囲であり、その端点（限界）は b ± 1.96∙SE となります。この近似は、正規分布をt分布に置き換えることでしばしば洗練され、SE乗数が増加しますが、回帰結果が完全に正規分布しない限り、これでも近似にすぎません。

特に**カテゴリカルな結果**の場合、サンプルサイズが小さくなるか、Zスコアがより極端になるにつれて、ワルド近似は**ますます不正確になります**。典型的なサンプルサイズでは、0.05付近の近似P値は10%ずれることがあり、0.001未満のP値は、より正確な方法と比較して**桁違いにずれる**可能性があります。同時に、オッズ比の推定値は、データがより疎になるにつれて（極端な推定値によって示される）、1から離れて**ますますバイアスがかかる**ようになり、これはワルド限界の**深刻な不正確さ**を伴います。

このセクションでは、統計ソフトウェアがP値や区間推定値を計算する際に依存している**近似**の問題に焦点を当てています。特に、これらの近似が依存する「モデル形式が正しい」ことや「十分なサンプルサイズ」といった仮定がしばしば破られ、それが結果のバイアスや不正確さにつながることを強調しています。ワルド法のような一般的な近似の限界を具体的に示すことで、ソフトウェアの出力を盲信することの危険性を警告しています。

---

### **11. 統計的有意性検定の批判的概観**

P値は、推定値と**適合性指標（compatibility measures）**の両方を提供できる**多用途な統計ツール**です。しかし、これらの応用は軽視され、P値は**統計的検定のためのツール**としてのみ使用されるように追いやられてきました。

二値的なαレベル仮説検定では、仮説Hに対する観測されたP値 p は、事前に指定された「小さい」数αと比較されます。そして、p ≤ α の場合、Hは「棄却」され、p > α の場合、「採択」されます。したがって、「p ≤ α ならば棄却する」というルールは、いつHを放棄するか、あるいは維持するかについての**決定ルール**として機能します。誤解を避けるため、多くの情報源では「採択」を「棄却できない」（fail to reject）に置き換えており、αレベルのルールは「p ≤ α ならばHを棄却する。p > α ならば棄却しない」となります。

正しいHを棄却することは、「**偽棄却（false-rejection）**」、「**偽陽性（false-positive）**」、「**第一種過誤（Type-I error）**」、または**αエラー**として知られています。誤ったHを棄却できないことは、「**偽採択（false-acceptance）**」、「**偽陰性（false-negative）**」、「**第二種過誤（Type-II error）**」、または**βエラー**として知られています。これらの誤りの概念は、推定における誤り（推定値と対象とする関連性または効果の真の値との距離）という**連続的な誤りの概念**とは対照的です。

多くの場合、検定（決定ルール）はP値の代わりに**信用区間（CI）**を使用して実施されます。具体的には、「1−α区間がHによって指定された関連性を**除外する**ならばHを棄却する。区間がその関連性を**含む**ならば棄却しない」というルールです。この区間ルールはαレベルルールと等価です。誤った棄却は、Hが正しい場合に区間がHによって予測された関連性を含まないことに対応します。誤った採択は、Hが誤っている場合に区間がその予測された関連性を含むことに対応します。1−α区間は、p > α であり、そのルールを使用して棄却されない関連性のすべての値を示します。したがって、区間全体を調べることで、p > α だからといってHを安易に採択してしまうことを防ぐことができます。

研究報告における、二値的な検定とその用語によって引き起こされた多くの誤った推論を文書化し、分類した**広範な文献**が現在存在します。何よりも、αレベルのルールは通常「**有意性検定**」と呼ばれ、p ≤ α は「**統計的に有意**」、p > α は「**有意ではない**」と呼ばれています。後述するように、これらの検定と用語は非常に広範に誤用され、誤解されてきたため、区間推定と、区切りを設けない連続的なP値への置き換えによる**完全な放棄が求められています**。

誤解はさておき、統計的検定のより根本的な批判は、**単一の統計的二分法に基づいて決定を下すことに、通常、健全な文脈的根拠がない**ということです。この見解では、研究は、推定値とP値の観点から、どのように実施され、何が観測されたかを正確に報告しようとすべきです。もし決定が必要な場合、それは研究からの完全な情報と背景情報に基づいて行われるべきであり、各研究およびメタ分析から得られる正確な推定値とP値を含めるべきです。なぜなら、誤差の可能性のある大きさを判断することが、**実用的な結果を予測する上で極めて重要**になるからです。

#### **11.1. 有意性検定の用語と慣習における問題点**

統計的検定の誤用と誤解の多くは、**日常語が、その一般的な意味とほとんど対応しない専門用語に誤用され、その結果、結果の単純さや決定性の錯覚を生み出すという相乗効果**に起因しています。

特に、「採択/棄却」という元の意味は、より良い作業仮説やより多くのデータが得られるまでHを使用するかしないかという**一時的な決定**を意図していました。しかし、**「関連性がない」または「効果がない」という帰無仮説（H0）を検定する際**に、「Hを採択する」および「Hを棄却する」というフレーズは、あたかもルールが「p > 0.05 ならばデータがH0を支持する」と宣言する**権威ある神託であるかのように、H0が正しいか間違っているかについての宣言として誤解される**ようになりました。この**誤ったゼロ仮説主義（nullism）的解釈**は、「採択」という用語によって助長され、結果として、実際には独自の推定値がそのようなことを一切示唆していないにもかかわらず、p > α であるという理由だけで、**関連性がない、または効果がないと誤って結論付ける報告が膨大に生じました**。

表1の例では、ORpop = 1 (H0) のP値は0.041であり、もしαが0.04以下であれば「採択」されるでしょう。しかし、ORpop = 6 の正確なP値は0.070であり、**データとの適合性がより高い**のです。

同様に誤解を招くのは、p ≤ α を「有意（significant）」、p > α を「有意ではない（not significant）」と表現することです。なぜなら、この統計的決定ルールは、結果の**実用的な有意性**とはほとんど、あるいは全く関係がないからです。**実用的な有意性は、効果量と誤差の程度に直接依存します**。統計的有意性と実用的な有意性の混同は、元々の文献で用いられた「統計的に有意」と「統計的に有意ではない」というより正確なラベルであっても、永続的に続いています。驚くべきことに、この混乱はボーリング (1919) によってはるか昔に批判されており、「統計的に有意ではない」ことを関連性がないと誤解する間違いは、ピアソン (1906) によってそれ以前に批判されています。混乱をさらに深めているのは、20世紀の文献の大部分（特に英国）が「有意水準」をP値の同義語として使用していたのに対し、別の大部分（特に米国）が「有意水準」を決定カットオフαの同義語として使用していたことです。

前述の通り、多くの文献が**「帰無仮説」という用語を、あらゆる統計的仮説Hを指す**ものとして使用しています。しかし、通常の英語では「null」はゼロまたは何も意味しません。この「null」をあらゆる仮説に誤用する慣行は、「関連性なし」または「効果なし」という仮説のみを検討し、それに対する**合理的な代替案を軽視する**ことにつながっています。この誤解を招く用語は、P値やαレベルのルールを使用するいかなる場合も「**帰無仮説有意性検定（NHST）**」と呼ぶことによってさらに悪化しています。

用語はさておき、二値的な検定はP値または区間を、統計的決定ルールにおける**中間的な計算**に縮小してしまいます。これは、**重要なデータ情報を見落とし、さらには曖昧にしてしまう**ため、非常に誤解を招く可能性があります。例えば、Hは、たとえp > 0.05 であったとしても、データと最も適合性の高い関連性からかけ離れている場合があります。繰り返しになりますが、表1では、仮説ORpop = 1 のP値は0.041であり、α = 0.04 を使用した場合には「採択」されるでしょう。それにもかかわらず、ORpop = 2 のP値は0.64であり、**集計されたデータとのはるかに高い適合性**を示しています。

さらに別の問題は、α = 0.05 というカットオフ点が、R.A.フィッシャーによって彼自身の研究における好みとして** casually に言及されたに過ぎない**にもかかわらず、多くの異論があるにもかかわらず、一部の学術誌によって**厳格な慣習**として強制されてきたことです。フィッシャー自身も、αが研究ごとに決定されるべき理由を多くの説明とともに示しています。これらの説明にもかかわらず、一部の統計学者は、正しいHが棄却される頻度（「偽陽性エラー」）を減らすために、新しい慣習としてα = 0.005 を使用するキャンペーンを展開しています。しかし、このキャンペーンは、一部の研究者が、誤ったHを受け入れるという反対の誤り（「偽陰性エラー」）についてより懸念している点を無視しています。この誤りの頻度は、αを小さくすることで増加します。したがって、誤った棄却（偽陽性または第一種過誤）を減らすためにαを下げると、**誤った採択（偽陰性または第二種過誤）が増加し**、後述する出版バイアスと「有意」な推定値の膨張が増加します。相反する懸念があるため、α = 0.05 はほとんどの場で慣習として残っています。

このセクションは、統計的有意性検定、特にP値の誤用と誤解を徹底的に批判しています。P値が持つ本来の「適合性指標」としての価値が失われ、「決定ルール」に矮小化されてしまった歴史的経緯と、それが「有意/有意ではない」という二分法や「帰無仮説」の誤解釈、そして恣意的なαレベルの設定といった様々な問題を生み出してきたことを詳しく解説しています。特に、統計的有意性が実用的な有意性とは異なるという点は、研究者が常に念頭に置くべき重要な警告です。

---

### **12. 出版バイアスと「再現性の失敗」の錯覚**

統計の誤用と誤解によって引き起こされる深刻な文献の歪みの一つに、**出版バイアス（publication bias）**があります。これは通常、「統計的に有意」な結果が、より注目に値するという誤った信念に基づいて、**優先的に出版される傾向**を指します。このバイアスは、出版された推定値が**平均的にサイズが肥大化する**（実際の基礎となる効果よりも帰無仮説から遠ざかる）という結果を招きます。

しかし、一度「有意」な関連性が報告されると、**逆のデフレ的な出版バイアス**が生じる可能性があります。これは、「有意ではない」結果が、元の「有意」な結果と矛盾していると誤って報告された場合、それほど興味深いとは見なされなくなるものです。この結果、一部の研究は「統計的に有意」であり、他の研究はそうではないという理由で、**研究間で矛盾や「再現性の失敗」（replication failure）を報告するレビュー**につながります。実際には、**研究間に偶然の範囲を超える差がないにもかかわらず**、このような誤解が生じます。このような誤った矛盾の報告を避けるためには、研究は、**それらの差に対するP値と推定値を用いて直接比較される**必要があります。

このセクションは、統計的有意性検定の誤用が、研究結果の出版にどのような偏り（出版バイアス）をもたらし、それが「再現性の危機」といった誤った認識を生み出すかを指摘しています。特に、「有意ではない」結果が「効果がない」ことを意味するのではなく、単に「統計的な証拠が弱い」ことを示すに過ぎないという点と、異なる研究間の「矛盾」が実は単なる偶然の変動である可能性を強調しています。

---

### **13. 二値的統計的決定における誤差率と検出力**

統計的決定ルールの**一般的な正当化**は、その使用が**誤った決定の発生率に関する保証を伴う**とされる点にあります。しかし、この根拠は、ルールを導き出すために使用された仮定が不確かな場合には**誤り**です。なぜなら、**実際の誤差率**は、無作為抽出やランダム化の仮定の妥当な違反に対して**極めて敏感**だからです。それでも、「有意性検定」は、そのような仮定が正当化できない研究に日常的に適用されており、この種の**誤用から多くの悪い決定が生まれています**。

次に、必要なすべての仮定が研究デザインと実行によって完全に適用された**理想的な状況**を考えます。この場合、正しい仮説Hを検定する際、「p ≤ α」ルールは、可能な無作為標本の**100α%以下**でHを誤って棄却し（第一種過誤を犯し）、他の標本の**100(1−α)%以上**でHを「採択」します。したがって、αはしばしば「偽棄却率（false-rejection rate）」と呼ばれますが、この用語はわずかに不正確です。なぜなら、αはその率自体ではなく、率の**事前に指定された上限（maximum）**だからです。理想的な条件下でさえ、検定が正しいHを棄却する実際の率は、小さな期待カウントを持つ表の正確な検定では、αよりも**実質的に小さくなる**ことがあります。そして繰り返しになりますが、αは、実際に行われた決定が誤っている確率を指すものではなく、補助仮定に関する不確実性を考慮に入れているものでもありません。

誤ったHを棄却するルールの率は、その検定の**検出力（power）**または「真陽性率（true-positive rate）」と呼ばれます。これはαとHがどれだけ正しい値に近いかに**反比例**します。極端なケースで例示すると、もしαが0であれば、決して棄却されない（つまり、検出力はゼロ）でしょう。一方、αが1であれば、常に棄却される（つまり、検出力は100%）でしょう。同様に、α=0.05を使用する典型的な研究では、もしORpopが1.01であれば、H0: ORpop = 1 の棄却率はαとほとんど変わりませんが、もしORpopが100であれば、H0の棄却率は100%に近づくでしょう。

検定が誤ったHを棄却できない率は**1−検出力**であり、しばしば「偽陰性（false-negative）」または**第二種過誤率（Type-II error rate）**と呼ばれ、βで表されます。これはαとHがどれだけ正しい値に近いかに**正比例**します。したがって、正確には、選択されたαと未知の正しいオッズ比ORpopにどのように依存するかを示すために、β(α, ORpop) と表記すべきです。

#### **13.1. 検出力に関する問題**

α = 0.05 の場合、特定の事前指定された代替仮説H1に対して80%の検出力を持つように研究を設計することが**一般的な慣習**となっています。これにより、β = 0.20 となり、偽陰性率βは偽陽性率の少なくとも4倍になります。この**誤差率の不均衡**は、正当な理由が与えられることがほとんどなく、もしH1が正しい場合にH0を棄却できないことが、H0を誤って棄却するよりもコストが高い場合、**有害**です。そのような場合、H0とH1の役割は逆転されるべきです。

より深い問題は、**真の関連性が不明であるため、検出力も不明である**という点です。これにより、研究設計における検出力計算は**非常に投機的**になります。この問題は、異なる妥当な関連性の値に対して検出力をグラフ化または表化し、ターゲット仮説Hに対する異なる代替案の下でのαレベル検定の検出力を示す**検出力曲線（power curve）**を作成することで、部分的に対処できるかもしれません。

検出力はデータ分析には**不要であり、議論の余地があるほど無関係である**とされています。なぜなら、それが伝える統計情報は、点推定値や区間推定値といった**より直感的に理解しやすい形で既に示されている**からです。したがって、検出力の使用は、**今後の研究の設計に限定されるべき**です。検出力は結果の解釈において**非常に誤解を招く**可能性があります。例えば、データがH0に対して「有意ではない」（例えば、p > 0.05 で検出力 > 80%）と示され、それが「効果がない」ことを支持すると誤解されることがあります。しかし実際には、データは重要な効果と**より高い適合性を持つか、より矛盾が少ない**場合があるのです。

このセクションは、統計的決定における誤差率と、特に検出力という概念の解釈に潜む問題点を浮き彫りにしています。検出力計算が、未知の真の関連性に依存するため本質的に投機的であること、そしてデータ分析において検出力が誤解を招く可能性があることなど、その限界と誤用について詳しく解説しています。

---

### **14. 多重比較**

区間とP値の「信頼性」と「有意性」の解釈の使用における、非常に**物議を醸す微妙な問題**が、「多重比較（multiple comparisons）」という見出しの下で生じます。実際には多くの異なるバージョンの問題が生じ、それらには多くの**相反する解決策と意見**が存在します。グリーンランド (2021b) は、この論争の概要を提供し、対立の原因とそれぞれの立場の背後にある理論を説明しようと試みています。

この問題の一つのバージョンでは、大規模な無作為調査から得られたデータセットを分析し、20個の仮説H1, …, H20のうち、どれを追求すべきかを決定することを目標とすると仮定します。それぞれをα = 0.05レベルで個別に有意性検定します。もし20個すべての仮説が正しく、P値が統計的に独立していると仮定すると、1つ以上がp ≤ 0.05 となる（そして誤って棄却される）確率は、1−0.95^20 = 64% になります。これは、1つの正しい仮説を検定した場合に期待される1−0.95^1 = 5% とは大きく異なります。この事実により、一部の統計学者は、この問題において**ボンフェローニ補正（Bonferroni adjustment）**の使用を奨励しています。αに適用される場合、それは私たちのカットオフとしてα/20 = 0.0025 または 0.25% を使用すべきだというものです。この場合、1つ以上の仮説がp ≤ 0.0025 となり、誤って棄却される確率は1−0.9975^20 = 4.9% となります。

この結果は当初、ボンフェローニ補正を正当化するように見えるかもしれませんが、**実用的な目的には非常に誤解を招きます**。なぜなら、これは**検出力、データ依存性、または誤差のコストを一切考慮に入れていない**からです。最も重要な点は、決定カットオフを一律にα/20に下げることで、**誤った仮説を棄却する検出力が劇的に低下する**ことです。さらに、検定が同じ変数とデータを使用して各仮説を決定するため、検定は独立しているとは限らず、検出力の損失は悪化します。依存性の程度はかなり大きく、20個の正しい仮説のうち偽棄却が生じる確率は、独立性に基づく式1−(1−α)^20で示されるよりもはるかに低くなります。極端な例でこれを示すと、もしすべての検定が完全に正の相関関係にあった場合（つまり、すべて同時に棄却または棄却失敗する）、そしてすべての仮説が正しかったとしたら、ボンフェローニ手順が偽棄却を行う率は、新しいカットオフの0.25%に等しく、5%ではありません。実際の偽棄却率がカットオフをはるかに下回る結果の一つは、**誤った仮説を検出する検出力が数パーセントにまで低下する**ことです。

コストを考慮すると、研究者は、もし20個すべての仮説が正しい場合に少なくとも1つの偽棄却が64%の確率で発生することを受け入れるかもしれません。それは、一部の仮説が誤っていると予想しており、それらを発見する検出力を損ないたくないという理由も考えられます。分析タスクは、その場合、偽検出と検出失敗の両方を最小限に抑えながら、合計の中からどの仮説が誤りであるかを検出するという**再構築された問題**として捉えられるべきです。ボンフェローニよりもはるかに洗練された多くの多重比較方法が存在し、そのような問題に対処します。

より深い問題は、多重比較方法が**そもそも正当化されるかどうか**を決定することです。多くの著者らは、もし分析者の目標が、異なる仮説とデータとの適合性を個別に記述すること、あるいは関連性や効果に関するデータ情報を要約することである場合（意思決定を行うのではなく）、**多重比較手順には健全な根拠がない**と主張しています。他の著者らは、多重性が生じるほとんどの状況は、**ベイズ法または経験ベイズ法を用いて分析するのが最適である**と主張しています。

このセクションは、多重比較問題の複雑さと、それに伴う解決策と意見の対立に焦点を当てています。特に、ボンフェローニ補正のような一般的な手法が抱える実用上の欠点（検出力の低下やデータ依存性の無視）を指摘し、統計的決定が常に研究の目的とコストを考慮に入れるべきであることを強調しています。また、多重比較手法の根本的な正当性自体を問う見解も紹介しており、この分野の継続的な議論の深さを示しています。

---

### **15. 結論と提言**

この章では、従来の統計学の基本的な要素をレビューし、それらがヒト集団の研究における主題領域や研究の現実と一致しない、**深刻な過剰単純化を前提としている**ことを中心に議論してきました。

これらの失敗は、P値が観測された関連性の「有意性」を示し、区間推定が実際の関連性の大きさに対する「信頼性」の範囲を提供するという、**伝統的な統計学が誘発する過剰解釈**につながります。統計的手法を安全に利用するためには、それらが**理想的なケースにおいてのみ推論を提供**し、実際の不完全な応用に対する「正解」ではないことを強調する必要があります。

問題を減らすためには、統計的手法を科学的推論のための**「お告げ」としてではなく**、データ生成プロセスの挙動に関するモデルとデータとの関係を記述するために利用するよう、**再方向付けを行うべき**です。この再方向付けには、以下の重要な側面が含まれます:

1.  **P値を、仮説モデルとデータとの間の適合性（compatibility）の尺度として再解釈する**こと。これは「相性の良さ」として理解できます。
2.  **区間推定を、データ生成プロセスの明示的な仮定の下で、データと高い適合性を持つ関連性の大きさの範囲として再解釈する**こと。これは「相性区間」または「信用区間」とも呼ばれます。
3.  **統計量を使用して推論や意思決定を行う前に、統計量を計算するために使用された仮定の不確実性（uncertainty）を記述し、説明する**こと。

これらの提言は、統計学をより誠実で、現実の複雑さに対応できるツールへと変革するためのものです。単なる数値やカットオフに囚われるのではなく、その背後にある仮定、不確実性、そしてデータとの「相性」を深く理解し、文脈に基づいた推論を行うことの重要性を強調しています。

この章の最後には、関連する参考文献と、疫学ハンドブック内の他の章へのクロスリファレンスが多数記載されており、読者がさらに深く探求できる豊富なリソースが提供されています。これには、「ベイズ法」「因果推論と疫学」「回帰手法」「感度分析とバイアス分析」といった重要なトピックが含まれています。

この音声概要では、サンダー・グリーンランド教授の「統計的手法：基本概念、解釈、および注意点」の内容を、その批判的視点と実用的な提言に焦点を当てて詳しく解説しました。統計的結果を解釈する際には、常にその限界と背景にある仮定を意識し、より包括的かつ慎重なアプローチを取ることの重要性が、この章全体を通して一貫して示されています。

これで、本資料の音声概要を終了します。ご清聴いただきありがとうございました。
