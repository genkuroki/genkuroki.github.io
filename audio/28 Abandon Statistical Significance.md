提示されたソースによると、本論文の著者名はBlakeley B. McShane、David Gal、Andrew Gelman、Christian Robert、およびJennifer L. Tackettであり、タイトルは"Abandon Statistical Significance∗"、出版年は2017年9月21日と記されています。

ソースの著者らは、科学出版物や多くの研究領域における現状として、**p値が従来の0.05の閾値（pが0.05未満）を上回ること**がまず必須条件とされ、その後にようやく（しばしばわずかに）事前証拠や関連証拠、メカニズムの妥当性、研究デザインとデータ品質、現実世界のコストと利益、発見の新規性など、研究領域によって異なる他の要因（これをまとめて「無視された要因」と呼んでいます）が考慮されるという**字引（lexicographic）的な決定ルール**が存在すると述べています。

彼らは、p値の閾値を変更するという最近の提案があるものの、それとは異なり、**帰無仮説有意性検定（NHST）のパラダイム全体を放棄すること**を推奨しています。そして、p値を科学出版や意思決定において特権的な役割を持たない、単なる多くの情報の一つとして扱うことを提唱しており、この急進的なアプローチが実際的かつ合理的であると主張しています。

これは、生物医学および社会科学において、出版された研究結果が高い割合で再現に失敗しているという広範な危機に直面しているためです。このような再現失敗は、しばしば、小さく、時にはばかげた介入からの巨大な効果の主張に関連しており、その主要な証拠として一つ以上の比較が「統計的に有意」、通常は**pが0.05未満**という従来の閾値をもってゼロ効果およびゼロ系統誤差というシャープポイント帰無仮説に対して定義されたものが用いられています。現状では、**p < 0.05** は科学理論に有利な強い証拠と見なされ、結果が出版されるためだけでなく、真剣に受け止められるためにも必要とされています。

伝統的に、pが0.05未満というルールは、ノイズ追跡に対する保護策として、したがって再現性の保証であると考えられてきました。しかし近年、Carney et al.  や Bem  のような広く知られた例に加えて、理論的な研究により、「研究者の自由度」（researcher degrees of freedom）[Simmons et al., 2011] が豊富にあるため、純粋なノイズから統計的有意性を容易に得られることが明らかになっています。その結果、既存の科学的実践を考慮すると、低い再現率は予想されることであり [Ioannidis, 2005, Smaldino and McElreath, 2016]、改革の要求は（例えば Meehl  を参照）一層強固になっています。

一つの代替案として、Daniel Benjaminおよび71名の共同著者ら（幅広い分野の著名な学者を含む）によって提案されたのは、「新しい発見の主張に対する統計的有意性のデフォルトのp値閾値を0.05から0.005に変更すること」でした。

ソースの著者らは、この提案では現在の再現性の問題に対処するのに不十分であると考えています。彼らは、Benjamin et al.  の著者らが「この推奨を新しい効果の発見の主張に限定していること」、「特定の閾値の選択は恣意的であること」、「帰無仮説が真であるという事前のオッズ、検定された仮説の数、研究デザイン、第一種エラーと第二種エラーの相対的なコスト、および研究トピックによって異なるその他の要因に依存すべきであること」を認識していることから、彼ら自身も同意するだろうと予想しています。実際、「著者らの多くは、帰無仮説有意性検定（NHST）よりも優れた統計解析アプローチがあることに同意している」と述べています。

著者らは、Benjamin et al.  が重視する具体的な当面の行動、すなわち「p値閾値を変更することは単純であり、多くの研究者が受けた訓練と一致し、迅速に広く受け入れられるかもしれない」という点に異議を唱えています。彼らは、このステップが有益であるとは確信していません。より厳しい閾値は、現在トップジャーナルさえも汚染している質の低い研究の流れを短期的には減らすかもしれません。中期的には、研究者により高い質の研究を行い、0.005の障壁を突破する可能性を高める動機付けとなるかもしれません。しかし一方で、より急なカットオフは、出版された結果に対する過信をさらに強めたり、そのような結果に関連する効果量の誇張を招いたりする可能性があります。また、それに達しなかった重要な発見が軽視されることにもつながる可能性があります。著者らは、提案された0.005閾値の導入が科学の状態を改善するか悪化させるかについては、両方の肯定的および否定的な結果が考えられるため、予測できないと述べています。最終的に、この問題は興味深いかもしれませんが、著者らはp値閾値（および他の統計的尺度に基づく閾値）は一般的に悪い考えであると信じているため、これは彼らの関心外であると見ています。

したがって、彼らは別の代替案を提案しており、それは**統計的有意性を放棄すること**です。特に、Benjamin et al.  の著者の一人が「より恒久的な修正を行うまで洪水をとどめるダム」と表現した「迅速な修正」を提案するのではなく [Resnick, 2017]、生物医学および社会科学における研究、出版、発見のデフォルトの統計的パラダイムとして、**NHSTパラダイム、およびそれに関連するp値閾値を放棄すること**を推奨しています。具体的には、現状のようにpが0.05未満（または他の統計的閾値）によって決定される統計的有意性が科学出版およびより広範な統計的意思決定における字引的決定ルールとして機能することを許容するのではなく、**p値がその閾値スクリーニングの役割から降格され、代わりに連続的に扱われ、無視された要因とともに単なる多くの証拠の一つとして考慮されること**を提案しています。

彼らがこの推奨を行う理由は大きく分けて三つあります。
1.  生物医学および社会科学において、圧倒的多数のアプリケーションで使用されているゼロ効果およびゼロ系統誤差という**シャープポイント帰無仮説は、一般的にあり得そうもないため、関心の対象ではない**。
2.  NHSTの標準的な使用法、すなわちこの「わら人形」的なシャープポイント帰無仮説の棄却を、何らかの好ましい対立仮説に有利な肯定的または決定的な証拠と見なすことは、経験豊富な科学者や統計学者によってさえ日常的に誤った科学的推論をもたらす**論理的誤謬**である。
3.  p値やその他の統計的閾値は、研究者にデータの全体ではなく、**単一の比較を研究し報告することを奨励する**。

著者らは、再現性向上のための具体的な提案について詳しく述べる前に、Benjamin et al.  の提案によっても解決されないNHSTの一般的な問題、および提案固有の問題について議論しています。生物医学および社会科学では、効果は通常小さく、人々や状況によって大きく異なります。さらに、測定は変動性が高く、しばしば関心のある基礎概念と間接的にしか関連しないため、サンプルサイズが大きい場合でも、系統的な変動とバイアスの可能性により、小規模または非代表的なサンプルと同等になります。結果として、単一の研究からの推定値自体は一般的にノイズが多いです。これに加えて、単一の研究が通常、分析の基本的な単位であるという事実が、NHSTパラダイムに問題をもたらします。

効果が小さく変動し、測定値がノイズが多いことを考慮すると、圧倒的多数のアプリケーションで使用されているゼロ効果およびゼロ系統誤差という**シャープポイント帰無仮説自体があり得そうもない**。Cohen  は、この帰無仮説を「nil hypothesis」と嘲笑し、「常に誤りである」と揶揄し、Tukey  は2つの処置は「常に異なる」と指摘しています。たとえ効果が真にゼロであったとしても、実験上の現実により、それをテストするために設計されたどの研究においても効果が厳密にゼロになることはないでしょう。

さらに、ノイズの多い推定値と、統計的有意性をスクリーニングする出版プロセスが組み合わさると、出版された推定値は**上方バイアスがかかり（潜在的に大きく）**、しばしば符号が誤っています。実際、出版プロセスによる統計的有意性のための推定値のスクリーニングは、研究者に多くの小さなノイズの多い研究を実施する間接的なインセンティブを提供し、一つ以上の統計的に有意な結果をもたらす可能性のある推定値につながります。これらすべての問題は、研究者が多重比較を行う場合（実際の比較であろうと潜在的な比較であろうと、「分岐する道の庭（garden of forking paths）」；Gelman and Loken ）にさらに複合されます。

要約すると、生物医学および社会科学における現代の様々な特徴、すなわち小さく変動する効果、ノイズの多い測定、統計的有意性をスクリーニングする出版プロセス、および研究実践は、NHST、特にゼロ効果およびゼロ系統誤差というシャープポイント帰無仮説をこれらの領域に**特に不向き**にしています。より広く言えば、NHSTは、証拠を「統計的に有意」と「統計的に有意でない」という異なるカテゴリーに二分化することに関連する多くの問題を抱えています。これに加えて、NHSTパラダイムに対するよく知られた批判の一つは、従来の0.05という閾値、あるいはその他のカットオフが**全く恣意的**であることです。

関連する批判として、問題はそもそも閾値を設けることにあるというものがあります。証拠を統計的有意性の異なるカテゴリーに二分化すること自体に「存在論的根拠はない」[Rosnow and Rosenthal, 1989]。著者らはさらに進んで、一般的に、証拠をp値の関数として校正することは理にかなっていないと述べています。なぜなら、この統計量は一般的に関心の対象とならず、あり得そうもないゼロ効果およびゼロ系統誤差という帰無仮説に対して定義されているからです。

証拠の二分化または三分化は、**誤った科学的推論**も引き起こします。例えば、研究者はしばしば統計的有意性と実質的な重要性を混同します。さらに、彼らは無視された要因の考慮を含む証拠のより全体的な見方をする代わりに、p値が0.05の閾値を超えるかどうかに基づいて、もしそうであればほぼ完全に科学的結論を下します。最後に、証拠が異なるカテゴリーに割り当てられることは、このように割り当てられた項目がカテゴリー的に異なると結論づける強力な誘因となるため、彼らは二分思考（dichotomous thinking）に従事します。具体的には、彼らは統計的有意性のために慣習的に定義された閾値に達した証拠を差異の証明として解釈し、対照的に、この閾値に達しない証拠を無差異の証明として解釈します。

二分思考から生じる誤った推論の例として、Gelman and Stern  が提供する例では、応用研究者が「‘有意’と‘有意でない’の違い自体は統計的に有意ではない」ということをしばしば理解していないことが示されています。McShane and Gal  は、医学、疫学、認知科学、心理学、経済学など幅広い分野の研究者が、(i) p値を連続的ではなく二分的に解釈し、p値の大きさではなく、p値が0.05未満であるかどうかにのみ焦点を当てていること、(ii) たとえば記述統計について尋ねられた場合など、p値が関係ない場合でもp値に固執していること、(iii) たとえば処置差の大きさなど、他の証拠を無視していることを示しています。McShane and Gal  は、統計学者でさえこれらの誤りに影響されやすいことを示しています。

NHSTパラダイムに固有の証拠の二分化に関連する問題は、少なくとも部分的には、最近のアメリカ統計協会による統計的有意性およびp値に関する声明 [Wasserstein and Lazar, 2016] により、最近大きな注目を集めています。この声明は実際、Benjamin et al.  のような提案に対して、その6つの原則のうちの3つ目（「科学的結論およびビジネスまたは政策決定は、p値が特定の閾値を通過するかどうかにのみ基づくべきではない」）で明示的に警告しています。

**Benjamin et al.  による提案されたp値閾値p < 0.005に関する具体的な問題**についても詳細に議論されています。
1.  Benjamin et al.  は、0.005の閾値が(i) 対立仮説に有利なベイズファクターが約14から26に対応すること、および(ii) 偽陽性率を「妥当だと判断するレベル」に低減することから提案していますが、**これらのレベルの選択に対する正当化はほとんど提供されていません**。
2.  彼らが提案するルールを**新しい効果に限定していること自体が問題**です。彼らは「新しい効果」を定義していないため、彼らの推奨は全く非実用的になっています。これは、研究が漸進的かつ累積的であると考えられている領域では特にそうです。この提案された方針は、推奨がまさに解決しようとしている再現性に応用された場合に**不整合をもたらす**でしょう。特に、共通の現象に関する2つの独立した研究が実施される順序は、ベイズ更新では無関係です。しかし、pが0.005未満の研究とpが0.005より大きく0.05未満の研究がある場合、実際に採用されている再現性の定義（後続の研究が先行研究を成功裏に再現したと見なされるのは、両方が統計的有意性に達しなかった場合、または両方が統計的有意性に達し方向的に一致している場合）の下では、どちらの研究が最初に実施されたか（したがって「新しい」であったか）が極めて重要になります。Benjamin et al.  の提案の下では、最初の研究がpが0.005未満の研究であれば2番目（再現）の研究は成功と見なされますが、そうでなければ失敗と見なされます。
3.  応用研究では、未補正の多重比較（実際の比較と潜在的な比較の両方）が常態であるという事実は、厳密には、**事前登録されたプロトコルとデータ分析手順を持つ研究からのp値以外のすべてのp値を無効化**します。これは、Benjamin et al.  も認めている懸念事項です。
4.  Benjamin et al.  の提案の根底にある数学的正当性は、少なからぬ批判を受けています。具体的には、提案の根底にある**一様最強力ベイズ検定（UMPBT）**は、Johnson [2013a] によって導入および擁護され、Johnson [2013b]（そして現在はBenjamin et al. ）における0.005を新しい閾値として使用する呼びかけと並行しています。著者らは、UMPBTには多くの懸念があると考えています。

    *   おそらく生物医学および社会科学にとって最も関連があるのは、UMPBTアプローチが**1世紀前のネイマン-ピアソン流派の二値決定と0-1損失関数に深く根差している**ことです。Pericchi et al.  が指摘するように、NHSTパラダイムが合理的である設定においてさえ、「古典的有意性検定の問題の本質は、固定された第一種エラー（偽陽性）に対して第二種エラー（偽陰性）を最小化するというその目標にある」ことです。この流派は、いくつかの制限された分布と検定問題の集合の下での数学的最適化を可能にしますが、シャープポイント帰無仮説検定を行うほとんどの目的を達成しないという点で、**決定論的な観点からは非常に初歩的**です。
    *   より具体的には、NHSTパラダイムに暗黙的な0-1損失関数は、一般的に科学的学習のプロセスやコストと利益に**近似的にさえ対応しません**。特に、より低いp値閾値への移行提案が特定の応用分野で良い助言であったとしても、その根底にある論理が問題の性質にしっかりと向き合っていないという事実は変わりません。このような規則は、第一種エラーと第二種エラーの間の特定のトレードオフを暗黙的に表現しますが、実際には、このトレードオフはすべての結果のコスト、利益、および確率に依存すべきであり [Gelman and Robert, 2014]、これらは手元の問題に依存し、生物医学および社会科学の研究間で大きく異なります。代わりに、UMPBTは、効果量の分布に対応せず、数学的仮定のセットの下での**最悪のシナリオを表すミニマックス事前分布**に基づいています。
    *   閾値に関する手続きの依存性を定義すること（Johnson [2013a] の表記では γ）は、1世紀前のフィッシャー流派の仮説検定に対する答えに内在する根本的な困難を繰り返します。Johnson [2013a] が主張するように、古典的な棄却域との完全な一致をさらに求めることは、**真にベイズ的なアプローチの魅力を単に否定すること**であり、さらに、現実的な統計モデルではこの一致を達成することは不可能です。
    *   より一般的に言えば、**一様最強力事前分布（および検定）の概念は、多変量設定に容易に拡張されず、局外パラメータ(nuisance parameter)を含む複雑な帰無仮説を伴う現実的なケースにはさらに拡張されません**。Johnson [2013a] で提案された最初の解決策、すなわち特定の事前分布を使用して局外パラメータ(nuisance parameter)を帰無仮説で積分することは、「客観的ベイズ検定」の問題を解決するには不十分です。2番目の解決策、すなわち未知の局外パラメータ(nuisance parameter)を標準的な推定値に置き換えることは、ベイズ的な観点からさらに遠ざかります。
    *   実際、ベイズファクター自体も、初歩的なネイマン-ピアソン流派の結果であり、それゆえ統計的有意性の問題に対応するものです。Kamary et al.  では、混合推定の問題として仮説問題を提起する提案とともに、ベイズ的な観点からのこれに関する困難について議論されています。
    *   著者らは、仮説検定がベイズ的な方法で行われなければならないと言っているわけではありません。しかし、Johnson [2013a] のアプローチがベイズ的なつながりを失う程度に、0.005ルールのベイズ的な正当性も失われます。したがって、0.005は単なる別の恣意的な閾値となり、絶対的かつ文脈外的な意味で理解できないと著者らが考える、偽陽性と偽陰性の間の暗黙のトレードオフによってのみ正当化されることになります。

これらの問題は、p値の閾値を0.005に変更するというBenjamin et al.  の提案だけではなく、統計的有意性を用いた現在の慣行にも関連しています。

**統計的有意性の「特権的役割」を放棄することによって前進する**という点について、著者らはいくつかの提案を行っています。
統計学は難しく、特に生物医学および社会科学のように効果が小さく変動し、測定値がノイズが多い場合はそうです。迅速な修正はありません。統計的有意性のデフォルトのp値閾値を変更すること、ゼロを含むかどうかを重視した信頼区間を採用すること、あるいは証拠の強さを評価するための従来の分類とともにベイズファクターを採用することのような提案は、現在の0.05の閾値を用いたp値の使用と同じまたは類似の問題を抱えています。特に、それぞれは、一般的に関心の対象とならずあり得そうもないゼロ効果およびゼロ系統誤差という帰無仮説に対する閾値に基づいて証拠を暗黙的または明示的にカテゴリー化しています。さらに、それぞれは純粋に統計的な尺度であり、無視された要因、すなわち事前証拠や関連証拠、メカニズムの妥当性、研究デザインとデータ品質、現実世界のコストと利益、発見の新規性、および研究領域によって異なるその他の要因の考慮を含む、証拠のより全体的な見方をすることができません。

要するに、それぞれは**統計的錬金術**の一形態であり、ランダム性を確実性に変質させるという偽りの約束であり、データから始まり、何らかのp値や他の統計的閾値を超えたかどうかに基づいて、「効果がある」か「効果がない」かという真偽の二分的な宣言で終わる**「不確実性laundering」**です。前進するための重要な第一歩は、不確実性を受け入れ、効果の変動を受け入れることから始めることであり [Carlin, 2016, Gelman, 2016]、そのような二分化によって提供される確実性の偽りの約束を捨てることによって、世界について多く（実際、より多く）を学ぶことができると認識することです。

著者らは、**p値を「禁止」することを望んでいません**。代わりに、p値がその閾値スクリーニングの役割から降格され、代わりに多くの証拠の一つとして考慮されるようになるための、編集者および査読者向けと著者向けの2つの具体的な推奨事項を提示しています。

1.  **編集者および査読者向け:** 正確性と新規性の目標が相反する限り、無視された要因の重要性に関して明示的かつ体系的な姿勢をとることが、現状の大きな改善となると考えられています。この推奨の具体的な運用化の一つは、レビュープロセスの様々な段階にこれらの要因の考慮を組み込むことかもしれません。例えば、ジャーナルポータルは、各要因（編集者によって決定される領域固有の要因を含む）および証拠全体の強さについて査読者からのフィードバックを求めるとともに、これらの評価のオープンエンドな正当化を許可することができます。これらの評価は、編集者の公に開示された（または査読者自身の）各要因の重要性評価によって重み付けされることができます。さらに、編集者は決定レターで各要因の重要性および評価について議論し対処することで、証拠のより全体的な見方を保証することができます。
    ジャーナルは、主張を裏付けるデータが純粋なノイズから十分に離れているかどうかを決定するために、何らかの明確な閾値を必要とするのではないか、という反論があるかもしれません。統計的閾値は証拠を構成するものの客観的な基準を提供し、それがジャーナル査読者の主観性や個人的バイアスに対する貴重なブレーキとなるのではないか、という反論があるかもしれません。これらに対して、著者らは、そのような閾値が必要であったとしても、p値に基づいて設定することは理にかなっていないと主張します。なぜなら、ノイズの多い結果を出版することのコストと利益は、文脈によって大きく異なるからです。さらに、p値は純粋に客観的な基準ではありません。同じデータと帰無仮説に対する異なるモデル仕様と統計的検定は異なるp値をもたらします。事態をさらに複雑にするのは、データのプロトコルおよび分析手順に関する多くの主観的な決定（コーディングや除外など）が実際には必要であり、これらが最終的に報告されるp値に強く影響することがあります。最後に、なぜジャーナルにそのような閾値スクリーニングルールが必要なのかが理解できないと述べています。ジャーナルはすでに定性的な要因に基づいて出版決定を個別に行っており、p値がデフォルトのスクリーニングルールから単なる証拠の一つに降格された場合でもこれは続けることができます。実際、p値、ベイズファクター、あるいは他の統計的尺度であろうと、単一の数字が主観性や個人的バイアスを排除することはできません。
    著者らは、例えばp値が0.2である結果や、ゼロを含む90%信頼区間を持つ結果であっても、関心のある理論的または応用的な問題に関連しており、解釈が十分に正確であれば、記事として出版することは全く許容されると考えています。例えばp値が0.001である結果も、それが何らかの好ましい対立仮説の真実を意味すると解釈されることなく、出版されることが可能であるべきです。
    p値は、特定の帰無モデルによって結果がどれほど容易に説明されるかという問題に関連していますが、これが**出版における決定的な要因であるべき理由はありません**。結果は帰無モデルと整合しているが、それでも科学や政策議論に関連していることもありますし、結果は帰無モデルを棄却しても、科学や政策の関心を引くものは何も提供しないこともあります。
    要するに、ジャーナル編集者は自由に論文を受け入れ、読者に関連する証拠を提示すべきです。例えば、興味深い発見に対する証拠は弱いものの、既存のデータは帰無効果と整合していることを述べた論文を見る方が、出版プロセスがそのような発見をスクリーニングアウトしたり、著者に研究者の自由度を悪用して統計的有意性を得るように奨励したりするよりもはるかに望ましいと述べています。
2.  **著者向け:** 何らかのp値や他の統計的閾値を超える単一の比較に焦点を当てるのではなく、**データの全体および関連する結果を研究し報告すること**を推奨しています。そうするにあたり、著者らは無視された要因を利用して統計分析と記述を動機付けることを推奨しています。例えば、彼らは原稿に、データの全体および結果の文脈で、各要因に直接的に言及するセクションを含めるかもしれません。例えば、このセクションでは、Gelman and Carlin  が議論したように、主題分野の知識と効果量の期待の文脈で研究デザインについて議論するかもしれません。別の例として、このセクションでは、(i) 当該効果に対する仮説上のメカニズムを形式化し、その様々な構成要素を明示化し、(ii) 研究で測定および分析された構成要素を明確にし、(iii) 提案されたメカニズムを支持するデータ結果の側面、および（全体のデータにおける）それに矛盾する側面について議論することによって、メカニズムの妥当性について議論するかもしれません。
    この推奨、すなわちデータの全体および結果について研究し報告することは、科学の基本原則であるため、わざわざ言及する必要はないと考える人もいるかもしれません。しかし、そうではありません！上述のように、科学出版における現状は、pが0.05未満であることが事実上常に結果が出版されるために必要であり、いくつかの例外はあるものの、標準的な実践はこのような結果に焦点を当て、すべての関連する発見を報告しないことです。これは明らかに著者のデータの研究および報告に影響を与えます。
    この推奨に対する潜在的な反論は、プロトコル、分析手順、および関心のある比較に関する決定がデータ収集前に行われ、したがって収集された特定のサンプルデータとは独立している**事前登録された研究に理想的に適している**ということかもしれません。著者らは、この文脈で推奨が最も明確であることに同意する一方で、事前登録がない場合でも、例えば多重宇宙分析（multiverse analysis）[Steegen et al., 2016] を使用して、収集されたデータに基づいて可能なプロトコル、分析手順、および比較の多様性についてある程度の考えを得ることができます。

著者らの焦点は科学出版における統計的有意性の閾値でしたが、同じ問題は、例えば研究者がどの結果を報告または真剣に受け止めるかを決定するためにボクセル単位のNHSTを使用するニューロイメージング、規制機関（食品医薬品局など）が新しい医薬品を承認するかどうかを決定するためにNHSTを使用する医療、非政府組織やその他の組織が介入が有益かどうかを判断するためにNHSTを使用する政策分析、マネージャーがA/Bテストを通じて二値決定を行うビジネスなど、**他の統計的意思決定の領域でも発生**します。さらに、閾値は科学出版だけでなく、研究プロジェクト内でも、研究者が予備的な発見に基づいてどの道筋を追求する価値があるかを決定する際に発生します。

p値の閾値スクリーニングの役割を降格し、無視された要因を強調するという著者らの提案は、これらのすべての設定に適用されます。例えば、ニューロイメージングでは、ボクセル単位のNHSTアプローチは的を外しています。なぜなら、通常真のゼロはなく、変化は通常、すべての脳の場所で常に起こっているからです。推定値と不確実性の画像をグラフ化することは理にかなっていますが、閾値を使用する利点は見出していません。規制、政策、およびビジネスの決定については、**費用対効果計算**が文脈外的な統計的閾値よりも明らかに優れていると述べています。

明確な費用対効果計算がない純粋な研究シナリオでも、例えば疾患状態を治療するために使用される2つの薬剤の有効性ではなく、**基礎となるメカニズムの比較**など、p値やその他の統計的閾値に価値を見出していません。代わりに、彼らは、仮説上のメカニズム研究者が、統計的に結論が出ない結果は将来の研究を動機付けるのに役立つとして、推定値、標準誤差、信頼区間などの結果を**単純に報告すること**を望んでいます。

研究の道筋（例えばアイデア、薬剤、遺伝子）をさらに追求するかどうかを決定するためのスクリーニングデバイスとしてp値やその他の統計的閾値を使用することの直感的な魅力があることを認める一方で、根本的にこのアプローチはデータの効率的な使用をしません。なぜなら、帰無仮説に基づく確率と、潜在的な研究リードを追求することからの潜在的な利益、あるいは当該リードが最終的に成功する予測確率との間に**一般的な関連性がない**からです。

代わりに、どの研究の道筋をさらに追求するかについて決定を下す必要がある限り、著者らは、効果量の分布と変動のモデルを使用してそのような決定を行うこと、したがって**帰無モデルから間接的に推論するのではなく、関心のある仮説と直接的に連携すること**を推奨しています。彼らはまた、可能であれば、より精密な個人レベルの測定、個人内または縦断的研究デザインのより大きな使用、および情報的な事前分布を使用し、変動する処置効果を特徴とし、多レベルまたはメタ分析的な性質を持つモデルの考慮の増加を望んでいます [Gelman, 2015, McShane and Böckenholt, 2017a,b, Gelman, 2017]。

著者らの推奨だけでは科学における再現性危機を解決することはできませんが、研究者を無関係な統計的目標の追求から遠ざけ、理論、メカニズム、および測定の理解に向かわせるという有益な効果があると信じています。彼らはまた、研究者をルーチン的な「発見」のパラダイム、および「効果がある」か「効果がない」かという二値的な声明から、不確実性と変動を受け入れる連続的かつ必然的に不完全な学習のパラダイムに移行させることを望んでいます。

---

提供された資料に基づき、ご質問について正確かつ詳細にまとめます。

資料は、「統計的有意性を放棄する (Abandon Statistical Significance)」と題された論文からの抜粋であり、統計的有意性検定（NHST）パラダイム、特に慣習的なp < 0.05という閾値の使用に疑問を投げかけ、その放棄を提唱しています。

以下に、資料の主要な論点と、p値の閾値を0.05から0.005に変更するという提案や、一様最強力ベイズ検定（UMPBTs）に関連する批判に焦点を当てた詳細をまとめます。

1.  **現状と問題点**
    *   生命科学および社会科学の分野では、発表された研究結果の再現性が低いという広範な危機に直面しています。
    *   現状では、結果が「統計的に有意である」、すなわちp値が慣習的な0.05という閾値（通常はゼロ効果というシャープポイント帰無仮説に対するもの）を下回る（**pが0.05未満**）ことが、科学的理論を強く支持する証拠とみなされ、出版されるため、あるいは真剣に受け止められるためにも必要とされています。
    *   これは「辞書順決定ルール」として機能しており、まず**pが0.05未満**であるかどうかが問われ、その後に（しばしば不十分ながら）先行研究や関連する証拠、メカニズムの妥当性、研究デザイン、データ品質、現実世界のコストと利益、発見の新規性など、研究領域によって異なる他の要因（これらを資料ではまとめて「無視されてきた要因 (neglected factors)」と呼んでいます）が考慮されるというものです。
    *   伝統的に**pが0.05未満**というルールはノイズチェイシングに対する保護策であり、再現性の保証であると考えられてきました。
    *   しかし、「研究者の自由度 (researcher degrees of freedom)」と呼ばれる実践が豊富にあるため、純粋なノイズからでも統計的有意性を容易に得られることが明らかになっています。その結果、現在の科学的実践を考えると、低い再現率は当然予想されます。

2.  **別の提案：閾値を0.005に変更することへの批判**
    *   ダニエル・ベンジャミンら72名の共著者による別の提案は、「新しい発見の主張に対する統計的有意性のデフォルトのp値閾値を0.05から0.005に変更すること」です。
    *   しかし、資料の著者らは、この提案は現在の再現性に関する困難を克服するには不十分であると考えています。
    *   この提案の支持者でさえ、特定の閾値の選択は「恣意的である」こと、「帰無仮説が真である事前のオッズ、検定される仮説の数、研究デザイン、第一種誤差と第二種誤差の相対的なコスト、および研究トピックによって異なるその他の要因に依存すべきである」ことを認識しています。また、「著者らの多くは、帰無仮説有意性検定（NHST）よりも優れた統計分析アプローチがあることに同意しています」。
    *   資料の著者らは、特に「p値閾値の変更は単純であり、多くの研究者が受けたトレーニングと一致し、迅速に広く受け入れられる可能性がある」という特定の即時行動への彼らの重点に異議を唱えています。
    *   閾値を厳格化することには短期的な利点（低品質な研究の減少）や中期的な利点（高品質な研究への動機付け）も考えられますが、より厳しいカットオフは、出版された結果への過信を増大させたり、効果量の誇張を招いたり、重要な発見が見過ごされたりする可能性もあります。資料の著者らは、0.005の閾値の導入が科学の状態を改善するか悪化させるか予測できないとし、この問題は彼らの管轄外であると考えています。なぜなら、彼らはp値閾値（および他の統計的指標に基づく閾値）が一般的に悪い考えであると信じているからです。

3.  **帰無仮説有意性検定（NHST）全般の問題点**
    *   資料の著者らは、帰無仮説有意性検定（NHST）パラダイム、特にそれに関連するp値閾値を、デフォルトの統計パラダイムとして放棄することを推奨しています。
    *   この推奨には3つの広範な理由があります。
        *   第一に、生命科学および社会科学において、大多数の応用で使用されているゼロ効果およびゼロ系統誤差というシャープポイント帰無仮説は、一般的にありそうもないため、関心の対象となりません。
        *   第二に、NHSTの標準的な使用法、すなわちこの「案山子」のようなシャープポイント帰無仮説の棄却を、何らかの好ましい対立仮説を支持する肯定的または決定的な証拠とみなすことは、論理的な誤謬であり、経験豊富な科学者や統計家によってさえ日常的に誤った科学的推論を引き起こします。
        *   第三に、p値やその他の統計的閾値は、研究者に対し、データの全体や結果の全体に焦点を当てるのではなく、単一の比較を研究し報告することを奨励します。
    *   NHSTは、証拠を「統計的に有意である」と「統計的に有意ではない」という異なるカテゴリーに二分化することに関連する多くの問題も抱えています（時には「周辺的に有意 (marginally significant)」を中間カテゴリーとする三分化もあります）。
    *   NHSTパラダイムのよく知られた批判の一つは、慣習的な0.05の閾値（あるいはどんなカットオフでも）が完全に任意であるということです。
    *   関連する批判は、問題はそもそも閾値を持つこと自体にあると示唆しています。証拠を統計的有意性の異なるカテゴリーに二分化（または三分化）すること自体に「存在論的な根拠はない」とされています。資料の著者らはさらに進んで、一般的にp値の関数として科学的証拠を評価することは意味をなさないと述べています。なぜなら、この統計量は、通常興味がなくありそうもないゼロ効果およびゼロ系統誤差という帰無仮説に対して定義されているからです。
    *   証拠の二分化または三分化は、誤った科学的推論も招きます。例えば、研究者は統計的有意性と実質的な重要性を混同しがちです。
    *   また、彼らはしばしば、p値が0.05の閾値を超えるかどうかに大部分あるいは完全に依拠して科学的結論を下し、無視されてきた要因 (neglected factors) を考慮に入れるなど、証拠のより全体的な見方をしていません。
    *   最後に、証拠を異なるカテゴリーに割り当てることは、そのように割り当てられた項目がカテゴリー的に異なると結論づける強い誘因となるため、研究者は二分法的思考（dichotomous thinking）に従事します。具体的には、慣習的に定義された統計的有意性の閾値に達する証拠を差異の証明と解釈し、対照的に、この閾値に達しない証拠を差異がないことの証明と解釈します。
    *   二分法的思考から生じる誤った推論の例として、GelmanとStern  は、応用研究者が「「有意である」と「有意でない」の違い自体は統計的に有意ではない」ことをしばしば理解していないことを示しています。McShaneとGal  は、医学、疫学、認知科学、心理学、経済学を含む様々な分野の研究者が、p値を連続的ではなく二分的に解釈し、p値の大きさではなく**pが0.05未満**であるかどうかにのみ焦点を当てていることを示しています。また、記述統計について尋ねられた場合など、無関係な場合でもp値に固執したり、他の証拠（例えば治療差の大きさ）を無視したりしています。McShaneとGal  は、統計家でさえこれらの誤りの影響を受けやすいことを示しています。

4.  **0.005閾値提案の具体的な問題点（詳細な説明）**
    *   ベンジャミンら  の提案には、NHST全般の懸念に加えて、具体的な問題があります。
    *   **第一に、彼らが0.005という閾値を提案する理由として、（i）対立仮説を支持するベイズファクターがおよそ14から26に対応すること、（ii）偽陽性率を「妥当」と判断するレベルに減らすことを挙げていますが、これらのレベルの選択に対する十分な正当化が提供されていません**。
    *   **第二に、彼らの提案が新しい効果の主張に限定されていること自体に問題があります**。何をもって新しい効果とするのかが定義されていないため、彼らの推奨は全く非現実的です。特に、研究が漸進的かつ累積的であると考えられる領域ではそうです。
    *   **この提案は、推奨が対処することを意図しているまさにその問題である再現性にも適用されると、非論理的になります**。特に、共通の現象に関する2つの独立した研究が実施される順序は、ベイジアン更新においては無関係です。しかし、**pが0.005未満**である研究とpが(0.005, 0.05)の間にある研究がある場合、どちらの研究が最初に行われたか（そして「新しい」とみなされるか）は、慣行で採用されている再現性の定義（後続の研究が先行研究を首尾よく再現したとみなされるのは、両方が統計的有意性に達しないか、両方が統計的有意性に達し、方向性が一致する場合）の下では決定的に重要になります。ベンジャミンら  の提案の下では、最初の研究が**pが0.005未満**の研究であれば、2番目の（再現）研究は成功とみなされますが、そうでなければ失敗とみなされます。
    *   **第三に、未補正の多重比較（実際のものと潜在的なもの）が応用研究で一般的であるという事実は、事前登録されたプロトコルとデータ分析手順を用いた研究以外の全てのp値を厳密に言えば無効にします**。これはベンジャミンら  も認めている懸念です。
    *   **第四に、ベンジャミンら  の提案の根拠となる数学的正当化は、かなりの批判を受けています**。具体的には、提案の根拠となる**一様最強力ベイズ検定 (uniformly most powerful Bayesian test / UMPBT)** は、ジョンソン [2013a] によって導入され擁護されており、ジョンソン [2013b] での呼びかけ（そしてベンジャミンら  で繰り返されている）とともに、0.005を新しい閾値として使用することを提唱しています。**資料の著者らは、一様最強力ベイズ検定 (UMPBTs) にいくつかの懸念があると考えています**。
        *   **おそらく生命科学および社会科学に最も関連するのは、一様最強力ベイズ検定 (UMPBT) のアプローチが、二値決定と0-1損失関数の100年前のネイマン・パーソン形式主義に深く根ざしている点です**。ペリッチら  が指摘するように、NHSTパラダイムが妥当な設定であっても、「古典的な有意性検定の問題の本質は、固定された第一種誤差（偽陽性）に対して第二種誤差（偽陰性）を最小化するというその目標にある」ことです。この形式主義は、限られた分布と検定問題の集合の下での数学的最適化を可能にしますが、シャープポイント帰無仮説検定を実行するほとんどの目的に対しては、決定理論的な観点から見て非常に初歩的です。
        *   **より具体的には、NHSTパラダイムに暗黙的に含まれる0-1損失関数は、一般的に、科学的学習のプロセスやコストと利益に近似的でさえマップしません**。特に、より低いp値閾値に移行するという提案が特定の応用分野で良いアドバイスであったとしても、その根底にある論理が問題の本質にしっかりと向き合うことを避けているという事実は残ります。**このようなルールは、第一種誤差と第二種誤差の特定のトレードオフを暗黙的に表現していますが、実際にはこのトレードオフは全ての結果のコスト、利益、確率に依存すべきであり、これらは問題によって異なり、生命科学および社会科学の研究間で大きく変動します**。代わりに、**一様最強力ベイズ検定 (UMPBT)** は、効果量の分布に対応しないが、一連の数学的仮定の下での最悪のシナリオを表すミニマックス事前分布に基づいています。
        *   **ジョンソン [2013a] の記法における閾値 (γ) に依存する手順を定義することは、100年前のフィッシャー流の仮説検定の答えにおける根本的な困難を再現しています**。
        *   **ジョンソン [2013a] が提唱するように、古典的な棄却域との完全な一致をさらに追求することは、この問題に対する真にベイジアンなアプローチの魅力を単に否定することになります**。さらに、この一致は現実的な統計モデルでは達成不可能です。
        *   **より一般的に言えば、一様最強力事前分布（および検定）の概念は、多変量設定には容易に拡張されず、局外パラメータ(nuisance parameter)を含む複雑な帰無仮説を伴う現実的なケースにはさらに拡張されません**。ジョンソン [2013a] で提案されている最初の解決策、すなわち特定の事前分布を使用して帰無仮説中の局外パラメータ(nuisance parameter)を積分で消去することは、「客観的ベイズ検定」の問題を解決するには不十分です。2番目の解決策、すなわち未知の局外パラメータ(nuisance parameter)を標準的な推定値で置き換えることは、ベイジアンな観点からさらにかけ離れています。
    *   資料の著者らは、仮説検定がベイジアンな方法で行われなければならないと言っているわけではありません。しかし、ジョンソン [2013a] のアプローチがベイジアンなつながりを失う程度に、0.005ルールのベイジアンな正当化も失われます。その結果、0.005は、ある暗黙的な偽陽性と偽陰性のトレードオフによって正当化される単なる別の恣意的な閾値となり、これは絶対的かつ文脈に依存しない形では意味をなさないと考えています。

5.  **統計的有意性の特権的役割を放棄して前進すること**
    *   統計は難しく、特に生命科学や社会科学のように効果が小さく変動が大きく、測定値がノイズが多い場合にはそうです。**迅速な解決策はありません**。
    *   統計的有意性のデフォルトのp値閾値を変更すること、信頼区間を使用してゼロを含むかどうかに焦点を当てること、または証拠の強さを評価するために慣習的な分類とともにベイズファクターを使用することなどの提案は、現在の0.05閾値でのp値の使用と同じまたは類似の問題を抱えています。
    *   特に、これらはそれぞれ、一般的に興味がなくありそうもないゼロ効果およびゼロ系統誤差という帰無仮説に対する閾値に基づいて証拠を暗黙的または明示的に分類しています。
    *   さらに、それぞれが純粋に統計的な尺度であり、無視されてきた要因 (neglected factors)、すなわち先行研究や関連する証拠、メカニズムの妥当性、研究デザインとデータ品質、現実世界のコストと利益、発見の新規性、および研究領域によって異なるその他の要因を含む証拠のより全体的な見方を怠っています。
    *   要するに、それぞれがランダム性を確実性に変質させると偽って約束する統計的錬金術の一形態であり、データから始まり、p値または他の統計的閾値が超えられたことに基づいて真偽の二項宣言、すなわち「効果がある」または「効果がない」という二値ステートメントで終わる「**不確実性laundering**」です。
    *   前進するための重要な第一歩は、不確実性を受け入れ、効果の変動を受け入れることを開始することであり、そのような二分化によって提供される確実性の偽りの約束を放棄することによって世界についてより多く（実際にはより多く）学ぶことができると認識することです。
    *   **資料の著者らは、p値を「禁止」する意図はありません**。代わりに、編集者や査読者向けと著者向けの2つの具体的な推奨事項を提示しています。これは、実際にはp値をその閾値スクリーニングの役割から降格させ、証拠の多くの断片の一つとして考慮する方法です。
    *   **編集者や査読者向けには**、正確性と新規性の目標が相反する限り、無視されてきた要因 (neglected factors) の重要性に関して明示的かつ体系的な立場を取ることが、現状に対する主要な改善となると信じています。この推奨事項の具体的な実施例としては、これらの要因の検討を査読プロセスの様々な段階に組み込むことが考えられます。例えば、ジャーナルのポータルは、各要因（編集者によって決定されるドメイン固有の要因を含む）および証拠の全体的な強さについて、査読者からのフィードバックを求め、これらの評価のオープンエンドの正当化を許可することができます。また、編集者は決定レターで各要因の重要性と評価について議論し対処することで、証拠のより全体的な見方を保証することができます。資料の著者らは、例えばp値が0.2である結果や、ゼロを含む90%信頼区間を持つ結果であっても、関心のある理論または応用問題に関連しており、解釈が十分に正確であれば、記事を出版することは完全に許容できると信じています。また、例えばp値が0.001である結果を、何らかの支持される対立仮説の真実を示唆するものと解釈せずに、出版することも可能であるべきです。
    *   **著者向けには**、何らかのp値またはその他の統計的閾値を超える単一の比較に焦点を当てるのではなく、データの全体と関連する結果の全体を研究し報告することを推奨しています。その際、著者が無視されてきた要因 (neglected factors) を統計分析と執筆の動機付けに使用することを推奨しています。例えば、彼らは、データの全体と結果の全体との関連で、これらの各要因に直接言及するセクションを原稿に含めるかもしれません。これは、科学の非常に基本的な原則のように思えるかもしれませんが、現状ではそうではありません。
    *   この提案は、科学的出版における統計的有意性の閾値に焦点を当ててきましたが、同じ問題は、ニューロイメージング、医学、政策分析、ビジネスなど、他の統計的意思決定領域でも発生します。
    *   統計的有意性をその閾値スクリーニングの役割から降格させ、無視されてきた要因 (neglected factors) を強調するという資料の著者らの提案は、これらの全ての状況に適用されます。例えば、規制、政策、およびビジネスの決定においては、文脈に依存しない統計的閾値よりもコスト-利益計算が明らかに優れています。
    *   たとえコスト-利益計算が明らかでない純粋な研究シナリオであっても、p値やその他の統計的閾値に価値を見出していません。代わりに、推定値、標準誤差、信頼区間などを報告することを望んでいます。統計的に結論が出ない結果は、将来の研究を動機付けるに関連しています。
    *   どの研究ライン（例えばアイデア、薬、遺伝子）をさらに追求するかを決定するためのスクリーニングデバイスとしてp値やその他の統計的閾値を使用することには直観的な魅力がありますが、根本的にはこのアプローチはデータの効率的な利用をしていません。帰無仮説に基づく確率と、潜在的な研究リードを追求することからの潜在的な利益、あるいは問題のリードが最終的に成功するであろう予測確率との間に一般的な関連性はありません。
    *   代わりに、どの研究ラインをさらに追求するかについて決定が必要な限り、効果量の分布と変動のモデルを使用してそのような決定を行うこと、したがって帰無モデルから間接的に推論するのではなく、関心のある仮説と直接的に作業することを推奨しています。また、可能であれば、より正確な個人レベルの測定、より多くの個人内または縦断的デザインの使用、および有益な事前分布を使用するモデル、変動する治療効果を特徴とするモデル、およびマルチレベルまたはメタ分析的性質を持つモデルの考慮の増加を望んでいます。

結論として、資料の著者らの推奨は、それ自体が科学の再現性危機を解決するわけではありませんが、研究者を無関係な統計的目標の追求から遠ざけ、理論、メカニズム、および測定の理解へと、そして定型的な「発見」パラダイムや「効果がある」または「効果がない」という二値ステートメントから、不確実性と変動を受け入れる連続的で不可避的に不完全な学習へと、押し進める健全な効果を持つと信じています。

---

ご提示いただいた情報源に基づき、統計的有意性に関する現状の課題と、著者らが提案する代替案について、ご指示いただいた日本語訳と強調すべき点を盛り込み、正確かつ詳しくまとめます。

情報源の冒頭では、科学出版や多くの研究分野における現状として、レキシコグラフィックな意思決定ルールが採用されていることが指摘されています。これは、まず結果のp値が0.05という閾値を超えることが求められ、その後で初めて、先行研究や関連証拠、メカニズムの妥当性、研究デザインとデータ品質、現実世界のコストとベネフィット、発見の新規性といった他の要因（著者らはこれらをまとめて「見過ごされてきた要因 (neglected factors)」と呼んでいます）が考慮される、というものです。しかし、これらの見過ごされてきた要因への考慮は、しばしば不十分であると述べられています。

生物医学および社会科学は、発表された研究結果が驚くほど高い割合で再現に失敗するという広範な危機に直面しています。このような再現性の失敗は、しばしば小さな、時には途方もない介入から得られた巨大な効果の主張と関連しており、その主な証拠として、慣習的な0.05の閾値未満のp値を持つ比較、すなわち「統計的に有意」とされた比較が挙げられています。実際、現状では **p < 0.05 は科学的理論を支持する強い証拠と見なされており**、結果が発表されるだけでなく、真剣に受け止められるためにも要求されています。

**p < 0.05**は「**pが0.05未満**」と読みます。

情報源では、従来のp < 0.05ルールは、ノイズ追跡に対する安全策であり、したがって再現性の保証であると考えられていたとしていますが、近年では、研究者の自由度（“researcher degrees of freedom”）が豊富にあるため、純粋なノイズからでも統計的有意性を容易に得られることが明らかになったと述べています。その結果、現在の科学的慣行を考慮すると、低い再現率は予想されることであり、改革の呼びかけが切迫したものとなっています。

ダニエル・ベンジャミン氏ら72名の共著者は、「新しい発見の主張に対する統計的有意性のデフォルトのp値閾値を0.05から0.005に変更する」という代替案を提案しています。しかし、情報源の著者らは、この提案は現在の再現性の困難を克服するには不十分であると考えています。彼らは、この提案が「新しい効果の発見の主張に限定されている」ことや、「特定の閾値の選択は恣意的である」こと、そして「事前オッズ、検定される仮説の数、研究デザイン、タイプI誤差とタイプII誤差の相対的なコスト、および研究トピックによって異なる他の要因に依存すべきである」ことをベンジャミン氏らが認識している点を指摘しています。さらに、ベンジャミン氏らの多くが「帰無仮説有意性検定（NHST）よりも優れた統計的分析アプローチがあることに同意している」ことにも言及しています。

著者らは、ベンジャミン氏らの提案である「p値閾値の変更は単純であり、多くの研究者が受けた訓練と一致し、迅速に幅広い受け入れを達成するかもしれない」という特定の即時行動への重点に反対しています。彼らは、このステップが有益であるとは確信しておらず、短期的なプラスの効果（質の低い研究の減少）と中期・長期的なマイナスの効果（結果への過信、効果量の過大評価、重要な発見の軽視）の両方が考えられるため、この変更が科学の状態を改善するか劣化させるかについては「全く分からない」と述べています。最終的に、彼らはp値閾値（および他の統計的尺度に基づく閾値も）は一般的に悪い考えであると信じており、この問題は自身の検討範囲外であると見ています。

代わりに、そして結果として、情報源の著者らは別の代替案を提案しています。それは、**統計的有意性を放棄すること**です。彼らは、「クイックフィックス」や「より恒久的な修正を行うまでの洪水対策のダム」ではなく、NHSTパラダイムとそれに付随するp値閾値を、生物医学および社会科学における研究、出版、発見のためのデフォルトの統計パラダイムとして捨てることを推奨しています。具体的には、現状のように **p < 0.05**（または他の統計的閾値）によって決定される統計的有意性が、科学出版やより広範な統計的意思決定におけるレキシコグラフィックな意思決定ルールとして機能するのではなく、p値をその閾値スクリーニングの役割から降格させ、代わりに**連続的に扱い、見過ごされてきた要因と共に、多くの証拠の一つとして考慮されるべき**だと提案しています。

この推奨には3つの主要な理由があります。
1.  生物医学および社会科学において、圧倒的大多数の応用で用いられるゼロ効果・ゼロ系統誤差というシャープポイント帰無仮説は、一般的にあり得ないため、通常は関心がない。
2.  NHSTの標準的な使用法（この藁人形のようなシャープポイント帰無仮説の棄却を、ある好ましい対立仮説を支持する肯定的または決定的な証拠と見なすこと）は論理的誤謬であり、経験豊富な科学者や統計学者によっても日常的に誤った科学的推論をもたらす。
3.  p値や他の統計的閾値は、研究者全体としてのデータや結果に焦点を当てるのではなく、単一の比較を研究・報告することを奨励する。

NHSTの一般的な問題点については、さらに詳しく説明されています。効果が小さく変動しやすく、測定がノイズが多いという特徴を持つ生物医学および社会科学では、ゼロ効果・ゼロ系統誤差というシャープポイント帰無仮説自体があり得ない（「nil hypothesis」と揶揄される）と指摘されています。また、統計的有意性をスクリーニングする出版プロセスとノイズの多い推定値が組み合わさることで、発表される推定値が上方バイアスされ、しばしば符号も間違っている可能性があると述べられています。さらに、多重比較（実際の比較も潜在的な比較も）を行うことで、これらの問題はさらに悪化するとされています。

NHSTのもう一つの広範な問題は、証拠を「統計的に有意」と「統計的に有意でない」という異なるカテゴリに二分化（または「やや有意」を含む三分化）することに関連しています。よく知られた批判として、慣習的な0.05の閾値（または他のいかなるカットオフも）が完全に恣意的であるという点があります。

関連する批判として、そもそも閾値を持つことに問題があるというものがあります。証拠を統計的有意性の異なるカテゴリに二分化（または三分化）すること自体に「存在論的な根拠がない」と指摘されています。著者らはさらに進んで、ゼロ効果・ゼロ系統誤差という一般的に関心のない、あり得ない帰無仮説に対して定義される統計量であるp値に基づいて科学的証拠を評価することは、一般的に意味がないと述べています。

証拠の二分化または三分化は、誤った科学的推論も引き起こします。例えば、研究者は統計的有意性と実質的重要性（practical importance）を混同したり、見過ごされてきた要因を考慮した証拠のより包括的な視点を持つ代わりに、p値が0.05の閾値を超えるかどうかのみに大きく依存して科学的な結論を導き出したりします。さらに、証拠を異なるカテゴリに割り当てることが、それらの項目がカテゴリー的に異なるという結論への強い誘導となるため、彼らは二分法的思考（dichotomous thinking）に従事すると述べています。具体的には、慣習的に定義された統計的有意性の閾値に達した証拠を「差があることの証明」と解釈し、対照的に、この閾値に達しなかった証拠を「差がないことの証明」と解釈します。Gelman and Stern  は、「‘有意’と‘有意でない’の間の差は、それ自体統計的に有意ではない」ことを応用研究者が理解していない例を示しています。McShane and Gal  は、様々な分野の研究者（統計学者を含む）がp値を二分的に解釈し、p値の大きさではなく0.05未満かどうかのみに注目し、他の証拠（例：処置差の大きさ）を無視していることを示しています。

NHSTパラダイムに内在する証拠の二分化に関する問題は、近年のアメリカ統計学会の統計的有意性とp値に関する声明 [Wasserstein and Lazar, 2016] により、多くの注目を集めています。この声明の6つの原則のうち3番目の原則（「科学的な結論やビジネスまたは政策の決定は、p値が特定の閾値を通過するかどうかのみに基づいて下されるべきではない」）は、ベンジャミン氏らの提案のようなものに対して明示的に警告を発しています。

提案されたp < 0.005の閾値に関する具体的な問題点も挙げられています。
1.  ベンジャミン氏らは、0.005の閾値が対立仮説に有利な**一様最強力ベイズ検定** (UMPBT) に基づくベイズファクターの約14から26に対応すること、および偽陽性率を合理的なレベルまで減少させることを理由として挙げていますが、これらのレベルの選択に対する根拠はほとんど、あるいは全く提供されていません。
    **uniformly most powerful Bayesian test** および **UMPBT** は「**一様最強力ベイズ検定**」と訳されます。
2.  彼らの提案ルールを新しい効果に限定していることは問題があります。新しい効果の定義が不明瞭なため、彼らの推奨は全く非実用的になっています。これは、研究が漸進的かつ累積的であると考えられている領域では特にそうです。この提案された方針は、推奨が対処しようとしているまさにその問題である再現性に応用された場合に、非整合性をもたらします。
3.  多重比較（実際の比較も潜在的な比較も）が応用研究で当たり前に行われているという事実は、事前の研究計画書とデータ分析手順を登録した研究からのp値以外、厳密には全てのp値を無効にします。この懸念はベンジャミン氏らも認めています。
4.  ベンジャミン氏らの提案の根底にある数学的正当化は、少なからぬ批判を受けています。具体的には、提案の根底にある**一様最強力ベイズ検定** (UMPBTs) は、Johnson [2013a] によって導入・擁護され、その際にJohnson [2013b]（そして今回のBenjamin et al. ）において0.005を新しい閾値として使用するよう呼びかけられました。著者らはUMPBTsにいくつかの懸念点を見ています。
    *   生物医学および社会科学にとって最も関連性が高いと思われるのは、UMPBTアプローチが1世紀前のNeyman-Pearsonの二項決定および0-1損失関数の形式主義に深く根ざしていることです。この形式主義は、特定の制限された分布と検定問題の下での数学的最適化を可能にしますが、意思決定論的な観点からは非常に初歩的であり、シャープポイント帰無仮説検定のほとんどの目的にすら適合しないと述べています。
    *   より具体的には、NHSTパラダイムに暗黙的に含まれる0-1損失関数は、科学的学習のプロセスやコストとベネフィットに、近似的であっても一般的に対応しません。どのようなルールも暗黙的にType I誤差とType II誤差の特定のトレードオフを表現しますが、現実にはこのトレードオフは全ての結果のコスト、ベネフィット、確率に依存すべきであり、これらは目の前の問題に依存し、生物医学および社会科学の研究間で大きく異なります。UMPBTは、効果量の分布には対応しないが、一連の数学的仮定の下での最悪のシナリオを表すミニマックス事前分布に基づいています。
    *   手続きを閾値に依存させる定義は、1世紀前のFisherian仮説検定の答えの根本的な困難を再現します。Johnson [2013a] が主張するように、古典的な棄却域との完全な一致をさらに求めることは、この問題への真にベイズ的なアプローチの魅力を単純に否定することに等しく、さらに、現実的な統計モデルではこの一致は達成不可能です。
    *   より一般的には、**一様最強力**な事前分布（および検定）の概念は、多変量設定に容易に拡張されず、複雑な帰無仮説が邪魔なパラメータを含む現実的なケースにはさらに拡張されにくいと述べています。
    *   ベイズファクター自体も、統計的有意性の問題に対応する初歩的なNeyman-Pearson形式主義の結果であると指摘されています。

著者らは、仮説検定がベイズ的な方法で行われなければならないと言っているわけではありませんが、Johnson [2013a] のアプローチがベイズ的連結を失う範囲で、0.005ルールのベイズ的正当化も失われると述べています。したがって、0.005は、絶対的かつ文脈に依存しない意味では意味をなさない偽陽性と偽陰性の間の何らかの暗黙的なトレードオフによって正当化される、**別の恣意的な閾値になる**と述べています。

前進するためには何ができるでしょうか。統計は難しく、生物医学および社会科学のように効果が小さく変動し、測定がノイズが多い場合には特にそうです。クイックフィックスはありません。統計的有意性のデフォルトのp値閾値を変更したり、ゼロを含むかどうかに焦点を当てて信頼区間を使用したり、従来の分類と共にベイズファクターを使用して証拠の強さを評価したりする提案は、0.05の閾値を用いた現在のp値の使用と同じ、あるいは類似の問題を抱えています。具体的には、それぞれがゼロ効果・ゼロ系統誤差という一般的に関心のないあり得ない帰無仮説に対する閾値に基づいて証拠を暗黙的または明示的に分類します。さらに、それぞれが純粋な統計的尺度であり、伝統的に見過ごされてきた要因（すなわち、先行研究および関連証拠、メカニズムの妥当性、研究デザインとデータ品質、現実世界のコストとベネフィット、発見の新規性、および研究領域によって異なるその他の要因）の考慮を含む証拠のより全体的な視点を取ることができていないと指摘されています。

端的に言えば、それぞれが統計的錬金術の一種であり、無作為性を確実性に変えると偽って約束する、「**不確実性ロンダリング** (**uncertainty laundering**) 」です。これは、データから始まり、何らかのp値または他の統計的閾値が超えられたかどうかに基づいて、真偽の二分的な宣言（「効果がある」または「効果がない」という二値的な声明）で終わると述べられています。前進するための重要な第一歩は、不確実性を受け入れ、効果の変動を受け入れ始めること、そして、このような二分法によって提供される偽りの確実性の約束を放棄することで、世界について多く（実際にはより多く）を学ぶことができると認識することです。
**uncertainty laundering** は「**不確実性ロンダリング**」と訳され、これは重要な用語です。

著者らは、p値を「**禁止する** (ban) 」ことを**全く望んでいません**。代わりに、p値をその閾値スクリーニングの役割から降格させ、多くの証拠の一つとして考慮する方法について、編集者と査読者向けに一つ、著者向けに一つ、具体的な推奨事項を提案しています。

1.  **編集者と査読者へ**: 正確性と新規性の目標が対立する限り、現状からの大きな改善は、見過ごされてきた要因の重要性に関して、明確かつ体系的な姿勢をとることであると彼らは信じています。この推奨の具体的な運用化の一つは、これらの要因の考慮を査読プロセスの様々な段階に組み込むことかもしれません。例えば、ジャーナルのポータルは、編集者が決定した領域固有の要因を含む各要因に関するフィードバックを査読者から求めると共に、全体的な証拠の強さに関するフィードバックも求め、これらの評価に対する自由形式の理由付けも許可することができます。これらの評価は、編集者によって公に開示された（あるいは査読者自身の）各要因の重要度評価によって重み付けされる可能性があります。さらに、編集者は意思決定書簡で見過ごされてきた要因の重要性と評価について議論し、対処することで、証拠のより全体的な視点を確保できます。
    これに対して、ジャーナルは主張を支持するデータが純粋なノイズから十分に離れているかどうかを決定するために何らかの明確な閾値を必要とするのではないか、統計的閾値が証拠を構成するものの客観的な基準を提供し、それがジャーナル査読者の主観性や個人的バイアスに対する貴重な抑制となるのではないか、という反論があるかもしれません。これに対し、著者らは、そのような閾値が必要であったとしても、ノイズの多い結果を出版するコストとベネフィットは文脈によって大きく異なるため、p値に基づいて設定することは意味がないと主張します。さらに、p値は純粋に客観的な基準ではありません。同じデータと帰無仮説に対する異なるモデル仕様と統計的検定は異なるp値をもたらし、さらに問題を複雑にするのは、実践ではコーディングや除外などのデータプロトコルや分析手順に関する多くの主観的な決定が必要であり、これらは最終的に報告されるp値に強く影響することが多いです。最後に、ジャーナルがそのような閾値スクリーニングルールを必要とする理由が分からないと述べています。ジャーナルはすでに質的な要因に基づいて出版決定を一件ずつ行っており、p値がデフォルトのスクリーニングルールから単なる証拠の一つに降格されても、これは継続可能です。実際、p値、ベイズファクター、または他の統計的尺度であろうと、単一の数値で主観性や個人的バイアスを排除することはできません。
    彼らは、例えばp値が0.2であったり、ゼロを含む90%信頼区間であったりする結果を含む記事であっても、それが関心のある理論や応用的な問題に関連しており、解釈が十分に正確であれば、出版することは**全く受け入れられる**と信じています。また、例えばp値が0.001であった結果を出版しても、これが何か好ましい対立仮説の真実を意味すると見なされるべきではないとも述べています。
    p値は、結果が特定の帰無モデルによってどれだけ容易に説明されるかという問題に関連していますが、これが出版において決定的な要因であるべき理由はありません。結果は帰無モデルと一致する可能性がありますが、依然として科学や政策の議論に関連し得るし、結果は帰無モデルを棄却する可能性がありますが、科学や政策に関心のあるものを何も提供しないかもしれません。
    要約すると、ジャーナル編集者は論文を受け入れ、読者に関連する証拠を提示することを自由に行うべきであり、そうすることができます。彼らは、例えば興味深い発見に対する証拠は弱いものの、既存のデータは依然としてヌル効果と一致していると述べる論文を見ることを、出版プロセスがそのような発見をスクリーニングしたり、著者が統計的有意性を得るために研究者の自由度を悪用して不正行為を奨励したりするよりも、**はるかに望んでいます**。
2.  **著者へ**: p値や他の統計的閾値を超える単一の比較に焦点を当てるのではなく、**データと関連する結果の全体を研究し報告すること**を推奨しています。その際、著者は見過ごされてきた要因を使用して統計分析と記述を動機付けることを推奨しています。例えば、原稿にこれらの要因それぞれに順に対処するセクションを含めることができます。例えば、このセクションでは、Gelman and Carlin  で議論されているように、対象分野の知識や効果量の期待値の文脈で研究デザインを議論することができます。別の例として、このセクションでは、疑問のメカニズムの妥当性を（i）問題の効果の仮説的なメカニズムを形式化し、その様々な構成要素を明確にすることで、（ii）どの構成要素が研究で測定・分析されたかを明確にすることで、そして（iii）提案されたメカニズムを支持するデータの側面だけでなく、（全データにおいて）それに矛盾する側面も議論することで、議論することができます。
    この推奨（データと結果の全体を研究し報告すること）は、科学の非常に基本的な原則であるため、言及する必要すらないと考える人もいるかもしれません。しかし、そうではありません！ 上述のように、科学出版における現状は、p < 0.05が結果が出版されるために**事実上常に要求される**レキシコグラフィックな意思決定ルールであり、いくつかの例外はあるものの、標準的な慣行はそのような結果に焦点を当て、関連する全ての発見を報告しないことです。これは、著者がデータと結果を研究し報告する方法に明らかに影響を与えています。

著者らの提案は、統計的有意性の閾値が科学出版において焦点が当てられてきましたが、神経画像、医学、政策分析、ビジネスなど、他の統計的意思決定の分野でも同じ問題が発生すると指摘しています。これらの分野でも閾値が生じ、研究プロジェクト内でも、研究者が予備的な発見に基づいてどの道筋を追求する価値があるかを決定する際に閾値が生じます。著者らがp値をその閾値スクリーニングの役割から降格させ、見過ごされてきた要因を強調するという提案は、これら全ての場面に適用されます。例えば、神経画像では、ボクセル単位のNHSTアプローチは要点を外しており、通常は真のゼロはなく、変化は一般的に全ての脳の場所で常に起こっていると述べています。推定値と不確実性の画像をグラフ化することは理にかなっていますが、閾値を使用する利点は見られないと述べています。規制、政策、ビジネスの決定については、文脈に依存しない統計的閾値よりもコストベネフィット計算が明らかに優れているように見えます。

費用便益計算が明白でない純粋な研究シナリオ（例えば、ある疾患の治療に使用される2つの薬剤の効果ではなく、根底にあるメカニズムの比較など）であっても、p値や他の統計的閾値に価値は見られないと述べています。代わりに、彼らは仮説的なメカニズム研究者に、推定値、標準誤差、信頼区間などの結果を単に報告し、統計的に決定的な結果でないものは将来の研究を動機付けるのに適切であるとしています。

どの研究ライン（例えば、アイデア、薬剤、遺伝子）をさらに追求するかを決定するためのスクリーニングデバイスとしてp値や他の統計的閾値を使用する直感的な魅力はあると認めつつ、根本的にこのアプローチはデータの効率的な使用にはなりません。帰無仮説に基づいた確率と、潜在的な研究のリードを追求することから得られる潜在的な利益、あるいはそのリードが最終的に成功するであろう予測確率との間には、一般的な関連性がないと述べています。
代わりに、どの研究ラインをさらに追求するかについて決定を下す必要がある範囲で、効果量の分布と変動のモデルを使用してそのような決定を行うことを推奨しており、帰無モデルから間接的に推論するのではなく、関心のある仮説を直接扱うことを推奨しています。また、可能な限り、より正確な個人レベルの測定、個人内または縦断的デザインのより広範な使用、および情報的な事前分布を使用するモデル、変動する処置効果を特徴とするモデル、および多階層またはメタアナリティックな性質を持つモデルの検討を増やしたいと考えています。

著者らの推奨自体が科学における再現性の危機を解決するわけではありませんが、彼らはそれが研究者を無関係な統計的目標の追求から遠ざけ、理論、メカニズム、および測定の理解へと促す有益な効果を持つと信じています。また、彼らは、ルーチン化された「発見」のパラダイムや「効果がある」または「効果がない」という二値的な声明から、不確実性と変動を受け入れる連続的で必然的に不完全な学習のパラダイムへと彼らを推進することを期待しています。

---

提示されたソースに基づき、ご質問の内容について正確にかつ詳しくまとめます。

ご質問にあるように、"p < 0.05" は「pが0.05未満」と読みます。また、"uncertainty laundering" は「**不確実性ロンダリング**」と訳し、"uniformly most powerful Bayesian test" および "UMPBT" は「一様最強力ベイズ検定」と訳します。

以下にソースの内容を要約します。

1.  **現状と問題提起**
    *   科学論文の出版や多くの研究分野における現状は、結果が最初に p値が0.05未満 の閾値を超えることが求められ、その後で初めて、事前の証拠や関連証拠、メカニズムの妥当性、研究デザインやデータの質、現実世界のコストと利益、発見の新規性といった要因（これらはまとめて「無視されがちな要因」と呼ばれる）が考慮されるという、辞書式決定ルールに基づいています。これらの要因は研究領域によって異なります。
    *   生物医学分野や社会科学分野は、出版された研究結果の再現率が憂慮すべきほど低いという広範な危機に直面しています。再現性の失敗は、しばしば、ごくわずかな、時には不合理な介入から得られた「統計的に有意」とされる、大きな効果の主張に関連しています。
    *   統計的有意性（通常 pが0.05未満）は、科学的理論を強く支持する証拠とみなされ、結果が出版されるだけでなく、真剣に受け止められるためにも必要とされています。
    *   伝統的に、pが0.05未満というルールは、ノイズ追跡に対する安全策であり、再現性を保証するものと考えられていました。しかし、「研究者の自由度」（researcher degrees of freedom）が十分に多いため、純粋なノイズからでも統計的有意性を容易に得られることが明らかになっています。その結果、現在の科学的実践を考慮すると、再現率の低さは当然のことと予想されます。

2.  **代替案とその批判**
    *   ダニエル・ベンジャミン氏ら72名の共著者による一つの代替案は、新しい発見の主張に対する統計的有意性のデフォルトのp値閾値を0.05から0.005に変更するというものです。
    *   著者らは、この提案は現在の再現性の困難を克服するには不十分だと考えています。閾値を変更するこのステップが役立つかどうかは不明であり、プラスとマイナスの両方の結果が考えられます。
    *   具体的に、ベンジャミン氏らの提案には以下の問題点があります。
        *   0.005という閾値が選択された根拠（代替仮説を支持する約14から26のベイズ因子、および妥当なレベルに偽陽性率を下げること）については、レベルの選択に対する正当化がほとんど、あるいは全く提供されていません。
        *   提案されたルールを新しい効果に限定していること自体が問題です。何が新しい効果を構成するのか定義されていないため、彼らの推奨は全く非現実的になっています。また、この方針は、推奨が対処しようとしているまさにその問題である再現性に適用された場合に、非一貫性（incoherence）を引き起こします。
        *   応用研究では、未補正の多重比較が一般的であるという事実が、厳密には、事前登録されたプロトコルとデータ解析手順を持つ研究以外のすべてのp値を無効にしています。
        *   ベンジャミン氏らの提案の根底にある数学的な正当化は、少なからぬ批判を受けています。特に、提案の根底にある**一様最強力ベイズ検定**（UMPBT）は、世紀前のネイマン・パーソン形式主義に深く根ざしており、二値決定と0-1損失関数に基づいています。これは意思決定論の観点からは非常に初歩的です。
        *   NHSTパラダイムに内在する0-1損失関数は、一般的に科学的学習のプロセスやコストと利益に近似的にすら対応していません。タイプIエラーとタイプIIエラーのトレードオフは、問題に依存し、コスト、利益、およびすべてのアウトカムの確率に依存するべきですが、0.005ルールはこれを回避しています。**一様最強力ベイズ検定**（UMPBT）は、効果サイズの分布に対応しないミニマックス事前分布に基づいており、数学的仮定のもとでの最悪シナリオを表しています。
        *   閾値への依存を定義することは、世紀前のフィッシャー流の仮説検定への回答における根本的な困難を再現しています。このアプローチがベイズ的な繋がりを失う限り、0.005ルールのベイズ的な正当化も失われ、文脈に依存しないという意味では、別の単なる恣意的な閾値となってしまいます。

3.  **著者らの提案：統計的有意性の放棄**
    *   著者らは、代替案として、統計的有意性を放棄することを提案しています。pが0.05未満（または他の統計的閾値）によって決定される統計的有意性が、科学論文出版や統計的意思決定における辞書式決定ルールとして機能する現状に対し、p値は閾値によるスクリーニングの役割から降格され、連続的に扱われ、無視されがちな要因と同様に、多くの証拠の一つとして考慮されるべきだと提案しています。
    *   この推奨の主な理由は3つあります。
        *   生物医学分野および社会科学分野において、圧倒的多数の応用で使用される「効果がゼロかつ系統誤差がゼロ」というシャープポイントの帰無仮説は、一般的にありそうもないため、関心の対象ではありません。コーエンはこれを「ナル仮説」と揶揄し、「常に偽である」としています。テューキーは2つの処置は「常に異なる」と述べています。
        *   NHSTの標準的な使用法（この藁人形のようなシャープポイント帰無仮説の棄却を、何らかの好ましい対立仮説を支持する肯定的、あるいは決定的な証拠として受け取る）は、経験豊富な科学者や統計家でさえ日常的に誤った科学的推論を引き起こす論理的誤謬です。
        *   p値や他の統計的閾値は、研究者に対し、データの全体や関連する結果に焦点を当てるのではなく、単一の比較を研究し報告することを奨励します。
    *   無視されがちな要因を含むより包括的な証拠の視点を持たずに、p値が特定の閾値を超えるかどうかに基づいて科学的結論を下すことは誤りです。証拠を異なるカテゴリーに二値化（または三値化）することは、それらがカテゴリー的に異なるという結論への強い誘因となります。例えば、統計的有意性と実際的な重要性を混同したり、統計的に有意であることとそうでないことの違い自体が統計的に有意でないことを理解しなかったりします。

4.  **前進するための方法**
    *   生物医学分野や社会科学分野のように効果が小さく変動が大きく、測定がノイズが多い場合、統計は難しいです。簡単な解決策はありません。統計的有意性のデフォルトのp値閾値を変更したり、ゼロを含むかどうかに焦点を当てて信頼区間を使用したり、ベイズ因子と従来の分類を使用したりといった提案は、現在のp値と0.05閾値の使用と同じか類似の問題を抱えています。
    *   これらはそれぞれ、**不確実性ロンダリング**（**uncertainty laundering**）の一形態であり、統計的アルケミー（錬金術）として、無作為性から確実性を偽って約束します。データから始まり、p値や他の統計的閾値が超えられたかどうかに基づいて、「効果がある」または「効果がない」という二元的な真偽の宣言で終わります。
    *   前進するための重要な第一歩は、不確実性を受け入れ、効果の変動を受け入れることです。このような二値化が提供する確実性の偽りの約束を放棄することで、世界についてより多く学ぶことができます。
    *   p値を「禁止」したいわけではありません。そうではなく、p値が閾値によるスクリーニングの役割から降格され、多くの証拠の一つとしてのみ考慮されるようにするための2つの具体的な推奨を提供します。
        *   **編集者と査読者へ**：無視されがちな要因の重要性に関して、明確で体系的な立場を取るべきです。例えば、査読プロセスにこれらの要因の考慮を組み込むことができます。雑誌は、特定の要因や証拠全体の強さに関するフィードバックを査読者から求め、その評価を編集者が公表した重要度に基づいて検討することができます。決定書簡でこれらの要因の重要性や評価について議論することも、より包括的な証拠の視点を保証します。雑誌は閾値によるスクリーニング規則を必要としません。p値は、モデルの特定やデータ解析手順の主観的な決定に強く影響されるため、純粋に客観的な基準ではありません。単一の数値が主観性や個人的バイアスを排除することはできません。
        *   例えば、p値が0.2の結果や、ゼロを含む90%信頼区間を持つ結果であっても、関心のある理論的または応用的な問題に関連しており、解釈が十分に正確であれば、論文を出版することは全く受け入れられます。p値が0.001の結果であっても、それが何らかの好ましい対立仮説の真実を意味すると受け止められる必要はありません。
        *   **著者へ**：p値や他の統計的閾値を超える単一の比較に焦点を当てるのではなく、データの全体や関連する結果の全体を研究し報告することを推奨します。その際、無視されがちな要因を使用して、統計分析と執筆を動機づけることを推奨します。例えば、これらの要因それぞれについて、データの全体や結果の文脈で直接的に述べるセクションを原稿に含めることができます。
    *   この推奨は、事前にプロトコルや分析手順を決定する事前登録研究に特に適していますが、そうでない場合でも、多宇宙分析などを利用して、収集されたデータに基づいて可能な複数のプロトコルや分析手順、比較のアイデアを得ることができます。

5.  **科学出版以外の応用**
    *   統計的有意性の閾値に関する同じ問題は、脳画像解析（voxelwise NHSTを使用して報告する結果を決定）、医学（FDAのような規制機関がNHSTを使用して新薬承認を決定）、政策分析（NGOなどが介入が有益かどうかを決定）、ビジネス（A/Bテストで二値決定） など、他の統計的意思決定領域でも発生します。
    *   これらの状況にも著者らの提案は適用されます。脳画像解析では、推定値と不確実性のグラフ化が閾値の使用より優れています。規制、政策、ビジネスの決定には、文脈に依存しない統計的閾値よりもコスト-利益計算が明らかに優れています。純粋な研究シナリオでも、p値や他の統計的閾値に価値はありません。推定値、標準誤差、信頼区間などを報告し、統計的に決定的な結果でない場合は将来の研究の動機付けとすべきです。
    *   研究の方向性を追求するためのスクリーニング装置としてp値や他の統計的閾値を使用することには直感的な魅力がありますが、根本的にはデータ効率の良い利用方法ではありません。
    *   どの研究ラインを追求すべきか決定する必要がある場合、効果サイズと変動の分布のモデルを使用して意思決定を行い、帰無モデルから間接的に推論するのではなく、関心のある仮説を直接扱うことを推奨します。可能であれば、より正確な個人レベルの測定、個人内または縦断的デザインのより大きな使用、情報的な事前分布、変動する処置効果、多階層またはメタ分析的な性質を持つモデルの考慮を増やしたいと考えています。

これらの推奨は、科学における再現性の危機を単独で解決するものではありませんが、研究者を無関係な統計的目標の追求から、理論、メカニズム、測定の理解へと押し進めるという有益な効果をもたらすと考えています。また、「発見」という日常的なパラダイムや、「効果がある」「効果がない」という二元的な声明から、不確実性と変動を受け入れる連続的で必然的に欠陥のある学習のパラダイムへと移行させることを期待しています。