マクエルリース著「統計的再考 第2版」についての詳細な説明を承りました。本書は、統計モデリングを単なる「検定法」のコレクションとしてではなく、「ゴーレム工学」という統一された枠組みで捉え、統計的推論を再考することを目的としています。特に、すべてのモデルは間違っているが、役に立つものもある、というジョージ・ボックスの格言が、本書全体の哲学を貫いています。

以下に、各章とそのセクション・サブセクションのタイトルと含意について、詳しく解説します。

---

### 第1章：プラハのゴーレム (The Golem of Prague)

この章では、統計モデルをチェコの伝説に登場する粘土の巨人「ゴーレム」に例え、その本質と限界について考察します。

*   **1.1. Statistical golems (統計的ゴーレム)**
    *   **含意**: 統計的手順は、忠実に計算を実行する強力な「粘土のロボット」であり、独自の意図や知恵はありません。これらは、自然選択の強さやニュートリノの速度を測定するためなど、科学のあらゆる分野で現象を測定するための「補綴物（プロテーゼ）」として機能します。
    *   しかし、ゴーレムは文脈が不適切であっても判断せず、ただ指示通りに動くだけです。従来の統計学の入門コースでは、「検定法」と呼ばれている事前に作られたゴーレム達の動物園（a zoo of pre-constructed golems known as “tests”） が提供されますが、これらは柔軟性がなく（inflexible）、新しい研究状況では予期せぬ形で破綻する（fragile）危険性があります。

*   **1.2. Statistical rethinking (統計的再考)**
    *   **含意**: 統計的推論には多くの問題があるため、この章では、従来の「あらかじめ作られた検定法を選ぶ」という枠組みから脱却し、統計的ゴーレムの「計算上の基礎（computational nuts and bolts）」を理解することの重要性を強調しています。
    *   **帰無仮説有意性検定（NHST）への批判**: 多くの学者が統計的推論の目標を帰無仮説の検定だと誤解していますが、これはカール・ポパーの反証主義哲学に反しています。NHSTは通常、研究仮説自体ではなく、帰無仮説を反証するために使われます。
    *   **反証の限界**: 「測定が重要」であるため、仮説が観測Dを内包し、Dが見つからなかった場合に仮説Hが偽であると結論付ける「破壊の方法（modus tollens）」 は、科学において常に機能するわけではありません。これは、データがモデルを反証していると思っても、別の観測者が方法や測定を疑問視する可能性があるためです。
    *   **仮説とモデルの区別**: 仮説はモデルではないため（Hypotheses are not models）、すべてのモデルが「間違っている（false）」 以上に、モデルが棄却されたからといって仮説が偽であるとは論理的に言えません。統計モデルは変数間の「関連性」しか表現せず、特定の「因果関係」を体現するものではないため、一つの統計モデルが複数のプロセスモデルや仮説と整合する可能性があります。
    *   **エントロピーとモデルの同定**: 統計モデルが多くの詳細なプロセスモデルに対応するのは、正規分布、二項分布、ポアソン分布など、最大エントロピー分布である指数族の分布に依存しているためです。これにより、基礎となるプロセスを特定できなくても、有用な統計的作業を行うことができます。
    *   **連続的な仮説の難しさ**: 「すべての白鳥は白い」のような単純な仮説ではなく、「白鳥の80%は白い」のような連続的な仮説の場合、黒い白鳥を観測しても、その仮説が偽であるとは結論できません。この場合、目的は仮説の真偽を証明するのではなく、白鳥の色の分布を正確に推定し説明することになります。

*   **1.3. Tools for golem engineering (ゴーレム工学の道具)**
    *   **含意**: 反証を模倣することが統計的手法に対する一般的な有用なアプローチではない場合、私たちは「モデリングする（to model）」べきです。研究者が求めるのは、特殊目的の統計的手順を設計、構築、改良するための統一された理論です。本書では、このための主要な4つのツールに焦点を当てています。
    *   **(1) Bayesian data analysis (ベイズデータ分析)**
        *   **含意**: データから世界について学ぶための最も効果的で一般的なアプローチの一つです。ベイズデータ分析は、問題をモデルの形で受け取り、論理を用いて確率分布の形で答えを導き出します。これは、データがどれだけの方法で発生し得るかを「数える」ことに他なりません。
        *   **頻度主義との対比**: 頻度主義的アプローチが、非常に大きなサンプルにおける事象の頻度によって確率を定義し、仮想的なデータの再サンプリングに基づく不確実性を前提としているのに対し、ベイズ的ゴーレムは「ランダム性」を世界の特性ではなく、「情報の特性」として扱います。
        *   **「信念」と解釈**: ベイズデータ分析は、特定の「信念」や主観的な意見を呼び起こすものではなく、情報を処理するための純粋に論理的な手順です。しかし、多くの科学者が非ベイズ的結果をベイズ的に解釈する傾向があり、ベイズモデルはより直感的な解釈を導くとされます。20世紀後半から、計算手法の進歩により広く受け入れられるようになりました。
    *   **(2) Model comparison (モデル比較) と prediction (予測)**
        *   **含意**: 複数のもっともらしいモデルがある場合、良い予測をするモデルを選択すべきです。しかし、未来のデータは過去のデータと全く同じではないため、**過剰適合（overfitting）**は予測における主要な逆説です。複雑なモデルほど過剰適合しやすく、過去のデータに過剰に適合しすぎると、かえって未来のデータに対する予測性能が悪化します。
        *   **交差検証（cross-validation）**と**情報量規準（information criteria）**は、予測精度を推定し、モデルの過剰適合傾向を評価し、影響力の強い観測値を特定するのに役立ちます。
    *   **(3) Multilevel models (多階層モデル)**
        *   **含意**: 過剰適合に対処するのに役立つツールです。これらは「部分的プーリング（partial pooling）」 という統計的な技法を利用し、データ内の単位間で情報を共有することで、すべての単位に対してより良い推定値を生み出します。これにより、研究者が測定の「クラスター」や「グループ」を認識する文脈で特に有用です。
    *   **(4) Graphical causal models (グラフィカル因果モデル)**
        *   **含意**: モデルが因果的に間違っていても、より良い予測をすることがあるという「予測における二次的な逆説」が存在します。これは、予測に焦点を当てることが因果推論を誤導する可能性があることを意味します。
        *   **因果モデルの必要性**: 統計ツールは、エビデンスから原因を推論するという根本的な問題に対処するものではありません。統計的ゴーレムは因果関係を理解せず、関連性しか理解しません。真の因果推論のためには、統計モデルとは独立した「因果モデル」 が必要です。これは**有向非巡回グラフ（DAG）** として表現され、どの統計モデルが妥当な因果推論を提供できるかを論理的に導き出します。
        *   **因果関係サラダ（causal salad）**: 統計モデルに様々な「制御」変数を無計画に投入し、推定値の変化を観察して因果関係について物語ることです。これは、見落とされた変数だけが因果関係について誤解させるという考えに基づいているように見えますが、含められた変数も同様に交絡を引き起こす可能性があります。

*   **1.4. Summary (まとめ)**
    *   **含意**: 第1章は、人気の統計哲学と科学哲学を**統計的再考**するよう主張しました。帰無仮説を検定するためのブラックボックスなツールの中から選択するのではなく、自然現象の複数の非帰無モデルを構築・分析することを学ぶべきであると述べています。この目標を支援するために、ベイズ推論、モデル比較、多階層モデル、グラフィカル因果モデルが導入されました。

---

### 第2章：小世界と大世界 (Small Worlds and Large Worlds)

この章では、ベイズ推論の基礎となる概念である「可能性を数える」という考え方を、**小世界（small world）**と**大世界（large world）**という枠組みの中で説明します。小世界はモデルの自己完結的な論理世界を指し、大世界は現実の世界を指します。

*   **2.1. The garden of forking data (分岐するデータの庭)**
    *   **含意**: ベイズ推論は、データの発生経路として考えられるすべての「可能性を数え、比較する」ことから構築されます。この概念は、ホルヘ・ルイス・ボルヘスの短編小説「分岐するこみちの庭（The Garden of Forking Paths）」 に由来しており、物語の中で矛盾に満ちた本が登場するように、ベイズ分析は、代替のイベントのシーケンスが育成される「分岐するデータの庭」 と例えられます。データが観測されるにつれて、これらの代替シーケンスの一部が論理的に排除され、最終的には私たちの知識と論理的に整合するものだけが残ります。
    *   **尤度の概念**: 各モデル（仮説）が観測されたデータを生成しうる経路の数を数えることで、相対的な**相性の良さ（compatibility）** を測定します。このカウントは「事前（prior）」 と呼ばれる既存の情報と掛け合わせることで更新されます。
    *   **正直な無知の原則（principle of honest ignorance）**: データが何によって引き起こされたか分からない場合、より多くの方法でデータを生成しうる潜在的な原因の方が、より**相性が良い（compatible）** という考え方です。
    *   **確率への変換**: このカウントをそのまま扱うのは難しいため、通常は確率に標準化します。
    *   **Rethinking: Justification (正当化)**: 分岐する庭を通過する経路の数を相対的な相性の良さの尺度として使うことは、論理的にも数学的にも正当化されます。これは実際に機能し、多くの成功した現実世界への応用があります。
    *   **Rethinking: Original ignorance (最初の無知)**: 以前の情報がない場合に、各モデルに同じ数を割り当てる「無差別原理（principle of indifference）」は一般的ですが、本書では推奨せず、モデルの構造と科学的文脈からより良い事前情報を活用することを推奨しています。

*   **2.2. Building a model (モデルの構築)**
    *   **含意**: ベイズ統計モデルの従来の形式を、地球儀投げの例を用いて提示します。モデル構築は、データがどのようにして得られたかという「データ物語（data story）」 を語ることから始まります。この物語は記述的でも因果的でもあり、新しいデータをシミュレートするのに十分なほど完全であるべきです。
    *   **Rethinking: The value of storytelling (物語の価値)**: データ物語を概説することで、追加の質問に答える必要があることに気づくことが多く、曖昧な仮説を解決し、モデルの改訂につながる重要な気づきを得ることができます。
    *   **更新プロセス**: 各観測が追加されるにつれて、曲線は以前のすべての観測と整合するように更新されます。すべての結論は、将来の推論の出発点となります。
    *   **Rethinking: Sample size and reliable inference (サンプルサイズと信頼できる推論)**: ベイズ推定は任意のサンプルサイズに対して有効であり、より多くのデータが役立つことは確かですが、推定値は明確で有効な解釈を持ちます。ただし、初期の相性の良さ、すなわち**事前分布（prior）**に依存します。
    *   **モデルの監視と批判**: モデルの確実性は、モデルが優れていることの保証ではありません。モデルの推論はモデルに条件付けられているため、モデルがデータをどのように処理するかを理解し、その出力を吟味することが重要です。モデルが「真」であるかどうかをテストするのではなく、その目的への「適切性（adequacy）」を評価することが目標です。
    *   **Rethinking: Deflationary statistics (デフレ的統計学)**: ベイズ推論が利用可能な最も優れた汎用推論手法である可能性がある一方で、それは私たちが望むほど強力ではないことを認めています。いかなる推論アプローチも普遍的な保証を提供するものではありません。

*   **2.3. Components of the model (モデルの構成要素)**
    *   **含意**: ベイズモデルの内部構造を、その主要な構成要素である**尤度（likelihood）**と**事前分布（prior）**に焦点を当てて詳述します。
    *   **Rethinking: A central role for likelihood (尤度の中心的な役割)**: ベイズモデルと非ベイズモデルのどちらにおいても、最も影響力のある仮定は、データに割り当てられる分布、すなわち尤度関数です。サンプルサイズが増加するにつれて、尤度は推論においてますます重要になります。
    *   **事前分布（prior）の役割**: 自然科学や社会科学におけるベイズデータ分析では、事前分布はモデルの一部として扱われ、モデルの他の構成要素と同様に選択、評価、改訂されるべきです。統計分析は本質的に主観的ですが、事前分布やベイズデータ分析は、尤度や有意性検定に必要な再サンプリングの仮定よりも本質的に主観的であるわけではありません。
    *   **Rethinking: Prior, prior pants on fire (事前分布、事前分布、嘘つき)**: 歴史的にベイズ推論の反対者は事前分布の恣意性を批判してきましたが、実際には事前分布を使って嘘をつくのは容易に露呈するため、統計で嘘をつく目的であれば、尤度のより不透明な仕組みを利用する方が賢明であると述べています。

*   **2.4. Making the model go (モデルを動かす)**
    *   **含意**: ベイズモデルが実際にどのように計算を実行し、データから推論を生成するかを説明します。ベイズの定理は、事前分布の経路数と新しい経路数（尤度）の積として、圧縮されたカウントとして表現されます。
    *   **Rethinking: Bayesian data analysis isn’t about Bayes’ theorem (ベイズデータ分析はベイズの定理に関するものではない)**: ベイズデータ分析がベイズの定理の使用によって区別されるという一般的な認識は誤りです。ベイズの定理はあらゆる確率の概念の下で最終的に使用されます。ベイズ的アプローチがより広範にベイズの定理を使用できるのは、観測できない理論的実体（パラメータやモデル）に関する不確実性を定量化するためです。
    *   **Rethinking: How you fit the model is part of the model (モデルの適合方法はモデルの一部である)**: モデルの適合方法の詳細もモデルの一部として考慮すべきです。なぜなら、異なる数値手法は異なる間違いや妥協点をもたらすからです。
    *   **2.4.4. Quadratic approximation (二次近似)**: グリッド近似の代替手法として導入されます。モデルのパラメータ数が増加するとグリッド近似は急速に計算コストが増大するため、二次近似がより効率的です。均一事前分布または大量のデータがある場合、二次近似は**最尤推定（maximum likelihood estimate, MLE）**とその標準誤差に相当することが多いです。
    *   **2.4.5. Markov chain Monte Carlo (マルコフ連鎖モンテカルロ, MCMC)**: 多階層モデルのような複雑なモデルでは、グリッド近似も二次近似も満足のいくものではないため、MCMCが最も人気のある手法として導入されます。MCMCは、後述するハミルトニアンモンテカルロ（HMC）のような高度な手法を含み、直接事後分布を計算するのではなく、事後分布からサンプルを抽出します。これらのサンプルは、事後分布の特性を要約し、操作するために使用されます。

*   **2.5. Summary (まとめ)**
    *   **含意**: この章では、ベイズデータ分析の概念的な仕組みが導入されました。推論の目標は**事後分布（posterior probability distribution）**であり、これはデータに関する各推測された原因がデータを生成しうる相対的な経路の数を示します。これらの相対的な経路数（尤度と事前分布の結合）は、異なる推測の**相性の良さ（plausibilities）**を示します。これらの相性の良さは、観測値に基づいて更新されるプロセス、すなわち**ベイズ更新（Bayesian updating）**を通じて得られます。

---

### 第3章：想像をサンプリングする (Sampling the Imaginary)

この章では、事後分布からの「サンプル」を操作するための基本的なスキルを教えます。これらのサンプルは、積分計算の問題をデータ要約の問題へと変換し、ベイズ推論をより直感的で実践的にします。

*   **含意**: 「想像をサンプリングする」とは、実際に起こった事象をサンプリングするのではなく、モデルによって定義された理論的な確率分布（パラメータの事後分布）から想像上の値を抽出することです。これにより、複雑な計算を回避し、より多くの質問に答えられるようになります。

*   **Rethinking: Why statistics can’t save bad science (なぜ統計が悪い科学を救えないのか)**
    *   **含意**: 科学的推論が仮説の真偽をベイズの定理で判断する問題は、医療検査のシナリオ（例：吸血鬼検査）と論理的に同じ構造をしています。しかし、統計的手順（ベイズ的であろうとなかろうと）は、仮説が真である「基本率（base rate）」を改善する上ではほとんど役に立たないことを示します。真の仮説の基本率を高めるためには、**検定ではなく、「思考」が必要**です。

*   **3.2.2. Intervals of defined mass (定義された質量区間)**
    *   **含意**: 科学論文で一般的に報告される「信頼区間」の代わりに、**相性区間（compatibility interval）**という用語を導入します。これは、モデルとデータと**相性が良い（compatible）** パラメータ値の範囲を示します。「信頼」や「信用」といった不当な含意を避けるため、「相性区間」という言葉を使用します。
    *   **パーセンタイル区間（PI）**と**最高事後密度区間（HPDI）**: 事後分布を要約するための2つの一般的な方法です。HPDIは指定された確率質量を含む最も狭い区間であり、パラメータ値とデータとの相性の良さを最もよく表します。
    *   **「信頼区間」の誤解**: 「95%信頼区間は真のパラメータ値がその区間に95%の確率で含まれる」という解釈は、厳密な非ベイズ統計推論では正しくありません。これは「小世界（small world）」の数値であり、モデルの論理世界でのみ真であり、現実の世界（大世界）にはそのまま適用されません。

*   **3.3. Sampling to simulate prediction (予測をシミュレートするためのサンプリング)**
    *   **含意**: モデルから観測された結果を生成することは、モデル設計、モデルチェック、予測シミュレーションなど、少なくとも4つの異なる理由で有用です。
    *   **3.3.1. Dummy data (ダミーデータ)**: ベイズモデルは常に**生成可能（generative）**であり、観測値をシミュレートできます。尤度関数は両方向に機能し、観測された値がどれだけ尤もらしいかを伝えるだけでなく、パラメータが与えられた場合に可能な観測値の分布を定義します。
    *   **Rethinking: Sampling distributions (サンプリング分布)**: 非ベイズ統計ではサンプリング分布がパラメータ推論の基礎ですが、本書では事後分布が推論の中心であり、サンプリング分布は直接推論には用いられません。
    *   **3.3.2. Model checking (モデルチェック)**:
        *   **ソフトウェアの動作確認**: モデルの適合が正しく行われたかを、モデルがデータをどれだけうまく再現するか（回帰予測、retrodiction）をチェックすることで確認します。
        *   **モデルの適切性の評価**: モデルがデータ生成プロセスと「真に」一致するかどうかをテストするのではなく、モデルがデータをどれだけうまく説明できないかを評価し、モデルの理解、改訂、改善につなげます。
        *   **「より極端（more extreme）」とは何か**: モデルの観測値からの逸脱度を測定する際、データを見る方法は非常に多く、「より極端」を定義する方法も様々です。従来のP値は、モデルが期待する通りにデータを見る非常に弱い形式のモデルチェックに過ぎません。想像力に富んだチェックは主観的ですが、非常に強力です。

*   **3.4. Summary (まとめ)**
    *   **含意**: この章では、事後分布を操作するための基本的な手順が導入されました。主要なツールは、事後分布から抽出されたパラメータ値のサンプルであり、これらを使用することで、積分計算の問題をデータ要約の問題へと変換できます。これらのサンプルは、区間推定、点推定、事後予測チェック、その他のシミュレーションに利用できます。事後予測チェックは、ソフトウェアが正しく動作したかを確認し、モデルが不十分な点を探索するのに役立ちます。

---

### 第4章：地心モデル (Geocentric Models)

この章のタイトル「地心モデル」は、データ駆動型で現象論的な統計モデル、特に線形回帰モデルを、天動説（地球中心の宇宙モデル）になぞらえています。天動説が複雑な惑星の動きを驚くほど正確に予測できた一方で、宇宙の真の構造（太陽中心）とは異なっていたように、統計モデルもデータにうまく適合し、優れた予測を行うことができますが、必ずしも基礎となる因果プロセスを正確に反映しているわけではない、という含意があります。

*   **4.1. Why normal distributions are normal (なぜ正規分布が正規なのか)**
    *   **含意**: 正規分布（ガウス分布）が自然界で頻繁に現れるのは、多数の小さな独立した影響が合成されるプロセスから生じるためです。これは、人間の身長などの複雑な現象をモデル化する際に、その基礎となるミクロなプロセス（例えば、身長の発達生物学）を詳細に知らなくても、正規分布が有用な働きをすることを意味します。
    *   **情報理論と最大エントロピー**: 正規分布は、平均と分散だけを知っている場合に、最も情報量が少なく（ widest and least informative）、**最大エントロピー**な分布であるという認識論的根拠があります。このため、モデルの基礎となる分布として合理的な選択となります。

*   **4.2. A language for describing models (モデルを記述するための言語)**
    *   **含意**: 統計モデリングを記述するための統一された言語を紹介します。この言語を学ぶことで、**モデルの仮定**（例: 等分散性homoscedasticity）が明確になり、線形回帰、多重回帰、ANOVA、ANCOVAといった異なるように見えるモデルが、実際には同じ種類のモデルであることが理解しやすくなります。
    *   **確率的関係（stochastic relationship）**: `~` シンボルで示される確率的な関係は、ある変数やパラメータが分布へとマッピングされることを意味します。これにより、不確実性のある関係をモデル化できます。
    *   **無限の可能性と事後分布**: ベイズ的アプローチでは、可能なすべてのパラメータ値の組み合わせを考慮し、データとモデルとの論理的な相性の良さによってそれらをランク付けします。結果として得られる**事後分布**は、「ガウス分布の分布」 となり、パラメータに関する不確実性の全体像を提供します。
    *   **i.i.d.仮定（独立同分布）**: これは、現実世界の物理的な仮定というよりも、ゴーレムが不確実性をどのように表現するかという**認識論的な仮定**です。

*   **4.3. Gaussian model of height (身長のガウスモデル)**
    *   **含意**: 身長データにガウスモデルを適用する具体的な例を示し、モデル構築の実践的な側面を詳述します。
    *   **事前分布予測シミュレーション（Prior predictive simulation）**: モデル構築において非常に有用なステップです。選択した事前分布が観測可能な変数についてどのような含意を持つかをシミュレートすることで、**不適切な選択を診断**するのに役立ちます。
    *   **Rethinking: A farewell to epsilon (イプシロンへの別れ)**: `hi = µ + ϵi` という表記ではなく、`hi ~ Normal(µ, σ)` という形式が推奨されます。後者の形式は、非ガウスモデルにも一般化しやすいためです。
    *   **事後分布からのサンプリング**: 第3章と同様に、事後分布からパラメータ値をサンプリングする方法が示されます。これにより、事後分布の特性を詳細に分析できます。
    *   **Rethinking: Sample size and the normality of σ’s posterior (サンプルサイズとシグマの事後分布の正規性)**: σの事後分布は、サンプルサイズが小さい場合、常にガウス型になるとは限らず、二次近似が不適切になる可能性があることに注意を促します。
    *   **`precis`出力**: 各パラメータの**周辺事後分布（marginal posterior distributions）**のガウス近似を提供し、**相性区間（compatibility interval）**の境界を示します。89%の相性区間がデフォルトとして推奨されますが、これは特定の閾値に固執する従来の慣習（例: 95%）への批判でもあります。

*   **4.4. Linear prediction (線形予測)**
    *   **含意**: ガウス分布の平均μを予測変数と新しいパラメータの線形関数としてモデル化する「線形モデル」戦略を解説します。これは、パラメータ値の可能なすべての組み合わせを論理的な妥当性によってランク付けするプロセスです。
    *   **Log-Normal priors (対数正規事前分布)**: パラメータが常に正の値をとる必要がある場合に、Log-Normal分布が有用です。
    *   **Rethinking: What’s the correct prior? (正しい事前分布とは何か？)**: 特定の分析に「唯一正しい」事前分布は存在しません。事前分布はデータを見る前の情報状態を符号化するものであり、科学的知識を用いて合理的な事前分布を構築すべきです。デフォルトの手順が客観的であるという「幻想」にも警鐘を鳴らします。
    *   **Rethinking: Prior predictive simulation and p-hacking (事前分布予測シミュレーションとPハッキング)**: 事前分布を観測データに基づいて選択する「p-hacking」の危険性を強調します。事前分布は、データの制約、範囲、理論的関係性に関する**データ以前の知識**に基づいて選択されるべきです。
    *   **Rethinking: Everything that depends upon parameters has a posterior distribution (パラメータに依存するすべては事後分布を持つ)**: パラメータから派生する量（例: μ）も、それ自身の事後分布を持つことを意味します。
    *   **Rethinking: What do parameters mean? (パラメータは何を意味するのか)**: パラメータの意味は文脈に強く依存し、統計的モデルは「小世界」の数値として、データとモデルに応じた世界の状態の相対的な**相性の良さ**を示すと説明されます。
    *   **事後推論のプロット**: パラメータの数値表を読み取るだけではモデルを理解しにくいため、データに対して事後推論をプロットすることが非常に重要であると強調されます。
    *   **`link`関数**: 事後分布の各サンプルと新しいデータセット（予測値の範囲）を組み合わせて、μの事後分布を計算し、予測平均と信頼区間をプロットするのに使われます。
    *   **Rethinking: Overconfident confidence intervals (過信された信頼区間)**: 信頼区間はモデルに条件付けられた推論であり、悪いモデルであっても狭い区間を示すことがあるため、過信すべきではないと警告します。
    *   **予測区間（Prediction intervals）**: 平均身長だけでなく、実際の身長に対する予測区間を生成する方法を説明します。これは、σの不確実性も組み込むことを意味します。

*   **4.5. Curves from lines (線からの曲線)**
    *   **含意**: 線形モデルの枠組みの中で、曲線的な関係（例: 多項式回帰）をどのようにモデル化するかを示します。予測変数を非線形に変換して線形モデルに含めることで、曲線的な関係を捉えることができます。
    *   **Rethinking: Linear, additive, funky (線形、加法的、ファンキー)**: 「線形モデル」という用語の混乱を解消します。この文脈での「線形」は、**μが任意の単一パラメータの線形関数である**ことを意味し、予測変数との関係が曲線的であっても線形モデルと呼ばれます。これらは**地心的なエンジン（geocentric engines）**であり、変数間の部分相関を記述する装置として利用されます。

---

### 第5章：多くの変数と見せかけのワッフル (The Many Variables & The Spurious Waffles)

この章では、複数の予測変数を持つモデル、特に多重回帰の利点と危険性を探ります。タイトルは、ワッフルハウスの密度と離婚率の間にある**見せかけの関連性（spurious association）** の例に由来しており、関連性が必ずしも因果関係を意味しないことを示唆しています。

*   **5.1. Spurious association (見せかけの関連)**
    *   **含意**: 大規模なデータセットでは、ほとんどすべての変数ペアが統計的に識別可能な非ゼロの相関を持つため、単純な相関が因果関係を示すとは限りません。
    *   **多重回帰の理由**:
        *   **共変量（confounds）の統計的「制御」**: 共変量は、因果関係について誤解を招く要因です。多重回帰は、これらの共変量の影響を分離するのに役立ちます。ただし、統計的制御は実験的制御とは異なります。
        *   **多重原因**: ある現象が複数の原因から生じる場合、それぞれの原因を測定し、その影響を推定するのに多重回帰が有用です。
    *   **因果モデルと条件付き独立性**: **有向非巡回グラフ（DAG）** は、ある条件下で特定の変数が互いに独立であることを示唆する**条件付き独立性（conditional independencies）** を含意することがあります。これにより、記述的結果に因果的な意味を与えることができます。
    *   **Rethinking: “Control” is out of control (「制御」は制御不能)**: 「統計的制御」という言葉は、しばしば誤解を招き、統計的手法の力を過大評価させる可能性があると警告します。

*   **5.1.5. Visualizing multivariate posteriors (多変量事後分布の可視化)**
    *   **含意**: 多変量モデルの出力を理解するための3つの主要なプロットタイプを導入します。
        *   **5.1.5.1. Residual plots (残差プロット)**: 線形モデルの仮定（例: 線形性、等分散性）をチェックするために使用されます。**残差をデータとして使用することは常に誤りである**と警告します。残差はパラメータであり、不確実性を持つため、既知の値として扱うと不確実性を捨ててしまいます。
        *   **5.1.5.2. Posterior prediction plots (事後予測プロット)**: モデルの予測と観測されたデータを比較するために使用されます。モデル適合が正しく機能したかを確認し、モデルがデータをどれだけうまく記述できないか（モデルの失敗箇所）を評価するのに役立ちます。
            *   **Rethinking: Stats, huh, yeah what is it good for? (統計、ふむ、ええ、何に役立つのか？)**: 統計モデリングは、効果が「実在」するかどうかを直接判断するものではなく、モデルが問題を理解する特定の方法で不確実性を定量化するにすぎないと強調します。因果関係に関する大きな世界の問いへの答えは、しばしばモデルに含まれていない情報に依存します。
        *   **5.1.5.3. Counterfactual plots (反事実プロット)**: モデルの**含意される予測（implied predictions）**を表示します。これらは、予測変数のあらゆる値、たとえ観測されていない、あるいは不可能な組み合わせであっても生成できるため、「反事実」と呼ばれます。これらは、モデルがどのように機能し、架空の介入の結果を予測するかを理解するのに役立ちます。

*   **5.2. Masked relationship (隠蔽された関係)**
    *   **含意**: 別の変数を含めることで、関係性が隠されたり、逆に明らかになったりするシナリオを探ります。例えば、ネオコルテックスと乳のキロカロリーの間には、体質量が介在することで関係が隠されることがあります。
    *   **マルコフ同値集合（Markov equivalence set）**: 同じ条件付き独立性を含意するDAGの集合を指します。データだけではどの因果モデルが正しいかを判断できないという問題を示唆します。

*   **5.3. Categorical variables (カテゴリ変数)**
    *   **含意**: 離散的で順序のないカテゴリ変数（例: 性別、分類群）をモデルに含める方法を説明します。
    *   **指標変数（index variable）**: カテゴリを表す数値ラベルを割り当て、それぞれのカテゴリに独自のパラメータ（例: `αsex[i]`）を持たせることで、同じ事前分布を割り当てつつ異なる効果をモデル化できます。
    *   **Rethinking: Differences and statistical significance (差と統計的有意性)**: 統計的に有意なパラメータとそうでないパラメータがあるからといって、その「差」も有意であるとは限らないという、一般的な解釈の誤りについて警告します。差の分布を知るには、その差自体を計算し、その事後分布を評価する必要があります。

---

### 第6章：幽霊DAGと因果の恐怖 (The Haunted DAG & The Causal Terror)

この章のタイトルは、**有向非巡回グラフ（DAG）** が、未観測の変数（**幽霊（Haunted）**） や、統計モデルに潜む因果推論の落とし穴（**因果の恐怖（Causal Terror）**）を明らかにするツールであることを示唆しています。

*   **選択バイアスとコライダーバイアス**: 章の冒頭では、選択プロセス（例: 研究助成金や論文の査読）が、信頼性（trustworthiness）と話題性（newsworthiness）が無相関であるにもかかわらず、選択後には負の相関を生み出す可能性をシミュレーションで示します。これは、**コライダー（collider）**と呼ばれる変数（複数の矢印が流れ込む変数）を条件付けすることによって生じる**コライダーバイアス（collider bias）** の一例です。

*   **6.1. Multicollinearity (多重共線性)**
    *   **含意**: **多重共線性**（multicollinearity）とは、2つ以上の予測変数の間に非常に強い相関がある状態を指します。その結果、事後分布は、実際にはすべての変数がアウトカムと強く関連しているにもかかわらず、どの変数も信頼性のある関連性を示さないように見えることがあります。これは予測には問題ないものの、モデルの解釈を困難にします。
    *   **Rethinking: Identification guaranteed; comprehension up to you (同定は保証される；理解はあなた次第)**: ベイズモデルにおいては、事後分布が適切である限り、技術的にはすべてのパラメータが**同定可能（identifiable）** です。しかし、これは事後分布を容易に理解できることを意味するわけではなく、パラメータが「弱く同定されている（weakly identified）」 状況が存在します。

*   **6.2. Post-treatment bias (治療後バイアス)**
    *   **含意**: 実験デザインにおいて、「治療後」に生じる変数（例: 植物の成長実験におけるカビの発生）をモデルに含めることで、治療の因果効果の推論が歪められる可能性があるという問題です。
    *   **Rethinking: Model selection doesn’t help (モデル選択は助けにならない)**: 治療後バイアスが生じる場合、情報量規準（information criteria）を用いたモデル選択は役に立ちません。なぜなら、誤解を招くモデルであっても、データへの適合度が高く、予測性能も優れている場合があるからです。**予測と因果推論は異なる目標である**ことが強調されます。

*   **6.3. Collider bias (コライダーバイアス)**
    *   **含意**: コライダーバイアスは、共通の結果を条件付けること（例: グラント選定で提案書の信頼性Tと話題性Nがどちらも選定Sに影響し、Sで条件付ける）、または未測定の原因（幽霊DAG）が存在する場合に生じます。
    *   **コライダーの概念**: 複数の矢印が流れ込む変数（S）を**コライダー**と呼びます。コライダーを条件付けると、その原因（TとN）の間に統計的関連性が生じます。
    *   **シンプソンのパラドックス**: コライダーバイアスは、シンプソンのパラドックス（Simpson’s paradox） の一例でもあります。これは、別の予測変数を含めることで、ある予測変数と結果の間の関連性の方向が反転する統計的現象です。

*   **6.4. Confronting confounding (交絡への対処)**
    *   **含意**: 因果推論における最も重要な課題の一つである**交絡（confounding）** にどう対処するかを説明します。交絡とは、予測変数Xと結果Yの間の関連性が、Xの値を実験的に決定した場合とは異なる場合に生じる状況です。
    *   **4つの基本的交絡（four elemental confounds）**: DAGの構成要素として、フォーク（Fork）、パイプ（Pipe）、コライダー（Collider）、子孫（Descendant）という4つの基本的関係が導入されます。
    *   **6.4.1. Shutting the backdoor (バックドアを閉じる)**: 予測変数Xと結果Yの間のすべての交絡経路（**バックドア経路（backdoor paths）**）をブロックするプロセスを指します。これは、適切な変数をモデルに含める（条件付ける）ことで行われます。
    *   **Rethinking: DAGs are not enough (DAGだけでは不十分)**: DAGは因果推論の仕組みと障害を教える強力なツールですが、それ自体が万能ではなく、より完全な機械論的モデルがあればDAGは不要になる場合もあります。
    *   **Overthinking: A smooth operator (スムーズな演算子)**: **`do-operator`**という記法が導入され、Xを操作する実験を行ったかのように、Xへのすべてのバックドア経路を切断することで、因果関係を定義します。

*   **6.5. Summary (まとめ)**
    *   **含意**: 多重回帰は単なる条件付きの関連性を記述するものであり、因果的影響を直接示すものではないと結論付けています。因果推論には、モデル外の情報、特に因果モデルが必要です。この章では、多重共線性、治療後バイアス、コライダーバイアスといった一般的な問題と、それらに対処するための因果的フレームワークが紹介されました。実験が不可能な場合でも、適切な因果モデルがあれば有効な因果推論が可能であることが強調されます。

---

### 第7章：ユリシーズのコンパス (Ulysses’ Compass)

この章のタイトル「ユリシーズのコンパス」は、ホメロスの叙事詩『オデュッセイア』の主人公ユリシーズが危険な海を航海する様子になぞらえ、統計モデリングにおける2つの主要な「怪物」である**過剰適合（overfitting）**と**過少適合（underfitting）** の間で、どのようにモデルの性能を最適化するかを示すコンパス（指針）の役割を果たします。

*   **含意**: 予測と原因の理解は異なる目標であり、情報量規準や交差検証といったツールは、主にモデルが新たなデータに対してどれだけ良い予測をするかを評価するために使用されます。

*   **Rethinking: Stargazing (星を見つめること)**
    *   **含意**: すべての係数が統計的に有意なモデル（星が多くついたモデル）を探すという、科学者の間で見られる一般的なモデル選択手法を批判しています。p値は、過剰適合と過少適合の間をナビゲートするようには設計されておらず、この方法で選ばれたモデルは「最適」ではありません。

*   **7.1. The problem with parameters (パラメータの問題)**
    *   **含意**: モデルにパラメータを追加すると、たとえそのパラメータがランダムな数値であっても、**訓練データ（training data）**へのモデルの適合度が必ず向上するという問題（過剰適合）を説明します。
    *   **R2 (決定係数)**: 訓練データへの適合度を測る一般的な指標ですが、予測変数を追加するにつれて常に増加するため、モデル選択には不適切です。
    *   **過剰適合の例**: ヒト科動物の脳容積と体質量データを用いて、次数を増やした多項式線形モデルが訓練データに完璧に適合する一方で、データが存在しない領域（例: 55kgと60kgの間）では予測が**不合理（absurd）**（例: 脳容積が負の値）になることを示します。これは、モデルが訓練データに過剰に「興奮」してしまっている状態を指します。
    *   **Rethinking: OLS and Bayesian anti-essentialism (OLSとベイズの反本質主義)**: 一般的な**最小二乗法（Ordinary Least Squares, OLS）** が、事前分布が曖昧な場合のベイズ的パラメータ推定（事後平均の算出）と等価であるという興味深い事実を指摘します。
    *   **Rethinking: Model fitting as compression (圧縮としてのモデル適合)**: モデル適合を、データをパラメータというよりシンプルな形に**圧縮**することと捉える視点を提供します。
    *   **過少適合と過剰適合の比較**: 過少適合モデルはサンプルに対して鈍感であり、個々のデータ点を削除しても回帰線はほとんど変化しません。対照的に、過剰適合モデルはサンプルに対して非常に敏感であり、データ点の一部が削除されると予測平均が劇的に変化します。

*   **7.2. Entropy and accuracy (エントロピーと正確さ)**
    *   **含意**: 過剰適合と過少適合の間のバランスをどのように取るか、そのためのモデル性能の基準として「情報理論」が提供する「対数スコアリングルール（log scoring rule）」 を導入します。
    *   **真のモデルとは何か**: 「真の」確率を定義することは困難ですが、この文脈での「真実」は、私たちの無知の状態を考慮した上で「正しい」確率を意味します。
    *   **逸脱度（deviance）**: モデルの平均対数確率（`E log(qi)`）を計算し、モデルの予測精度を評価します。これは、モデルがターゲット（真の分布）からどれだけ離れているかの相対的な距離を推定するものです。
    *   **訓練データによるスコアリングの欠陥**: 訓練データに対する対数スコアは、R2と同様に、モデルが複雑になるほど必ず向上します。これは**予測精度（predictive accuracy）** を測るものではなく、**事後予測精度（retrodictive accuracy）**を測るものに過ぎません。
    *   **訓練データとテストデータ**: 関心があるのは**新しいデータ（test sample）**に対するスコアです。シミュレーションを通じて、訓練データに対する逸脱度（in-sample deviance）は常にモデルの複雑さとともに減少するが、将来のデータに対する逸脱度（out-of-sample deviance）は、真のデータ生成プロセスと利用可能なデータ量に依存して増減することを示します。

*   **7.3. Golem Taming: Regularization (ゴーレムの調教：正則化)**
    *   **含意**: より良い予測を生み出す一つの方法は、モデルを訓練データへの適合において「悪くする」ことであると主張します。これは、**懐疑的な事前分布（skeptical prior）**、特に**正則化事前分布（regularizing prior）** を使用することで達成されます。
    *   **正則化の機能**: 正則化事前分布は、訓練データからの学習速度を遅らせることで、モデルが過剰に訓練データに適合するのを防ぎます。これにより、過剰適合が減少し、予測精度が向上することが期待されます。事前分布が強すぎると、重要な特徴を見逃し、**過少適合**につながる可能性もあります。
    *   **適応的正則化**: 第13章で学ぶ**多階層モデル**は、事前分布の強度をデータ自体から学習する「適応的正則化（adaptive regularization）」 を行います。

*   **7.4. Predicting predictive accuracy (予測精度を予測する)**
    *   **含意**: データがない**アウトオブサンプル（out-of-sample）** の予測精度を推定するための2つの主要な戦略**交差検証（cross-validation）**と**情報量規準（information criteria）** を詳述します。
    *   **7.4.1. Cross-validation (交差検証)**:
        *   **概念**: サンプルの小さな部分を意図的に除外し、残りのデータでモデルを訓練し、除外されたデータでモデルの予測精度を評価します。これを「フォールド（folds）」と呼ばれる複数のチャンクに分割して行います。
        *   **PSIS (Pareto-smoothed importance sampling)**: leave-one-out cross-validation (LOO) の近似手法で、各観測の「重要度」を利用して、モデルを何度も再適合させることなくアウトオブサンプル精度を推定します。PSISは、その信頼性についてフィードバックを提供する利点があります。
    *   **7.4.2. Information criteria (情報量規準達)**:
        *   **概念**: アウトオブサンプル**K-Lダイバージェンス（Kullback-Leibler Divergence）** の相対的な理論的推定値を構築します。
        *   **WAIC (Widely Applicable Information Criterion)**: AICやDICよりも一般的で、事後分布の形状に関する仮定を置きません。WAICのペナルティ項は、**「有効パラメータ数（effective number of parameters）」** とも呼ばれ、モデルの過剰適合リスクを測ります。WAICは**ポイントワイズ（pointwise）** であり、各観測の予測を個別に評価します。
        *   **Rethinking: Information criteria and consistency (情報量規準と一貫性)**: AICやWAICは**モデル同定（model identification）** に関して「一貫性（consistent）」 がない（つまり、必ずしも「真の」モデルを選ばない） とされますが、**予測**においては「壊れていない」と主張します。無限のデータがある場合、WAICが選択する複雑なモデルは、真のモデルと同一の予測を行います。
        *   **Rethinking: What about BIC and Bayes factors? (BICとベイズ因子はどうなる？)**: BIC（Bayesian Information Criterion） や**ベイズ因子（Bayes factors）** もモデル比較に用いられますが、これらは事前分布に大きく影響され、計算も困難であるという課題があります。これらも純粋に予測的な基準であり、因果関係については何も教えてくれません。
    *   **7.4.3. Comparing CV, PSIS, and WAIC (CV、PSIS、WAICの比較)**:
        *   **含意**: シミュレーションを通じて、CV、PSIS、WAICのすべてがアウトオブサンプルスコアをよく推定することを示します。PSISは、ユーザーに信頼性に関する警告（k値）を提供する点で独自の利点があります。
        *   **Rethinking: Diverse prediction frameworks (多様な予測フレームワーク)**: 訓練-テストのシミュレーションは、将来のデータが過去のデータと同じプロセスから生まれるという**均一説（uniformitarian assumption）** に基づいていますが、これは現実世界では常に当てはまるとは限らないと警告します。

*   **7.5. Model comparison (モデル比較)**
    *   **含意**: **モデル選択（model selection）**（最低の情報量規準値を持つモデルを選び、他を捨てる）は避けるべきだと強く主張します。なぜなら、それはモデル間の相対的な精度に関する情報（WAIC/CV/PSIS値の差）を捨ててしまうからです。また、これらの基準が因果推論に役立つとは限らないため、因果推論の目標と予測の目標を混同しないよう注意を促します。
    *   **モデル比較（model comparison）**: モデル選択ではなく、複数のモデルを用いて、異なる変数が予測にどのように影響するか、また因果モデルと組み合わせて条件付き独立性が因果関係の推論にどう役立つかを理解するための、より一般的なアプローチを推奨します。
    *   **7.5.1. Model mis-selection (モデルの誤った選択)**: 予測精度だけに基づいてモデルを選択すると、因果的に誤った（交絡した）モデルを選んでしまう可能性があることを再強調します。
    *   **WAICの比喩（WAIC metaphors）**: WAICをより直感的に理解するための2つの比喩を提供します。
        *   **競走馬**: モデルを競走馬に例え、WAICの数値はレースのタイムに似ており、小さいほど良いことを示します。モデル間の差が大きいほど、どのモデルが優れているか確信度が高まります。
        *   **石投げ**: モデルを水面に投げる石に例え、どの石が平均的に最も遠くまで飛ぶか（最も良い予測をするか）を推論する情報を提供します。
    *   **7.5.2. Outliers and other illusions (外れ値とその他の錯覚)**: PSISやWAICがどのように**外れ値（outlier）** のような影響力の大きい観測点を特定するかを示します。
        *   **Rethinking: The Curse of Tippecanoe (ティペカヌーの呪い)**: 多くのモデルの組み合わせや予測変数の変換を試すことで、特定のサンプルに非常にうまく適合するモデルを見つけてしまうが、これは「過剰適合の特殊なケース」であり、新しいデータには一般化しにくいという警告です。これは、十分な時間とデータがあれば、どんなデータセットにも強い相関パターンが見つかる可能性を、**ティペカヌーの呪い**という現象に例えて説明しています。これは「データ浚渫（data dredging）」 の危険性を示唆しています。

*   **7.6. Summary (まとめ)**
    *   **含意**: この章は、モデルがパラメータを増やすほどサンプルに適合し、追加のパラメータが無意味であっても適合度が向上する「過剰適合」の問題を中心に展開しました。これに対処するために、**正則化事前分布**と**アウトオブサンプル精度（out-of-sample accuracy）**の推定値（WAICとPSIS）という2つの主要なツールが導入されました。正則化事前分布は推定時の過剰適合を抑制し、WAICとPSISは過剰適合の程度を推定するのに役立ちます。因果推定を目指す場合、これらのツールは誤解を招く可能性があるため、モデルは予測精度に基づいて選択されるのではなく、別の方法で設計されるべきであると強調しています。

---

### 第8章：条件付きマナティー (Conditional Manatees)

この章のタイトル「条件付きマナティー」は、統計モデリングにおける重要な概念である**条件付け（conditioning）** に焦点を当てています。マナティーの瘢痕（キズ）がデータサンプルに入る方法に条件付けされているように、統計モデルも、個々のケースの特定の側面に条件付けされた確率を可能にする装置として機能するという含意があります。

*   **含意**: これまでの単純な線形モデルは、各予測変数がアウトカムの平均と独立した関連を持つと仮定していましたが、この章では、ある予測変数の関連性が別の変数の値に**条件付けされる（conditional）** 、すなわち**相互作用（interaction）** をどのようにモデル化するかを探ります。

*   **8.1. Building an interaction (相互作用の構築)**
    *   **含意**: GDPと地形の起伏度の関係が、アフリカと非アフリカ諸国で異なるという例を用いて、相互作用を構築する方法を説明します。
    *   **データ分割の避け方**: 相互作用をモデル化する際、データを分割することは避けるべきです。その理由として以下の4つが挙げられます。
        1.  共通のパラメータ（例: σ）の推定精度が低下する。
        2.  誤った仮定（例: アフリカ諸国と非アフリカ諸国で分散が異なる）をしてしまう可能性がある。
        3.  情報量規準などを用いたモデル比較が困難になる。
        4.  多階層モデル（第13章）における**情報共有（borrowing information）**の利点が失われる。
    *   **事前分布予測シミュレーション**: 第4章と同様に、モデルの事前分布が現実的な含意を持つことを確認するために、事前分布予測シミュレーションを行うことの重要性を強調します。
    *   **8.1.2. Adding an indicator variable isn’t enough (指標変数を追加するだけでは不十分)**: 単純にアフリカ諸国の指標変数（ダミー変数）を追加するだけでは、傾きの反転を捉えることはできません。それは、異なる**切片（intercepts）**を許容するだけであり、異なる**傾き（slopes）**を許容しないためです。異なる傾きをモデル化するためには、**相互作用項（interaction term）**を導入する必要があります。

*   **8.2. Symmetry of interactions (相互作用の対称性)**
    *   **含意**: 相互作用は対称的であり、XがYに与える影響がZの値に依存する場合、ZがYに与える影響もXの値に依存します。
    *   **解釈の困難さ**: 相互作用モデルは非常に複雑になるため、事後平均と標準偏差の表だけではほとんど解釈できません。**事後予測のプロット（plotting posterior predictions）** が、モデルの含意を理解するための不可欠なツールとなります。特に、複数の連続変数間の相互作用では、プロットが非常に重要です。

*   **8.3.3. Plotting posterior predictions (事後予測のプロット)**
    *   **含意**: ゴーレムは推論能力に優れているが、人間のような対人スキルは劣っています。ゴーレムが提供するパラメータ値の組み合わせの妥当性に関する事後分布を人間が理解するためには、その事後分布を何らかの形でデコードする必要があります。予測変数が一つだけの場合とは異なり、相互作用があるモデルでは、プロットの際に未観測の予測変数をどの値に設定するかが重要になります。

*   **8.4. Summary (まとめ)**
    *   **含意**: この章では、予測変数とアウトカムの間の関連性が別の予測変数の値に依存することを可能にする**相互作用**が導入されました。相互作用は正確な推論にとって重要ですが、解釈が難しいため、**三連画プロット（triptych plots）** のような可視化手法がその効果を理解するのに役立つことが示されました。

---

### 第9章：マルコフ連鎖モンテカルロ (Markov Chain Monte Carlo)

この章のタイトルは、**マルコフ連鎖モンテカルロ（MCMC）** という、複雑な事後分布からサンプリングを行う計算手法に焦点を当てています。「サンプリングする」というのは、モデルから「想像上の」パラメータ値を抽出するプロセスであり、第3章でこれらのサンプルをどのように利用するかを学んだ後、この章ではそれらのサンプルをどのように「生産する」かを説明します。

*   **含意**: MCMCアルゴリズムは、事後分布を直接計算または近似するのではなく、**事後分布からサンプルを抽出する**ことで、パラメータ値のコレクションを生成します。これらの値の頻度が事後妥当性に対応し、ヒストグラムから事後分布の全体像を構築できます。MCMCは、1990年代に始まった**ベイズデータ分析の普及の主要な要因**です。

*   **9.2. Metropolis Algorithms (メトロポリスアルゴリズム)**
    *   **含意**: MCMCアルゴリズムの基礎となる**メトロポリスアルゴリズム（Metropolis algorithm）** を導入します。これは、新しいパラメータ値を提案し、現在の値と比較してその提案を受け入れるか拒否するかを決定することで、事後分布の「島々」を探索します。
    *   **ギブスサンプリング（Gibbs sampling）**: メトロポリスアルゴリズムの効率的なバリアントであり、**共役事前分布（conjugate priors）** の知識を利用して提案のランダム性を低減します。
    *   **9.2.2. High-dimensional problems (高次元の問題)**: しかし、メトロポリスアルゴリズムとギブスサンプリングには深刻な限界があります。特に、何百、何千ものパラメータを持つ複雑なモデルや、事後分布に**高い相関（high correlation）**がある場合（狭い尾根のような形状）、これらは**非常に非効率（shockingly inefficient）** になります。これは、狭く高い確率の尾根を探索する際に、多くの「愚かな提案」をしてしまうためです。

*   **9.3. Hamiltonian Monte Carlo (ハミルトニアンモンテカルロ, HMC)**
    *   **含意**: メトロポリスやギブスサンプリングのような高度にランダムな手順とは異なり、HMCはより非ランダムな方法で計算効率を高める**最先端のMCMCアルゴリズム**です。HMCは、事後分布の**曲率（curvature）** を利用して、より賢明な「物理的な経路」（**リープフロッグステップ（leapfrog steps）**） をたどり、事後分布全体を一度に探索しようとします。
    *   **Uターン問題（U-turn problem）**: HMCの効率性は、リープフロッグステップの数とステップサイズを適切に調整するコストと引き換えに得られます。調整が不適切だと、サンプルが互いに相関したり、経路が開始地点の近くに戻ってしまう「Uターン問題」が生じます。
    *   **発散遷移（divergent transition）**: HMCの主要な利点の一つは、**数値シミュレーションが不正確である場合にそれを自動的に検出する**ことです。これは、軌跡の開始時と終了時でエネルギーが大きく異なる場合に警告として現れ、事後分布の探索に問題があることを示します。
    *   **限界**: HMCは**連続的なパラメータ**を必要とし、離散的なパラメータ空間では直接機能しません。また、一部の事後分布は非常にサンプリングが困難であり、HMCでも発散遷移に遭遇することがあります。

*   **ulam 関数**: `rethinking` パッケージの `ulam` 関数が導入されます。これは、本書で定義されるモデルをフィットさせるためにStan（mc-stan.org）のHMCエンジンを利用します。`quap`（二次近似）がうまく機能しない場合でも、`ulam`は機能することがよくあります。

*   **9.4.5. Checking the chain (チェーンのチェック)**
    *   **含意**: MCMCチェーンが事後分布を正しくサンプリングしているかを確認するための診断ツールと方法論について説明します。
    *   **収束（convergence）とミキシング（mixing）**:
        *   **収束**: 複数の独立したチェーンが、同じ高い確率の領域にとどまることを意味します。
        *   **ミキシング**: チェーンが事後分布の全領域を迅速に探索することを意味します。
    *   **診断プロット**:
        *   **トレースプロット（trace plot）**: パラメータ値が反復回数とともにどのように変化するかをプロットし、ミキシングと収束を目視で評価します。
        *   **トレースランクプロット（trace rank plot / trank plot）**: 各パラメータのサンプルをランク付けし、個々のチェーンのランクのヒストグラムを描画します。チェーンが同じ空間を効率的に探索していれば、ヒストグラムは互いに似ていて比較的均一になるはずです。
    *   **有効サンプル数 (`n_eff`)**: 生のサンプル数ではなく、事後分布からの独立したサンプルの推定数です。MCMCチェーンは通常自己相関があるため、連続するサンプルは完全に独立ではありません。
    *   **Rhat**: 複数のチェーンが事後分布に収束しているかを示す診断値です。1.0に近づくほど良い状態を示します。
    *   **発散遷移の警告**: HMC/Stanの大きな利点の一つは、サンプリングがうまくいかない場合に**発散遷移**の警告を出すことです。これは、チェーンに問題があることを示す「友達」のようなものであり、ギブスサンプラーのような他のアルゴリズムはこのような問題を黙って失敗することがあります。
    *   **Rethinking: The folk theorem of statistical computing (統計計算のフォーク定理)**: **計算上の問題がある場合、しばしばモデル自体に問題がある**という経験則です。例えば、事前分布が完全に省略されている場合など、問題がサンプリング前の段階にあることがよくあります。
    *   **弱情報事前分布（weakly informative priors）**: ごくわずかな事前情報であっても、モデルに内在する問題を解決し、推定を適切な範囲に「優しく導く」ことで、サンプリングの困難を解消できることを示します。**平坦事前分布（flat prior）** は、無限大までのすべての値を等しく妥当とみなすため、しばしば問題を引き起こします。

*   **9.6. Summary (まとめ)**
    *   **含意**: この章では、MCMC推定、メトロポリス、ギブスサンプリング、ハミルトニアンモンテカルロアルゴリズムの目的とアプローチが紹介されました。`rethinking`パッケージの`ulam`関数がStanのHMCエンジンを利用してモデルを適合させることが示されました。病理的な例を用いて、MCMCの適合不良を診断するための一般的なアドバイスが提示されました。

---

### 第10章：大きなエントロピーと一般化線形モデル (Big Entropy and the Generalized Linear Model)

この章のタイトル「大きなエントロピー」は、**最大エントロピー原理（maximum entropy principle）** に基づいて、確率分布（特に事前分布と尤度関数）を選択することの重要性を指し示します。「一般化線形モデル（Generalized Linear Model, GLM）」 は、この原理を活用して構築される柔軟な統計モデルのフレームワークです。

*   **含意**: 統計モデルを構築する際には多くの選択が必要ですが、**最大エントロピー原理**は、これらの選択、特に分布の選択を導く有用な指針を提供します。この原理に従うことで、私たちがプロセスについて知っていることに矛盾しない範囲で、最も情報量が少なく、最も広範な分布を選択することになります。

*   **最大エントロピー原理の正当化**
    *   **(1) 最も情報量が少ない分布**: 特定の制約（例: 平均、分散）がある場合に、確率をできるだけ均等に広げ、**最も情報量が少ない（least informative）**分布を選択します。これにより、不明な隠れた制約や**「幽霊の仮定（phantom assumptions）」** を導入することを防ぎます。
    *   **(2) ウォリスの導出（The Wallis derivation）**: グラハム・ウォリスに帰属される別の導出では、「情報」の概念を持ち出さずに、最大エントロピーを直感的に正当化します。これは、ある制約下で可能なすべてのイベントの組み合わせを数え上げることで、最も「公平な」分布が得られるという考えに基づいています。
    *   **(3) 分岐するデータの庭との関連**: 第2章で学んだ「分岐するデータの庭」における経路のカウントと、最大エントロピー原理が導き出す尤度関数は、本質的に同じことを行っています。

*   **一般化線形モデル（Generalized Linear Model, GLM）**
    *   **含意**: GLMは、従来のガウスモデルを拡張したもので、主に以下の2つの変更点があります。
        1.  **尤度関数（likelihood function）**: 最大エントロピー原理に基づいて選択されます。例えば、カウントアウトカムの場合、二項分布が最大エントロピー分布となります。
        2.  **リンク関数（link function）**: 線形モデルの出力（無限大の範囲を持つ）を、アウトカムの期待値が取りうる制約された範囲（例: 0-1の確率、0-無限大のカウント）に変換するための「モデルトリック」 です。
    *   **Rethinking: The scourge of Histomancy (ヒストマンシーの災厄)**: アウトカム変数のヒストグラムを見て、尤度関数を決定する「ヒストマンシー（Histomancy）」 という手法を強く批判します。モデルが仮定するのは、集計されたデータが特定の分布に従うことではなく、**予測変数で条件付けられた後の「残差」**がその分布に従うことです。
    *   **10.2.1. Meet the family (ファミリーに会う)**: 統計モデリングで最も一般的に使用される分布は、**指数族（exponential family）** のメンバーであり、これらはすべて特定の制約の下で最大エントロピー分布です。
    *   **Rethinking: A likelihood is a prior (尤度は事前分布である)**: 従来の統計学では尤度関数が「客観的」で事前分布が「主観的」とされますが、尤度関数自体も「パラメータに条件付けられたデータに対する事前分布」であると述べ、唯一「正しい」尤度関数は存在しないと主張します。

*   **リンク関数の含意**
    *   **パラメータが自分自身と相互作用する（Parameters interacting with themselves）**: GLMにおける回帰係数（β）は、アウトカム尺度上で一定の変化を生み出すわけではありません。予測変数の変化による影響は、その予測変数自身の値に依存するため、**すべての予測変数が実質的に自分自身と相互作用し、また他のすべての予測変数とも相互作用する**ことを意味します。これにより、反事実予測の可視化がモデル理解のためにさらに重要になります。
    *   **Rethinking: When in doubt, play with assumptions (疑問があれば、仮定をいじってみる)**: リンク関数を含むすべてのモデル仮定について**感度分析（sensitivity analysis）**を行うことを推奨します。これは「p-hacking」とは逆の目的を持ち、様々な正当化可能な分析を試し、それらすべてを記述することで、結論が仮定の変更にどれだけ敏感であるかを評価します。

*   **GLMsと情報量規準**
    *   **含意**: 第7章で学んだ情報量規準と正則化事前分布の概念はGLMにも適用されます。ただし、WAICや交差検証を用いて、異なる尤度関数を持つモデル（例: ガウスモデルと二項モデル）を比較すべきではないと警告します。

*   **10.3. Maximum entropy priors (最大エントロピー事前分布)**
    *   **含意**: 最大エントロピー原理は、尤度関数だけでなく、**事前分布の選択**においても有用な指針を提供します。科学的知識と整合する範囲で最も情報量の少ない事前分布を選択することで、推定の病理（pathologies）を抑制しながら、データが推論を支配することを可能にします。

---

### 第11章：神は整数に仕掛けた (God Spiked the Integers)

この章のタイトルは、統計モデルが**整数（integers）**、特にカウントデータ、の離散的でしばしば非ガウス的な性質に対処する必要があることを示唆しています。「神が仕掛けた」とは、これらのデータの特性が、単なる連続的な正規分布では捉えきれない、本質的な複雑さを持っていることを示唆する比喩です。

*   **含意**: この章では、カウントや比率のような**整数アウトカム**を扱うための、**一般化線形モデル（GLM）**の様々なタイプ、特に**二項回帰**と**ポアソン回帰**を導入します。これらは、正則化事前分布、情報量規準、MCMC推定といったこれまでの章で学んだツールを組み合わせて使用されます。

*   **11.1. Binomial regression (二項回帰)**
    *   **含意**: 第2章の地球儀投げモデルで導入された**二項分布**を、予測変数を持つ**一般化線形モデル**として拡張します。
    *   **二項分布の最大エントロピー**: 二項分布は、各試行が2つの結果のいずれかになり、期待値が一定である場合に、**最大エントロピー**な分布です。
    *   **ロジットリンク関数（logit link function）**: 二項回帰で一般的に使用され、線形予測子を0から1の確率の範囲に変換します。
    *   **推定エンジン**: `quap`（二次近似）は二項回帰でもうまく機能することが多いですが、**マルコフ連鎖モンテカルロ（MCMC）** を用いた `ulam` による推論も検証されます。
    *   **事前分布予測シミュレーション**: ロジット尺度での**平坦事前分布（flat prior）** が、アウトカム確率尺度では0と1の極端な値にほとんどの確率質量が集中する**「ばかげた（silly）」 事前分布**を意味することを具体的に示します。これにより、**弱情報事前分布（weakly informative priors）** の重要性が強調されます。
    *   **事後予測チェック**: チンパンジーの行動データを用いて、モデルの予測と生データを比較することで、モデルがデータをどのように「見ている」かを理解し、異常を発見します。
    *   **モデル比較**: 情報量規準（PSISやWAIC）を用いたモデル比較の例が示されます。ただし、実験デザインが関連する因果モデルを教えてくれる場合、推論のためにモデル比較が必須ではないことも強調されます。
    *   **UCバークレー入学データ**: 部門を無視した分析が、女性志願者の入学確率に関して**誤解を招く（misleading）** 推論をもたらす例を示します。これは、男性と女性が異なる部門に応募する傾向があるため、**省略変数バイアス（omitted variable bias）** の一種として機能します。

*   **11.2. Poisson regression (ポアソン回帰)**
    *   **含意**: **ポアソン分布**は、試行回数Nが未知または数えきれないほど多い**二項事象**をモデル化するのに有用な、二項分布の特殊な形状です。
    *   **対数リンク関数（log link）**: ポアソン回帰では、期待値λが常に正であることを保証するために使用されますが、これは予測変数と期待値の間に**指数関数的な関係**を含意します。
    *   **事前分布予測シミュレーションの重要性**: 対数リンク関数を使用する場合、線形予測子の尺度における平坦な事前分布が、アウトカム尺度では非常に不合理な（例: 巨大な）期待値に変換されることがあるため、事前分布予測シミュレーションが不可欠です。
    *   **有効パラメータ数（`pPSIS`）の挙動**: ポアソンモデルでは、有効パラメータ数`pPSIS`が、より単純なモデル（例: 切片のみのモデル）の方が、より多くのパラメータを持つモデルよりも大きくなるという、一見すると直感に反する結果が見られることがあります。これは、モデルがデータに適合するために「より懸命に働いている」ことを示唆しています。
    *   **科学的モデルと地心モデルの対比**: 従来の「地心モデル」としてのGLMと、科学的知識から構築された「科学的モデル」との比較が行われます。後者は、ゼロ人口でツールキットがゼロになるなど、より**理にかなった（sensible）予測** を生成できることを示します。
    *   **11.2.3. Example: Exposure and the offset (曝露とオフセットの例)**: ポアソンモデルで、ケースごとに**曝露（exposure）**（例: 観測時間）が異なる状況をどのように扱うかを示します。これは、対数変換された曝露を線形モデルに**オフセット（offset）**として含めることで達成されます。

*   **11.3. Multinomial and categorical models (多項式およびカテゴリモデル)**
    *   **含意**: 複数の離散的で順序のないイベントタイプ（カテゴリ）のカウントをモデル化するために使用されます。
    *   **多項ロジット（multinomial logit）/ソフトマックス関数（softmax function）**: この文脈での慣習的なリンク関数です。K個のイベントタイプに対してK-1個の線形モデルが必要となり、一つのアウトカム値が「ピボット」として選択され、他のイベントがそれに対してモデル化されます。
    *   **解釈の困難さ**: これらのモデルのパラメータ推定値は、ピボットアウトカム値に対する相対的な値であるため、非常に解釈が困難です。**含意される予測（implied predictions）**を確率の形でプロットすることが、モデルを理解するための最も安全な方法です。

*   **11.4. Censoring and survival (打ち切りと生存)**
    *   **含意**: 予測したいアウトカムが**期間（durations）**である（例: イベントが発生するまでの時間）**生存モデル（survival models）** を簡単に紹介します。期間は常に正の実数値であり、**指数分布（exponential distribution）**（平均変位だけが既知の場合の最大エントロピー分布）や**ガンマ分布（gamma distribution）** が一般的に使用されます。
    *   **打ち切り観測（censored observations）**: イベントが観測されないまま観測が終了した場合など、部分的な情報を持つ観測をモデルに含める方法を簡単に示唆します。

---

### 第12章：怪物と混合 (Monsters and Mixtures)

この章のタイトル「怪物と混合」は、これまでの章で学んだ一般的な**GLM（一般化線形モデル）**の範疇を超える、より複雑で特殊なモデルタイプを紹介することを示唆しています。「怪物」は、標準的な仮定から逸脱するデータ（例：過分散や過剰なゼロ）に対応するために、既存のモデル構成要素を異なる方法で「組み立てる」 必要があるモデルを指します。「混合」は、複数の確率分布やプロセスを組み合わせて、より柔軟なモデルを構築するアプローチを意味します。

*   **含意**: この章の目的は、測定の不都合な現実に対応するためにモデリングを変容させることであり、モデルの制約に対応するために測定を変容させることではありません。

*   **12.1. Over-dispersed counts (過分散カウント)**
    *   **含意**: カウントデータが、標準的な二項モデルやポアソンモデルが仮定するよりも大きな分散を持つ場合（**過分散（over-dispersion）**）、その追加の変動をモデル化する方法を説明します。
    *   **12.1.1. Beta-binomial (ベータ二項分布)**: 各二項カウント観測がそれぞれ独自の成功確率を持つと仮定するモデルです。これらの成功確率自体が**ベータ分布（beta distribution）** に従うことで、ケース間の未測定の変動を捉えます。UCバークレー入学データ（性別と部門）の例で、部門という**省略変数**に起因する変動を考慮しない二項モデルが誤った推論を導いた問題を、ベータ二項モデルが部門変数を直接含めなくても、この変動を「考慮」して**誤った推論を防ぐ**ことができることを示します。
    *   **WAICとPSISの使用の注意**: ベータ二項モデルやガンマ-ポアソンモデルでは、WAICやPSISを慎重に使用すべきだと警告します。データがどのように構造化されているかによって、未観測のパラメータの変動がモデルにどのように組み込まれるかが異なり、結果に影響を与える可能性があるためです。

*   **12.2. Zero-inflated outcomes (ゼロ過剰な結果)**
    *   **含意**: 観察されたカウントデータに、標準的なポアソンや二項分布が予測するよりも多くのゼロが含まれる場合（**ゼロ過剰（zero-inflated）**）、これに対処するためのモデルを紹介します。これらのモデルは、バイナリイベント（ゼロか非ゼロか）と、通常のGLM尤度（ポアソンや二項など）を組み合わせて構築されます。
    *   **Rethinking: Breaking the law (法を破る)**: 研究者が自身のカスタムモデルを構築・検証する能力が向上した現代において、数学者による「合法化」を待つ必要はなく、**独自の生成プロセスを想像し、データをシミュレートし、モデルを記述し、真のパラメータ値を回復できる**ようになったと主張します。

*   **12.3. Ordered categorical outcomes (順序カテゴリ結果)**
    *   **含意**: **順序カテゴリ（ordered categorical）** のアウトカム（例: 7段階評価のような順序はあるが連続的ではない尺度）をモデル化する方法を説明します。
    *   **累積リンク（cumulative link）**: 特に**ロジット累積オッズ（log-cumulative-odds）** 尺度で、アウトカム分布をパラメータ化します。これにより、予測変数とアウトカムの関連性を、順序を維持しつつモデル化できます。
    *   **モデルの構造**: 各可能なアウトカム値に対応する「カットポイント（cutpoints）」または「インターセプト（intercepts）」 を持つ`dordlogit`尤度関数を使用します。線形モデルの出力`phi`は、これらのカットポイント全体をシフトさせ、アウトカムの平均応答を変化させます。
    *   **プロットの重要性**: ロジット累積オッズ尺度での解釈は難しいため、**事後予測のプロット**がモデルの含意を理解する上で非常に重要です。特に、**三連画（triptych）プロット** を用いて、複数の予測変数（と相互作用）に対する予測応答の分布を視覚化できます。
    *   **Rethinking: Staring into the abyss (深淵を見つめる)**: 順序ロジスティックモデルのプロットコードは複雑になりますが、これはモデルが複雑になるにつれて避けられない「苦難」であると述べています。モデルの内部構造を理解することの重要性を強調します。

*   **12.4. Ordered categorical predictors (順序カテゴリ予測変数)**
    *   **含意**: 順序カテゴリ変数を予測変数としてモデルに含める方法を説明します。これにより、各カテゴリレベルが段階的な影響を持つことをモデル化できます。
    *   **ディリクレ分布（Dirichlet distribution）**: 各段階的効果（`delta`ベクトル）に対する事前分布として導入されます。これは**ベータ分布（beta distribution）** の多変量拡張であり、確率（0から1の間の値で合計が1になる）の分布です。
    *   **モデルの比較**: 教育レベルを順序カテゴリ予測変数として扱うモデルと、通常の連続変数として扱うモデルを比較し、線形性の仮定が結果に影響を与える可能性を示します。

---

### 第13章：記憶を持つモデル (Models With Memory)

この章のタイトル「記憶を持つモデル」は、**多階層モデル（multilevel models）** の核心的なアイデアを指しています。これは、モデルがデータ内の**クラスター（clusters）**（例: 実験のタンク、調査対象の個人）間で情報を「記憶」または「共有」（**部分的プーリング（partial pooling）**）することで、個々のクラスターの推定値を改善するという意味合いです。

*   **含意**: これまでのモデルは各観測が独立していると仮定していましたが、多階層モデルは、クラスター内で情報が共有され、同時にクラスターの集団についても学習することで、**アンテログラード健忘症（Anterograde amnesia）** のように、前の観測から学習しないことを避けます。

*   **13.1. Example: Multilevel tadpoles (多階層オタマジャクシの例)**
    *   **含意**: 多階層モデルの構築と適合の具体例として、オタマジャクシの生存率データを扱います。
    *   **多階層モデルの構造**: **変動切片（varying intercepts）** が導入されます。これは、各タンク（クラスター）が独自の切片（`alpha_tank[i]`）を持つが、これらの切片が**ハイパーパラメータ（hyperparameters）**（例: **平均タンク（average tank）**の平均 `alpha_bar` と、タンク間の標準偏差 `sigma`）によって定義される共通の**適応的事前分布（adaptive prior）** から導かれるというものです。
    *   **ハイパーパラメータとハイパー事前分布（hyperpriors）**: `alpha_bar`と`sigma`は「パラメータのためのパラメータ」であり、それらの事前分布は「ハイパー事前分布」と呼ばれます。
    *   **Rethinking: Why Gaussian tanks? (なぜガウス型の水槽なのか)**: 変動効果の分布にガウス分布を仮定する理由を説明します。これは実用性、多次元への一般化の容易さ、および既知の平均と分散がある場合の最大エントロピー分布であるという理由からです。
    *   **Rethinking: Varying intercepts as over-dispersion (過分散としての変動切片)**: 変動切片は、二項モデルやポアソンモデルにおける**過分散**に対処する別の方法として機能し、ベータ二項モデルやガンマ-ポアソンモデルと同様の効果を持つことを示します。

*   **13.2. Varying effects and the underfitting/overfitting trade-off (変動効果と過少適合・過剰適合のトレードオフ)**
    *   **含意**: 多階層モデルの主要な利点である**推定精度の向上**が、どのように過少適合と過剰適合の間のバランスを取ることで達成されるかを詳細に説明します。
    *   **3つの予測アプローチ**:
        1.  **完全プーリング（Complete pooling）**: すべてのクラスターのデータをまとめて単一の推定値を得るアプローチ。データが豊富なため推定値は高精度だが、個々のクラスターの特性を無視するため**過少適合**する可能性があります。これは、クラスター間の変動がゼロであると仮定するのと同等です。
        2.  **非プーリング（No pooling）**: 各クラスターに独立した推定値を与えるアプローチ。これは、各クラスターから得られるデータが少ない場合に、推定値が非常に**不正確**になり、**過剰適合**しやすくなります。これは、クラスター間の変動が無限大であると仮定するのと同等です。
        3.  **部分的プーリング（Partial pooling）**: 多階層モデルが採用するアプローチ。**適応的正則化事前分布**を用いることで、各クラスターの推定値を全体平均の方に**「収縮（shrinkage）」** させます。これにより、情報量の少ないクラスター（小さいサンプルサイズ）は、全体平均の影響を強く受け、過剰適合を防ぎます。逆に、情報量の多いクラスターは、自身のデータに基づいて推定されるため、収縮は少なくなります。

*   **13.3. More than one type of cluster (複数のクラスタタイプ)**
    *   **含意**: データに複数のタイプのクラスター（例: チンパンジーの実験における**個体（actor）**と**ブロック（block）**）が同時に存在する場合に、**交差分類多階層モデル（cross-classified multilevel model）** を構築する方法を示します。
    *   **交差分類と階層（Cross-classification and hierarchy）**: クラスターが互いに入れ子になっていない（例: 各チンパンジーが複数の異なるブロックで行動した）状況を「交差分類」と呼びます。これにより、個体間の変動とブロック間の変動の両方を同時に推定し、両方のカテゴリ変数に**部分的プーリング**を適用できます。
    *   **変動傾き（Varying slopes）の可能性**: 切片だけでなく、処理効果（例: 治療効果）にも**部分的プーリング**を適用し、**変動傾き**をモデル化できることを示唆します。

*   **13.4. Divergent transitions and non-centered priors (発散遷移と非中心化事前分布)**
    *   **含意**: 多階層モデルにおいて発生しうる**発散遷移（divergent transition）** という、サンプリング効率の問題とその解決策に焦点を当てます。発散遷移は、ハミルトニアンモンテカルロ（HMC）が事後分布の急峻な領域を正確に探索できないときに発生する数値誤差です。
    *   **Rethinking: No free samples (無料のサンプルはない)**: HMCが発散遷移について警告を発する際に、より警告の少ない他のサンプラー（例: ギブスサンプラー）に頼るのは誤りであると警告します。これは、警告が少ないサンプラーが単に問題を「黙って失敗」するだけで、信頼性が高いわけではないためです。
    *   **13.4.1. The Devil’s Funnel (悪魔の漏斗)**: 発散遷移が発生する典型的な例として、「悪魔の漏斗」と呼ばれる事後分布の形状を紹介します。これは、ある変数のスケールが別の変数に依存する、多階層モデルでよく見られる分布です。
    *   **解決策：再パラメータ化（reparameterization）**: 発散遷移を減らすための主要なトリックは、統計モデルを**非中心化パラメータ化（non-centered parameterization）** という新しい方法で記述することです。これは、パラメータ間の相互依存性（例: σによってスケールされるμ）を線形モデルの外に「因子化」することで、事後分布の急峻な領域を「平坦化」し、HMCが効率的に探索できるようにします。チンパンジーの多階層モデルに応用し、**有効サンプル数（n_eff）** の大幅な改善を示します。

*   **13.5. Multilevel posterior predictions (多階層の事後予測)**
    *   **含意**: 多階層モデルにおける**予測（prediction）**のニュアンスを説明します。
    *   **モデルチェック**: ソフトウェアの動作確認やモデルの理解のために、適合したモデルから含意される予測を生成することが重要であるという、第3章からのアドバイスが多階層モデルにも適用されます。
    *   **収縮の影響**: 多階層モデルでは、**部分的プーリング**によって推定値が全体平均に**収縮（shrinkage）** されるため、事後予測分布が訓練データと完全に一致することを期待すべきではありません。
    *   **予測の二重性**:
        1.  **同一クラスターに対する予測**: モデル適合に使用した特定のクラスター（例: チンパンジー）に対する予測を生成する方法。これは、各ケースに対応する変動切片を使用します。
        2.  **新しいクラスターに対する予測**: 訓練データで観測されていない**新しいクラスター**（例: 新しいチンパンジー）に対する予測を生成する方法。この場合、個々のクラスターの切片推定値ではなく、クラスター集団の**ハイパーパラメータ**（`alpha_bar`と`sigma_alpha`）を使用して新しいクラスターをシミュレートします。
    *   **事後層化（Post-stratification）**: 代表的ではないサンプルから、より代表的な予測を生成するための技術です。多階層モデリングと組み合わせて使用されることが多く、MRP（multilevel regression with post-stratification）と呼ばれます。

---

### 第14章：共分散の冒険 (Adventures in Covariance)

この章のタイトル「共分散の冒険」は、統計モデリングにおいて**共分散（covariance）**、すなわち複数の変数がどのように共に変化するかを明示的にモデル化することの複雑さと応用範囲の広さを示唆しています。これまでの章で扱ってきた多階層モデルをさらに発展させ、変動する切片だけでなく、変動する傾き間の相関もモデル化します。

*   **含意**: この章は概念的にも計算的にも難易度が高いとされています。しかし、**多変量分布**や**相関行列**の**事前分布**、**ガウス過程（Gaussian process）**といった高度な概念を学ぶことで、因果推論や、空間的、系統発生的（phylogenetic）、ネットワーク上の距離など、**連続的な類似性**を持つカテゴリ間の変動をモデル化できるようになります。

*   **14.1. Varying slopes by construction (構成による変動傾き)**
    *   **含意**: 第13章で導入された変動切片をさらに発展させ、各クラスターが**独自の切片と独自の傾き**を持つ**変動傾き（varying slopes）** モデルを構築する方法を説明します。これにより、クラスター間で切片と傾きがどのように**共変動（covary）** するかをモデル化できます。
    *   **LKJcorr prior (LKJcorr事前分布)**: **相関行列（correlation matrix）** のための便利な事前分布として導入されます。これにより、変動する切片と傾きの間の相関について、データ以前の知識をモデルに組み込むことができます。
    *   **二次元での収縮（Shrinkage in two dimensions）**: 部分的プーリングによる**収縮**が、切片と傾きの両方にどのように影響するかを視覚的に示します。推論された集団内の相関を反映して、収縮は特定の方向（例: 負の相関がある場合は斜め）に向かいます。

*   **14.2. Advanced varying slopes (高度な変動傾き)**
    *   **含意**: チンパンジーの実験データを用いて、**交差分類多階層モデル**に**変動傾き**を導入する例を詳述します。このモデルは、個体（actor）とブロック（block）の両方に対して、変動する切片と、複数の予測変数（例: プロソーシャルオプションの効果、パートナーの有無との相互作用）に対する変動する傾きをモデル化します。
    *   **非中心化パラメータ化（Non-centered parameterization）**: 複雑な多階層モデル、特に共分散行列を含むモデルにおけるサンプリングの非効率性（**発散遷移**） を解決するために、**コレスキー分解（Cholesky decomposition）** を用いた非中心化パラメータ化がどのように行われるかを示します。これにより、モデルの**有効サンプル数（n_eff）** が大幅に向上し、サンプリング時間が短縮されます。
    *   **解釈**: この複雑なモデルであっても、部分的プーリングによる収縮効果により、**有効パラメータ数**は実際のパラメータ数よりも大幅に少なくなり、モデルの頑健性が高まります。事後予測のプロットは、個々の変動がどのようにモデルに組み込まれているかを示し、未観測の変動を考慮した推論を可能にします。

*   **14.3. Instruments and causal designs (操作変数と因果関係設計)**
    *   **含意**: 第6章で学んだバックドア基準で閉じられないような**未観測の交絡（unobserved confounds）**が存在する場合でも、因果推論を可能にする**操作変数（instrumental variables）** という強力なツールを導入します。
    *   **操作変数の基準**:
        1.  予測変数に影響を与える。
        2.  結果に直接影響を与えない（**排除制約（exclusion restriction）**）。
        3.  未観測の交絡因子と相関しない。
    *   **Rethinking: Two-stage worst squares (二段階最悪二乗法)**: 操作変数モデルがしばしば**二段階最小二乗法（two-stage least squares, 2SLS）** という推定手順と関連付けられますが、この手順には大きなサンプル近似に依存する既知の問題があり、限界があると指摘します。ベイズ的アプローチは、より柔軟なモデルを扱うことを可能にします。
    *   **フロントドア基準（front-door criterion）**: 未観測の交絡因子が存在する状況で、**完全な媒介変数（perfect mediator）** を見つけることができれば、因果効果を推定できる別の因果同定戦略です。

*   **14.4. Social relations as correlated varying effects (相関する変動効果としての社会的関係)**
    *   **含意**: 多階層モデルの応用として、社会ネットワークデータ（例: 贈与交換）をモデル化する方法を示します。家庭間の贈与を、各家庭の「潜在的な寄与」という変動効果としてモデル化し、それらの間に相関を許容します。
    *   **Rethinking: Where everybody knows your name (みんながあなたの名前を知っている場所)**: このモデルに欠けている重要な特徴として、社会関係の**推移性（transitivity）**（AがBと友達で、CがBと友達なら、AとCも友達である可能性が高い）を挙げます。これは、未観測の共通因子によって引き起こされる相関関係から生じるとされます。

*   **14.5. Continuous categories and the Gaussian process (連続カテゴリとガウス過程)**
    *   **含意**: これまでの変動効果が離散的で順序のないカテゴリ（例: カフェ、タンク）に定義されてきたのに対し、このセクションでは、**連続的な類似性**の次元（例: 空間的距離、時間、系統発生的距離）にわたる変動をモデル化する**ガウス過程（Gaussian process）** を導入します。
    *   **応用例**: オセアニア諸島の社会における道具の複雑さと地理的距離の関係をモデル化する例が示されます。各社会に**変動切片**を導入し、これらの切片が地理的距離に基づいて相関するように仮定します。
    *   **非中心化パラメータ化**: ガウス過程モデルでも、特に大きな共分散行列を扱う場合に、サンプリング効率を向上させるために非中心化パラメータ化が推奨されます。

*   **14.6. Phylogenetic regression (系統発生回帰)**
    *   **含意**: ガウス過程の特定の応用例として、**系統発生的距離（phylogenetic distance）** を用いて、種間の類似性が共通の祖先（未測定の交絡因子）によってどのように引き起こされるかをモデル化します。これにより、系統関係が推定値に与える影響を調整し、より信頼できる因果推論を行うことが可能になります。
    *   **モデルの解釈**: 種の群れ行動と脳サイズのデータを用いて、系統関係を考慮しないモデルでは群れサイズが脳サイズに影響するように見えますが、系統関係をモデルに含めると、その影響は消失することが示されます。これは、脳サイズと群れサイズの両方が系統樹内でクラスター化するためであり、系統関係が両変数の間の見せかけの関連性を生み出していたことを示唆します。

*   **14.7. Summary (まとめ)**
    *   **含意**: この章では、パラメータの統計集団における共分散をモデル化することで、多階層アプローチを変動切片と変動傾きに拡張する方法を説明しました。**LKJcorr事前分布**が相関行列の便利な事前分布として導入され、**操作変数**や**フロントドア基準**を用いた因果推論への応用も示されました。**ガウス過程**は、空間的、ネットワーク的、系統発生的、またはその他の抽象的なエンティティ間の距離のような**連続的な類似性**の次元に変動効果戦略を拡張する実用的な方法であることが示されました。

---

### 第15章：欠損データとその他の機会 (Missing Data and Other Opportunities)

この章のタイトルは、**ベイズ推論**が、これまで厄介な問題とされてきた**測定誤差（measurement error）** や**欠損データ（missing data）** を扱う上で、強力な「機会（opportunities）」を提供するという含意があります。ベイズモデルは、これらの問題をアドホックな方法ではなく、確率理論に基づいて、**未観測のパラメータ**として直接モデルに組み込むことを可能にします。

*   **含意**: ベイズ推論の大きな利点は、**「賢くある必要がない（obviates the need to be clever）」** ことです。データがどのように発生したかについて「生成的に考える（generative thinking）」 ことを通じて統計モデルを開発し、測定誤差や欠損データをモデルに直接組み込むことができます。

*   **ベルトランの箱のパラドックス（Bertrand’s box paradox）**: この古典的な確率パズルは、ベイズモデルが「生成可能（generative）」 であるという事実（観測をシミュレートするだけでなく、パラメータを推定できる）を説明する比喩として使われます。これにより、データ生成プロセス（未観測の隠れた状態を含む）について深く考えることが、推論を導き出す上でどれほど役立つかが示されます。

*   **15.1. Measurement error (測定誤差)**
    *   **含意**: 観測されたデータがエラーを伴う場合に、そのエラーをモデル内で明示的に考慮する方法を説明します。
    *   **モデルの構造**: 観測された値（`Dobs`）が、**真の潜在変数（true latent variables）**（`Dtrue`）からの正規分布として生じると仮定し、この`Dtrue`が線形モデルの一部として他の予測変数に影響されます。
    *   **誤差の相関**: 測定誤差が互いに相関している場合（例: 未観測の共通因子によって引き起こされる）、単純な回帰では**非因果的な経路（non-causal path）**が生じる可能性があることを示唆します。この場合、エラー間の共分散をモデル化する必要があります。

*   **15.2. Missing data (欠損データ)**
    *   **含意**: 観測値が欠損している場合に、その欠損をモデルに直接組み込むことで、**情報を捨てずに** 分析する方法を説明します。
    *   **欠損のパターン**: 「完全にランダムに欠損（missing completely at random, MCAR）」、「ランダムに欠損（missing at random, MAR）」、「ランダムに欠損していない（missing not at random, MNAR）」といった統計用語がありますが、これらの分類よりも、**因果モデルをスケッチする**ことの重要性を強調します。
    *   **欠損値の代入（imputation）**: ベイズモデルでは、欠損値を「**パラメータ**」として扱い、他のモデルパラメータと同様に推定します。これにより、すべてのケースを分析に含めることができ、不確実性を考慮に入れた形で欠損値を「代入」することができます。
    *   **Rethinking: Multiple imputations (多重代入法)**: 従来の非ベイズ的な**多重代入法（multiple imputation）** は、完全なベイズ的解決策を近似しようとするものですが、デスクトップ上でのベイズ的代入が実用的になった現在では、**完全なベイズ代入**の方が優れていると述べています。

*   **15.3. Categorical errors and discrete absences (カテゴリ誤差と離散的欠損)**
    *   **含意**: 測定誤差や欠損データが**離散変数**（例: 0/1、カテゴリ）の場合、ハミルトニアンモンテカルロ（HMC）のようなMCMCアルゴリズムが直接扱いにくいという課題を説明します。HMCは連続的なパラメータ空間に最適化されているため、離散的な未観測変数をモデル化するには**特別なコーディング**が必要になります。

---

### 第16章：一般化線形モデルの狂気 (Generalized Linear Madness)

この章のタイトル「一般化線形モデルの狂気」は、**一般化線形モデル（GLM）** の強力さ（それゆえに「狂気」）を認めつつ、それがしばしば、より科学的に特化された「**特注モデル（bespoke models）**」 を犠牲にして、汎用的な「既成の（off-the-shelf）」 製品として使われすぎる傾向があることを示唆しています。GLMは非常に有用ですが、科学的専門知識を阻害し、現象の真の因果関係やメカニズムを捉えきれない限界がある、という含意です。

*   **含意**: 「GLMは不合理なほど強力である」 が、しばしば**地心的な装置（geocentric devices）** に過ぎないと警鐘を鳴らします。より良い適合とより良い推論のためには、最終的には**「特注の（bespoke）」科学的モデル**が必要であると主張します。

*   **16.1. Geometric people (幾何学的人間)**
    *   **含意**: 人間の身長と体重の関係をモデル化する例を用いて、統計的な関連性だけでなく、**科学的な知識**（例: 生物学的プロセス）に基づいてモデルを構築することの重要性を示します。
    *   **円筒の人々（Geometric people）**: 人間を円筒に近似するという**「球状の牛（spherical cow）」** の仮定（有用な簡略化）を用いて、体重と身長の間の物理的な関係を数学的に導出します。
    *   **意味を持つパラメータ（Parameters with meaning）**: 科学的にインスパイアされたモデルの大きな利点は、パラメータが物理的な意味を持つことです。これにより、**情報的な事前分布（informative distributions）** を設定でき、データだけでは識別できないパラメータの推定にも役立ちます。
    *   **Rethinking: Priors are never arbitrary (事前分布は決して恣意的ではない)**: 事前分布は**決して恣意的ではなく**、科学者が領域知識を無視するときにのみ恣意的になるのだと強調します。
    *   **識別可能性（Identifiability）**: 特定のパラメータの組み合わせ（例: `k`と`p`）が、データから独立して識別できない**（unidentifiable）** 可能性があることを示します。このような場合、事後分布には**狭い曲線状の尾根（narrow curved ridge）** が現れ、パラメータ間に強い相関が生じますが、情報的な事前分布を用いることでモデルを適合させることが可能です。

*   **16.2. Hidden states and other tricks (隠れた状態とその他のトリック)**
    *   **含意**: 直接観測できない**「隠れた状態（hidden states）」** をモデルに組み込む方法を紹介します。
    *   **実験の例**: 子供が他者の行動をコピーする実験において、観測される行動（コピーしたかどうか）の背後にある「戦略」（隠れた状態）をモデル化します。これにより、行動と戦略を混同することを防ぎます。
    *   **拡張性**: このモデルは、隠れた状態の確率を年齢や性別などの予測変数に条件付けることで拡張できます。

*   **16.3. Development and other curves (発達とその他の曲線)**
    *   **含意**: チンパンジーのナッツ割り能力の発達曲線のように、年齢と共に変化するような**非線形の関係**をモデル化する方法を示します。これは、単なる線形回帰ではなく、科学的知識に基づいたカスタムの非線形関数を用いることで達成されます。
    *   **事前分布予測シミュレーション**: 特に非線形モデルでは、事前分布予測シミュレーションが、事前分布が予測する発達パターンが生物学的に合理的であることを確認するために不可欠です。

*   **16.4. Population dynamics (個体群動態)**
    *   **含意**: 時系列データを扱う**状態空間モデル（state space model）** を導入します。これは、観測されたデータ（例: 毛皮の捕獲数）が、未観測の**真のシステム状態（true system states）**（例: 個体群数）の**「放出（emissions）」** であると仮定します。
    *   **ロトカ-ヴォルテラモデル（Lotka-Volterra model）**: 捕食者と被食者の相互作用をモデル化する有名な方程式系を例に、それが個体群動態における周期的な変動をどのように説明するかを示します。
    *   **測定誤差**: 時系列データでは、観測されたデータが必ず**測定誤差**を伴うため、観測されたデータが次のステップの観測データに直接因果関係を持つとモデル化することは誤りであると強調されます。真の因果関係は、未観測の**隠れた状態**に存在します。
    *   **事後予測シミュレーション**: 観測されたデータ（毛皮）と、未観測の「人口」レベルの両方で事後予測をプロットすることで、モデルが基礎となる滑らかな人口ダイナミクスをどのように再構築できるかを示します。

---

### 第17章：占星術 (Horoscopes)

この章のタイトル「占星術」は、科学的な発見や予測において、十分な根拠や厳密な分析がないまま結論が導き出されることへの批判を込めた比喩です。科学的な主張が、実際には「占い」に近い信頼性の低いものである可能性があることを示唆しています。

*   **含意**: 科学界で出版された研究結果の**偽発見率（false-discovery rate）** が高いという現代科学の懸念に焦点を当てています。これは、統計的有意性検定への過度な信頼や、再現性の低い研究が多く存在する問題と関連しています。

*   **偽発見率に影響を与える要因**
    *   **(4) データ分析の質（Quality of data analysis）**: 本書の主題でもありますが、データを見る前に分析を設計しない場合、正的な手法や科学の実践に対する深い省察を促し、より頑健で信頼性のある科学的発見を目指すことの重要性を強調しています。