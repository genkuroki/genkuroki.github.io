はい、承知いたしました。以下の要件に基づいてご回答いたします。

*   提供されたソースに基づき、マクエルリース氏の著書『統計的再考』の内容を説明します。
*   「compatibility interval」は「相性区間」と訳します。
*   各章ごとにナンバリングして整理します。
*   特に第1章と第2章の「Rethinking（再考）」および「Overthinking（深掘り）」コラムの内容を、順番に省略せずに詳しくまとめます。
*   帰無仮説有意性検定（NHST）への批判は、P値そのものへの批判ではなく、その周囲に形成された「奇妙な儀式」と、他の有用なツールの排除に対するものであることを明確にします。
*   「分岐するデータの庭（garden of forking data）」の由来（ホルヘ・ルイス・ボルヘスの小説「分岐する小道の庭」）を説明します。
*   「すべてのモデルは間違っているが、役に立つものもある（All models are wrong, but some are useful）」という重要な考え方を強調します。
*   「A good example is Fisher’s exact test...」に関する特定の記述は説明に含めません。
*   音声概要として20分から30分以上の長さになるよう、詳しく漏れなく説明します。

---

### 『統計的再考（Statistical Rethinking）』の概要：第1章と第2章の「再考」と「深掘り」

本書、『統計的再考（Statistical Rethinking） 第二版：RとStanによる例を添えたベイジアンコース』は、統計的推論を再考する旅へと読者を誘います。著者のリチャード・マクエルリース（Richard McElreath）氏は、従来の統計手法の限界を指摘し、より柔軟で強力なベイジアンアプローチとモデル構築の原則を提唱しています。

---

### 第1章：プラハのゴーレム（The Golem of Prague）

第1章では、統計的モデルを、意図を持たず、与えられた指示に盲目的に従う「ゴーレム」という比喩で説明しています。科学におけるモデルは、現象の測定やパターンの発見において不可欠な「義肢」のような存在ですが、その結果を適切に解釈し、文脈が不適切ではないかを見極めるのは人間である「ゴーレムのエンジニア」の責任であると述べられています。

#### 1.1. 統計的ゴーレム（Statistical golems）

*   **統計的ゴーレムの概念**: シンプルなt検定のような統計的手続きでも、それは「小さなゴーレム」であり、毎回ほぼ同じ方法で忠実に計算を実行します。科学のほぼすべての分野が統計的ゴーレムに依存しており、自然選択の強さやニュートリノの速度といった現象の測定にはモデルの使用が不可欠です。ゴーレムは私たちに代わって測定を行い、印象的な計算を実行し、明らかでないパターンを見つけ出します。
*   **ゴーレムの知恵の欠如**: しかし、ゴーレムには知恵がなく、その答えが不適切な文脈であるかを識別できません。ただ指示通りに動くだけです。統計科学の勝利は、特定の文脈で役立つ多様なゴーレムが存在することにあります。この観点から見ると、統計学は数学でも科学でもなく、むしろ工学の一分野と見なされます。
*   **初学者における混乱**: この多様性が、入門統計学のコースがしばしば初学者を混乱させる理由を説明しています。学生は、統計モデルを構築、改良、批判するための単一の方法ではなく、「検定法」と呼ばれている事前に作られたゴーレム達の動物園を提供されます。意思決定木（Figure 1.1のようなフローチャート）は一般的で、一連の質問に答えることで「正しい」手順を選択します。
*   **古典的手法の限界**: 経験豊富な統計家はこれらの手続きの統一性を理解していますが、学生や研究者はめったにそうではありません。入門統計学の古典的手法は「柔軟性がなく、脆弱」であるとされています。柔軟性がないとは、ユニークな研究の文脈に適応する方法が非常に限られていることを意味し、脆弱とは、新しい文脈に適用された場合に予測不可能な方法で失敗することを意味します。ほとんどの科学の境界では、どの手続きが適切であるか、またそれがどのように振る舞うかを理解することは困難です。
*   **原因と結果の理解の欠如**: 統計ツールは、証拠から原因を推論するという基本的な問題に単独で対処するものではありません。統計的ゴーレムは原因と結果を理解せず、ただ「関連性」を理解するのみです。私たちの導きと懐疑がなければ、既成のゴーレムは全く役に立たないか、あるいはプラハを破壊するかもしれません。研究者が本当に必要としているのは、特殊目的の統計的手順を設計、構築、改良するための原則の集合である「ゴーレムエンジニアリングの統一理論」であり、本書では、統計的推論を既製のツールの集合ではなく、戦略の集合として再考することに利益があると考えています。

#### 1.2. 統計的再考（Statistical rethinking）

*   **不安の源と克服**: 統計的推論は多くの点で誤解されやすく、これが初学者が不安を感じる一因です。フローチャートから既製の「検定法」を選ぶという枠組みでは、「正しい」検定法を選ぶことへの不安が高まることがあります。しかし、この不安は知恵に転化することができます。本書が各ゴーレムの計算上の「核とボルト」を扱うことにこだわるのはこのためです。ゴーレムが情報をどのように処理するかを理解しなければ、ゴーレムの出力を解釈することはできません。これは、統計モデルを慣例よりも詳細に理解し、少なくとも「賢く」なるまでは、手動で計算を行うことを要求します。
*   **概念的な障害**: 統計的目標の定義や統計的結果の解釈に関する概念的な障害も存在します。個々のゴーレムを理解するだけでは不十分で、統計モデルが仮説や関心のある自然なメカニズムにどのように関連するかを評価する統計的認識論が必要です。
*   **「フォーク・ポパー主義」の批判**: 著者が学生や同僚の間で遭遇する最大の障害は、統計的推論の適切な目的が「帰無仮説を検定することである」という暗黙の信念です。この信念は、カール・ポパーが科学は仮説を反証することで進歩すると主張したことに基づいていると考えられています。しかし、これは科学者の間で一般的な「フォーク・ポパー主義」、つまり非公式な科学哲学であり、実際の科学哲学者の間ではそうではありません。

    *   **Rethinking（再考）: 帰無仮説有意性検定（NHST）は反証主義的か？**
        帰無仮説有意性検定（NHST）はしばしば反証主義的、つまりポパー主義的科学哲学と同一視されます。しかし、NHSTは通常、実際の研究仮説ではなく、帰無仮説を反証するために用いられます。したがって、反証は説明モデルそのもの以外のものに対して行われていることになります。これはカール・ポパーの哲学とは逆のように見えます。

*   **演繹的反証の不可能性**: 実際には、ほとんどすべての科学的文脈において、演繹的反証は不可能です。これには主に2つの理由があります。
    *   **(1) 仮説はモデルではない**: 仮説と様々な種類のモデルの関係は複雑です。多くのモデルが同じ仮説に対応し、多くの仮説が単一のモデルに対応します。これにより、厳密な反証は不可能です。仮説を反証しようとするとき、私たちは何らかのモデルを扱わなければなりません。それが明示的に統計的でない場合でも、仮説を具体化する測定や証拠の暗黙のモデルが常に存在します。**「すべてのモデルは間違っている（All models are wrong, but some are useful）」**ので、モデルを反証するとはどういうことでしょうか？モデルを扱うという要件の1つの結果は、仮説から導き出されたモデルを拒否したからといって、その仮説が誤りであると演繹的に結論付けることがもはや不可能になることです。図1.2（Figure 1.2）は、仮説、詳細なプロセスモデル、統計モデルの関係を「中立進化モデル」の例で示しています。仮説（H）は通常漠然としており、複数のプロセスモデル（P）に対応します。仮説の統計的評価は、プロセスモデルに直接対処することはめったにありません。代わりに、統計モデル（M）に依存し、これらはプロセスモデルのいくつかの側面しか反映しません。結果として、関係は両方向で複数存在します。仮説は唯一のモデルを意味せず、モデルは唯一の仮説を意味しません。この事実が統計的推論を非常に複雑にしています。統計モデルは特定の因果関係を具現化せず、変数間の関連性を表現するにすぎません。そのため、多くの異なるプロセスモデルが単一の統計モデルと一致する可能性があります。
    *   **(2) 測定は重要である**: たとえデータがモデルを反証すると私たちが考えても、別の観測者は私たちの方法や測定を議論するでしょう。彼らはデータを信頼しません。時には彼らが正しいこともあります。
*   **科学的方法と統計的手法**: これら2つの理由から、演繹的反証は決して機能しません。科学的方法を統計的手順に還元することはできず、したがって私たちの統計的手法もそのように装うべきではありません。統計的証拠は、科学の「熱い混沌」の一部であり、その争いやエゴティズム、相互強制といった要素を伴います。もしあなたが私のように、科学がしばしば機能すると信じるなら、それが反証によって機能しないと学んでも、あなたの考えを変えるべきではありません。むしろ、統計的ゴーレムの多くの正当に有用な機能に目を開かせ、より良い科学を行うのに役立つでしょう。

    *   **Rethinking（再考）: エントロピーとモデル識別（Entropy and model identification）**
        統計モデルが多くの異なる詳細なプロセスモデルに対応する理由の一つは、正規分布、二項分布、ポアソン分布といった分布に依存しているからです。これらの分布は、**指数型分布族**のメンバーです。自然界がこれらの分布を好むのは、自然がエントロピーを好むからであり、指数型分布族のすべての分布は最大エントロピー分布であるためです。この説明から「自然の人格化」を取り除くのは第10章に譲られます。**実用的な含意**は、身長が正規分布しているという事実から発達プロセスを推測できないのと同様に、べき法則から進化プロセスを推測できないことです。この事実により、回帰モデルがメカニズム的プロセスについて私たちに教えることができる内容について謙虚になるべきです。一方で、これらの分布の最大エントロピーの性質は、基礎となるプロセスを特定できない場合でも、有用な統計的作業を行うためにそれらを使用できることを意味します。私たちはそれを特定できないだけでなく、特定する必要もありません。

*   **白鳥の寓話の限界**: 演繹的反証の論理は、「仮説Hがあり、それが何らかの観測Dを伴うことを示す。次にDを探す。もしそれが見つからなければ、Hは偽であると結論付けなければならない」という非常にシンプルなものです。論理学者はこれを「モーダストレンス（modus tollens）」と呼びます。対照的に、Dを見つけてもHについて確実なことは何もわかりません。なぜなら、他の仮説もDを予測する可能性があるからです。
    *   「すべての白鳥は白い」という仮説が、オーストラリアで黒い白鳥が発見されたことで反証されたという説得力のある科学的寓話は、非常に魅力的です。しかし、この寓話が示唆するほど、反証的証拠を求めることが強力であるとは限りません。仮説とモデル間の対応問題に加えて、科学者が直面する問題のほとんどは、このように論理的に離散的ではありません。私たちはしばしば、以下の2つの同時的な問題に直面します。
        1.  **観測は誤りに陥りやすい**: 科学的知識の境界では特にそうです。例えば、絶滅したと思われていたオオハシキツツキの目撃証拠が疑われた事例があります。**黒い白鳥が常に本当に黒い白鳥であるとは限らず、白い白鳥が実は黒い白鳥であることもあります**。誤った確認（偽陽性）や誤った反証（偽陰性）が存在します。
        2.  **仮説は定量的である**: ほとんどの興味深い科学的仮説は、「すべての白鳥は白い」という種類ではなく、「白鳥の80%は白い」や「黒い白鳥は稀である」といった量的なものです。このような場合、黒い白鳥を観測したからといって、仮説を反証したり証明したりするのではなく、白鳥の羽色の分布を可能な限り正確に推定し、説明することが課題となります。測定誤差がない場合でも、この問題は「モーダストレンス」式の白鳥の寓話を科学に適用することを妨げます。

#### 1.3. ゴーレム・エンジニアリングのためのツール（Tools for golem engineering）

*   **モデル構築への移行**: 反証を模倣しようとするのが一般的に有用な統計手法ではないとすれば、私たちは何をすべきでしょうか？私たちは「モデル」を構築すべきです。モデルは「検定手続き」に変えることもできますが、設計、予測、議論のためにも使用できます。研究を行うことは、科学的問題が単なる「検定」よりも一般的であり、入門統計学で出会った既製のゴーレムが多くの研究文脈に適さないため、モデルを作成し操作する能力から恩恵を受けます。
*   **ベイジアン・データ分析**: データがある場合、それを使って世界について学ぶにはどうすればよいでしょうか？唯一正しい答えはありませんが、最も効果的で一般的な答えの1つは、ベイジアン・データ分析を使用することです。ベイジアン・データ分析は、問題をモデルの形で受け取り、論理を使って確率分布の形で答えを導き出します。控えめに言えば、ベイジアン・データ分析は、私たちの仮定に従ってデータが起こりうる方法の数を数えることに過ぎません。確率論は、確率が単なる「数えるための計算」であるため、関連性があります。これにより、確率論を、世界の数え上げ可能な事象であろうと、パラメータのような理論的構成物であろうと、 plausibility（相性の良さ）を表現する一般的な方法として使用できます。統計モデルを定義すると、ベイジアン・データ分析は、推論を生成するためにデータを処理する純粋に論理的な方法を強制します。
    *   **頻度主義的アプローチとの比較**: 第2章で詳しく説明されます。ベイジアン確率は非常に一般的な確率アプローチであり、特別なケースとして「頻度主義的アプローチ」を含みます。頻度主義的アプローチは、すべての確率が非常に大きな標本における事象の頻度との関連によって定義されることを要求します。これにより、頻度主義的不確実性は、データの仮想的な再サンプリングに基づいています。もし測定を何度も繰り返したら、何らかのパターンを持つ値のリストが得られるだろう、という考え方です。これはまた、パラメータやモデルは確率分布を持つことができず、測定値のみが持てることを意味します。これらの測定値の分布は「サンプリング分布」と呼ばれます。この再サンプリングは実際には行われず、一般的には意味をなしません。**Sir Ronald Fisher**も、この架空の再サンプリングについて言及しています。しかし、温室での実験など、多くの文脈では、不確実性を記述するための有用な方法となります。どのような文脈であれ、それはモデルの一部、つまり再サンプリングした場合にデータがどのように見えるかについての仮定に過ぎません。それは、ベイジアンの「確率をあらゆる種類の不確実性（経験的であろうと認識論的であろうと）を記述するために使用する」という大胆な試みと同じくらい幻想的です。

    *   **Rethinking（再考）: 確率は単一ではない（Probability is not unitary）**
        「確率」を定義する方法が複数あるという提案は、一部の読者を不快にさせるかもしれません。数学的概念は唯一正しいものではないのでしょうか？そうではありません。ひとたび前提や公理の集合を採用すれば、数学的システムではすべてが論理的に導き出されます。しかし、その公理は議論や解釈の対象となります。したがって、「ベイジアン」と「頻度主義的」な確率があるだけでなく、異なる議論に基づいてベイジアン確率の異なるバージョンも存在します。この本は主に、「論理的」な**コックス（Cox）解釈**（あるいはラプラス-ジェフリーズ-コックス-ジェインズ解釈）に従っています。
        ベイジアン・データ分析には、少なくとも学者が統計モデリングを学ぶ上で利点があります。この本全体を「ベイジアン」という言葉を一切使わずに書き直すことも可能ですが、そうすると簡単になる部分と、はるかに難しくなる部分があるでしょう。著者は両方の方法で応用統計学を教えてきましたが、ベイジアンの枠組みの方が直感的であると感じています。その最も良い証拠は、非常に多くの科学者が非ベイジアンの結果をベイジアン的な用語で解釈していることです。例えば、通常のP値をベイジアンの事後確率として解釈したり、非ベイジアンの信頼区間をベイジアンの信頼区間として解釈したりします。統計学の講師でさえこれらの間違いを犯します。この意味で、ベイジアンモデルはより直感的な解釈につながり、科学者が統計的結果に投影しがちな解釈と一致する傾向があります。事後確率をP値として解釈するという逆のパターンは、めったに起こらないようです。

    *   **Rethinking（再考）: 少しの歴史（A little history）**
        ベイジアン統計的推論は、入門統計学の典型的なツールよりもはるかに古く、それらの多くは20世紀初頭に開発されました。ベイジアンアプローチのバージョンは1700年代後半から19世紀にかけて繰り返し科学的作業に適用されました。しかし、第一次世界大戦後、**サー・ロナルド・フィッシャー**のような反ベイジアン統計家が、このアプローチを周縁化することに成功しました。フィッシャーは、彼の影響力のある1925年のハンドブックでベイジアン分析（当時「逆確率」と呼ばれていた）について、**「…逆確率の理論は誤謬に基づいており、完全に拒絶されなければならない。」**とだけ述べています。
        ベイジアン・データ分析は、20世紀後半に統計学の中で徐々に受け入れられるようになりました。なぜなら、それが誤謬に基づいていないことが証明されたからです。哲学はさておき、それは機能しました。1990年代に入ると、新しい計算アプローチによりベイジアン手法の応用が急速に増加しました。しかし、ベイジアン手法は依然として計算コストが高く、データセットの規模が増大するにつれて（ゲノム解析では数百万行が一般的）、ベイジアン推論の代替や近似は依然として重要であり、おそらく常にそうでしょう。

*   **モデル比較**: モデルを予測精度で比較することは、それ自体が有用です。そして、さらに有用なのは、「複雑なモデルほど、単純なモデルよりも悪い予測をすることが多い」という驚くべき事実を発見できるからです。予測の主要なパラドックスは「過剰適合（overfitting）」です。データに適合させることは簡単ですが、予測は困難です。将来のデータは過去のデータと全く同じではないため、この事実を認識していないモデルは、本来よりも悪い予測をする傾向があります。そして、複雑なモデルほど単純なモデルよりも過剰適合に陥りやすいのです。つまり、ゴーレムが賢いほど、その予測は愚かになります。したがって、良い予測をしたいのであれば、単にデータへの適合度だけでモデルを判断することはできません。**情報量規準**は、予測精度を推測するために使用されますが、その力はしばしば誇張されます。

*   **多階層モデル（Multilevel models）**: 多階層モデルは、主に過剰適合に対処するのに役立ちます。交差検証（cross-validation）と情報量規準は過剰適合のリスクを測定し、それを認識するのに役立ちますが、多階層モデルは実際に対処します。その方法とは、「**部分プーリング（partial pooling）**」と呼ばれる驚くべき統計的トリックを利用し、データ内の単位間で情報をプールして、すべての単位に対してより良い推定値を生成することです。詳細は第13章で説明されます。

*   **グラフィカル因果モデル（Graphical causal models）**: 交差検証と情報量規準は予測精度を推測しようとします。予測の主要なパラドックスを過剰適合と説明しましたが、二次的なパラドックスもあります。「因果的に誤ったモデルが、因果的に正しいモデルよりも良い予測をする可能性がある」ということです。結果として、予測に焦点を当てると体系的に誤解を招く可能性があります。無作為化比較実験が因果推論を可能にすると聞いたことがあるかもしれませんが、これらのリスクは無作為化実験にも伴います。
    *   著者はこれを「**識別問題（identification problem）**」と呼び、生の予測の問題とは慎重に区別しています。予測には2つの異なる意味があります。最もシンプルなのは、外部の観察者として次に何が起こるかを推測しようとするときで、この場合、交差検証のようなツールは非常に有用です。しかし、これらのツールは、交絡変数を含むモデルを喜んで推奨し、誤った因果関係を示唆するでしょう。なぜなら、交絡関係は実際の関連性であり、予測を改善する可能性があるからです。成功する予測には、正しい因果識別は必要ありません。実際、この本の後半で見るように、**「因果的に誤解を招くモデルを使用しても、予測が実際に改善する場合がある」**のです。
    *   予測精度に基づいてモデルを比較しても、因果関係を導き出すことはできません。必要なのは、因果的識別（causal identification）の目的のために、一つ以上の統計モデルを設計するために使用できる「**因果モデル（causal model）**」です。第1章で述べた中立的な分子進化の例のように、完全な科学モデルは、そこから派生した統計モデルよりも多くの情報を含んでいます。そして、この追加情報には因果的含意が含まれています。ほとんどの科学者は、これらの含意を非公式に利用していますが、論理的に推定値が因果関係を識別する時期を実証するために、それらを公式に利用することも可能です。
    *   たとえ完全な因果モデルがなく、どの変数が他の変数に因果的に影響するかを示すヒューリスティックなモデルしかない場合でも、これらの論理ツールを利用できます。本書ではこの戦略を使用し、因果仮説を表現するために「**グラフィカル因果モデル**」を用います。最もシンプルなグラフィカル因果モデルは「有向非巡回グラフ（DAG）」と呼ばれます。DAGはヒューリスティックなものであり、詳細な統計モデルではありません。しかし、DAGが真であると仮定すれば、どの統計モデルが妥当な因果推論を提供できるかを推論することができます。

    *   **Rethinking（再考）: 因果サラダ（Causal salad）**
        因果推論には、統計モデルとは別の因果モデルが必要です。データだけでは不十分であり、すべての哲学がその点では同意しています。最も保守的な反応は、「因果関係」を証明不可能な精神的なものだと宣言することです。少し保守的でないのは、因果関係は厳格な無作為化と実験的制御の条件下でのみ推論できると主張することですが、これは非常に限定的です。多くの科学的問いは実験的に研究することはできません（例えば、人類の進化）。
        しかし、生物学や社会科学の多くの分野で支配的なアプローチは、代わりに「因果サラダ」です。因果サラダとは、様々な「統制（control）」変数を統計モデルに投げ込み、推定値の変化を観察し、因果関係についてのストーリーを語ることを意味します。因果サラダは、「欠落変数のみが因果関係について私たちを誤解させる」という考えに基づいているようです。しかし、**含まれている変数も同様に私たちを交絡させる可能性があります**。因果サラダを混ぜる際、良い予測をするモデルでも因果関係について誤解を招く可能性があります。もしそのモデルを介入計画に用いると、すべてがうまくいかなくなるでしょう。後の章で例が示されます。

#### 1.4. まとめ（Summary）

第1章では、一般的な統計哲学と科学哲学の再考を主張しています。様々なブラックボックスツールの中から帰無仮説を検定するのではなく、自然現象の複数の非帰無モデルを構築し分析することを学ぶべきだと述べています。この目標を支援するために、ベイジアン推論、モデル比較、多階層モデル、グラフィカル因果モデルが導入されました。

---

### 第2章：小さな世界と大きな世界（Small Worlds and Large Worlds）

第2章では、ベイジアン推論の概念的メカニズムが導入されます。ベイジアン推論の推論の目的は事後確率分布であり、事後確率はデータの各推測される原因がデータを生成しうる相対的な方法の数を示します。これらの相対的な plausibility（相性の良さ）は、観測結果に基づいて更新されます。

#### 2.1. 分岐するデータの庭（The garden of forking data）

*   **「小さな世界」と「大きな世界」**: 本書では、モデルの自己完結的な論理世界を「小さな世界」と呼びます。小さな世界の中では、すべての可能性が想定され、純粋な驚き（例えば、ヨーロッパとアジアの間に巨大な大陸が存在するような）はありません。モデルの小さな世界の中では、有利な仮定の下でモデルの論理を検証し、期待通りに機能することを確認することが重要です。ベイジアンモデルは、小さな世界が現実世界を正確に記述していると仮定すれば、利用可能な情報をより良く活用し、より良い意思決定をサポートできるという最適な主張があるため、この点でいくつかの利点があります。
    *   **Rethinking（再考）: 大きな世界における高速で質素な思考（Fast and frugal in the large world）**
        自然界は複雑であり、科学を行おうとすることがそれを思い出させます。しかし、謙虚なダニから勤勉なリス、怠惰なナマケモノまで、あらゆるものが適応的な意思決定を頻繁に行っています。しかし、ほとんどの動物はベイジアンではないと思われます。なぜなら、ベイジアンであることはコストがかかり、良いモデルを持つことに依存しているからです。代わりに、動物は環境（過去または現在）に適応した様々なヒューリスティックスを使用します。これらのヒューリスティックスは適応的な近道を取り、情報収集と処理のコスト（および第6章の過剰適合）を考慮すると、厳密なベイジアン分析を上回る可能性があります。無視すべき情報と注意すべき情報がすでに分かっている場合、完全にベイジアンであることは無駄です。それは良い意思決定を行うのに必要でも十分でもありません。しかし、人間にとって、ベイジアン分析は、関連情報を発見し、それを論理的に処理するための一般的な方法を提供します。それが唯一の方法だとは思わないでください。

*   **「分岐するデータの庭」の比喩**: 本節の目標は、ベイジアン推論を謙虚な出発点から構築し、それについて迷信を持たないことです。ベイジアン推論は、実際には可能性を数え、比較することに過ぎません。**ホルヘ・ルイス・ボルヘス**の短編小説**『分岐する小道の庭（The Garden of Forking Paths）』**を類推として考えてみましょう。物語は、矛盾に満ちた本に出会う男の話です。ほとんどの本では、登場人物がプロットの分岐点に到達し、選択肢の中から決定を下さなければなりません。主人公がある男の家に着き、その男を殺すか、あるいは一杯の紅茶を飲むかという選択肢があったとします。これらの道のうち1つだけが取られますが、ボルヘスの物語の中の本は、各決定が外側に広がる「分岐する小道の庭」へと枝分かれしていくすべての道を探索します。
    これこそがベイジアン推論が提供する装置です。実際に何が起こったのかについて良い推論を行うためには、起こりうるすべてを考慮することが役立ちます。ベイジアン分析は「**分岐するデータの庭（garden of forking data）**」であり、そこでは代替のイベントシーケンスが育てられます。何が起こったのかを学ぶにつれて、これらの代替シーケンスの一部は剪定されます。最終的に残るのは、私たちの知識と論理的に矛盾しないものだけです。

*   **可能性を数える**: このアプローチは、与えられた仮定とデータに基づいて、仮説を定量的にランク付けします。これは「最大限に保守的」なランク付けです。このアプローチは、大きな世界においては正しい答えを保証できません。しかし、小さな世界においては、与えられた情報から導き出される最善の答えを保証できます。
    *   例として、4つのビー玉が入った袋を考えます（青と白）。何色ずつあるかは不明ですが、5つの可能性（0青4白、1青3白、2青2白、3青1白、4青0白）があることを知っています。これらを「**conjectures（推測）**」と呼びます。
    *   そこからビー玉を3回取り出し、「青、白、青」というデータ（W, L, W）を得たとします。各推測について、このデータが得られる経路の数を数えます。例えば、[青青青青]の袋からは0通り、[青青青白]の袋からは3通り、[青青白白]の袋からは8通り、[青白白白]の袋からは9通り、[白白白白]の袋からは0通りとなります。このように、**各推測がデータを作り出す方法の数は、庭の各「輪」での経路の数を数え、それらを掛け合わせることで計算できます**。これは計算上の便宜に過ぎず、論理的に可能な経路の数を数えているという事実は変わりません。この点は、ベイジアン推論のより形式的な表現に出会うときにも再び出てきます。

    *   **Rethinking（再考）: 正当化（Justification）**
        「分岐するデータの庭」における経路の数を相対的な相性の良さの尺度として使用することは、いくつかの方法で正当化できます。ここで述べた正当化は論理的なものです。「相性の良さ」について推論し、通常の論理（真偽についての記述）と整合性を保ちたいのであれば、この手順に従うべきです。同じ数学的手順につながる他のいくつかの正当化もあります。どのように哲学的に正当化するかに関わらず、それが実際に機能することに注目してください。正当化と哲学は手順を動機付けますが、結果が重要です。ベイジアン推論の多くの成功した実世界での応用は、必要なすべての正当化かもしれません。20世紀のベイジアン・データ分析の反対者は、ベイジアン推論は正当化しやすいが、適用が難しいと主張しました。幸いにも、それはもはや真実ではありません。実際には、逆がしばしば真であり、科学者はベイジアンアプローチに切り替えています。なぜなら、それによって望むモデルを使用できるからです。

*   **他の情報の結合**: 各推測の相対的な相性の良さについて、追加情報があるかもしれません。この情報は、袋の中身がどのように生成されたかという知識から生じることもあれば、以前のデータから生じることもあります。情報源が何であれ、異なる情報源を結合して相性の良さを更新する方法を持つことは役立ちます。幸いなことに、自然な解決策があります。それは、数を掛け合わせることです。
    *   **「事前（prior）カウント」**: 各推測が最初から等しくもっともらしいと仮定すると、各推測が観測データとどのくらい一致しているかの数を比較します。これらは「事前（prior）」とラベル付けされます。新しい観測（例えば、もう一つビー玉を取り出し「白」だった）が得られた場合、以前のカウントを新しい観測に基づいて更新できます。この2つの方法は、新しい観測が以前の観測と論理的に独立している限り、数学的に同一であることが判明しています。

    *   **Rethinking（再考）: 最初の無知（Original ignorance）**
        推測について以前の情報がない場合、どの仮定を使用すべきでしょうか？最も一般的な解決策は、データを観察する前に、各推測が正しい可能性のある数を等しく割り当てることです。これは「無差別原理（principle of indifference）」として知られることがあります。**本書は「無知（ignorance）」事前分布を使用せず、推奨もしていません**。後の章で見るように、モデルの構造と科学的文脈は常に、無知よりも優れた情報を提供するでしょう。

*   **カウントから確率へ**: この戦略は「誠実な無知（honest ignorance）」の原則に従うものと考えることができます。データが何によって引き起こされたか分からない場合、より多くの方法でデータを生成できる可能性のある原因が、より相性が良い（plausible）ということです。これは「分岐するデータの庭」の経路を数えることにつながります。
    しかし、これらの生のカウントを扱うのは難しいため、通常はそれらを確率に変換する形で標準化します。生のカウントが扱いにくいのは、相対的な値のみが重要であり、絶対的な大きさは意味がないためです。また、データの量が増えるにつれて、カウントは非常に急速に大きくなり、操作が困難になります。10個のデータポイントがある時点で、すでに100万を超える可能なシーケンスがあり、数千の観測値を持つデータセットを分析したい場合、明示的にこれらを数えるのは実用的ではありません。

#### 2.2. モデル構築（Building a model）

*   **ベイジアン統計モデルの定型化**: 生のカウントではなく確率を扱うことで、ベイジアン推論ははるかに簡単になりますが、見た目はより難しくなります。本節では、「分岐するデータの庭」を補完する形で、ベイジアン統計モデルの一般的な形式を提示します。ここで使用するおもちゃの例は、典型的な統計分析の構造を持っています。しかし、その各部分は「分岐するデータの庭」にマッピングでき、論理は同じです。
*   **地球儀投げの例**: 地球儀を投げて、右人差し指の下にある面が水か陸かを記録するという例を用います。この戦略は、地球儀からの表面サンプルのシーケンスを生成します。データ物語は形式的な確率モデルに翻訳されます。この確率モデルは、構築プロセスを連続する構成要素の決定に分解できるため、簡単に構築できます。
    *   **Rethinking（再考）: 物語の価値（The value of storytelling）**
        データ物語は価値があります。たとえそれをすぐに放棄し、モデルを構築したり新しい観測をシミュレートしたりするために使わなかったとしてもです。実際、異なる多くの物語が同じモデルに対応するため、最終的には物語を捨てることの重要性が示唆されています。結果として、モデルがうまく機能することを示しても、それがデータ物語を一意に支持するわけではありません。それでも、物語には価値があります。なぜなら、物語を概説しようとすると、追加の質問に答える必要があることに気づくことが多いためです。ほとんどのデータ物語は、データ収集を促す口頭の仮説よりもはるかに具体的です。仮説は「暖かい日には雨が降りやすい」のように曖昧な場合があります。サンプリングと測定を考慮し、温度が雨をどのように予測するかを正確に記述することを強制されると、多くの物語と結果として生じるモデルが同じ曖昧な仮説と矛盾しなくなります。この曖昧さを解消することは、モデルがデータに適合する前であっても、重要な認識やモデルの改訂につながることがよくあります。

*   **初期相性の良さの更新**: 例のために、ベイジアン機械が当初、水のすべての比率、つまり**p**のすべての値に同じ相性の良さを割り当てると仮定します。図2.5の左上プロットの点線は、このpの各可能な値の初期相性の良さを表しています。最初の試投が「W（水）」であった後、モデルは相性の良さを実線に更新します。p=0の相性の良さは正確にゼロに落ちました。なぜなら、地球儀に少なくとも一滴の水があったことが観測されたため、水があることがわかったからです。モデルはこの論理を自動的に実行します。確率論は、本質的に「分岐するデータの庭」の経路を数えているため、これを処理します。

    *   **Rethinking（再考）: 標本サイズと信頼できる推論（Sample size and reliable inference）**
        統計的推定に有用な最小観測数があるということがよく言われます。例えば、ガウス分布を使用する前に30の観測値が必要であるという広く普及した迷信があります。なぜでしょうか？非ベイジアン統計的推論では、手続きはしばしば非常に大きな標本サイズでの方法の振る舞い、いわゆる漸近的振る舞いによって正当化されます。結果として、小さな標本サイズでのパフォーマンスは疑問視されます。
        対照的に、**ベイジアン推定は任意の標本サイズで有効です**。これは、より多くのデータが役に立たないという意味ではありません。確かに役に立ちます。むしろ、推定値は標本サイズに関係なく、明確で有効な解釈を持ちます。しかし、この力の代償は、初期の相性の良さ、つまり「**事前分布（prior）**」への依存です。事前分布が悪ければ、結果として得られる推論は誤解を招くものとなるでしょう。世界について学ぶ上で、「ただ乗り（no free lunch）」はありません。ベイジアンのゴーレムは初期の相性の良さを選択しなければならず、非ベイジアンのゴーレムは推定量を選択しなければなりません。どちらのゴーレムも、その仮定をもって「昼食代」を払います。

*   **評価**: ベイジアンモデルは、現実の「大きな世界」がモデルによって正確に記述されている限り、最適であると実証された方法で学習します。これは、ベイジアン機械が「小さな世界」内で完璧な推論を保証することを意味します。利用可能な情報を使い、同じ情報状態から始める他の方法は、より良く行うことはできません。
    *   しかし、この論理的な利点に興奮しすぎるべきではありません。計算が誤作動する可能性があり、結果は常に確認される必要があります。また、モデルと現実の間に重要な違いがある場合、大きな世界のパフォーマンスに論理的な保証はありません。たとえ両方の世界が一致しても、特定のデータサンプルが誤解を招く可能性は依然としてあります。したがって、少なくとも2つの慎重な原則を念頭に置く価値があります。
        1.  **モデルの確信度は、モデルが良いものであることを保証しない**。データの量が増えるにつれて、地球儀投げモデルは水の割合についてますます確信を持つようになります。これは、図2.5の曲線がますます狭く高くなり、もっともらしい値を非常に狭い範囲に制限することを意味します。しかし、ベイジアンであろうとなかろうと、あらゆる種類のモデルは、モデルが深刻に誤解を招く場合でも、推論について非常に確信を持つことができます。これは、推論がモデルに条件付けられているためです。あなたのモデルが言っているのは、「この特定のモデルにコミットしている限り、もっともらしい値が狭い範囲にあることを非常に確信できる」ということです。異なるモデルの下では、状況は異なって見えるかもしれません。
        2.  **モデルの作業を監督し、批判することの重要性**。前節での更新が、データの到着順序に関係なく機能するという事実を再考します。観測順序をシャッフルしても、6つのWと3つのLが残っていれば、最終的な相性の良さの曲線は同じになります。しかし、これはモデルが推論にとって順序が関係ないと仮定している場合にのみ真実です。機械にとって関係ないことは、推論に直接影響しません。しかし、データが順序に依存するため、間接的に影響する可能性があります。したがって、モデルが知らないデータの側面を考慮して、モデルの推論をチェックすることが重要です。そのようなチェックは本質的に創造的な事業であり、分析者と科学コミュニティに委ねられています。ゴーレムはそれが非常に苦手です。

*   **モデルの真偽ではなく、適切性**: 第3章で、そのようなチェックのいくつかの例を見ることができます。今のところ、目標はモデルの仮定の「真偽」をテストすることではないことに注意してください。モデルの仮定が真のデータ生成プロセスと一致するという意味で、決して正確に正しいわけではないことを私たちは知っています。したがって、モデルが真実であるかどうかをチェックする意味はありません。モデルが偽でないと結論付けるのは、私たちの想像力の失敗であり、モデルの成功ではありません。さらに、モデルは、非常に正確で有用な推論を生成するために、正確に真実である必要はありません。誤差分布などに関する「小さな世界」のあらゆる種類の仮定は「大きな世界」で破られる可能性がありますが、モデルは依然として完全に有用な推定値を生成する可能性があります。これは、モデルが本質的に情報処理機械であるためであり、情報には、問題を仮定の真偽の観点から捉えることで簡単には捉えられない驚くべき側面があります。
    *   代わりに、目的は、特定の目的のためにモデルが適切であるかをチェックすることです。これは通常、モデルを最初に構築した質問を超えて、追加の質問を問い、答えることを意味します。質問と答えはどちらも科学的文脈に依存します。そのため、一般的なアドバイスを提供することは困難です。本書全体を通して多くの例が示され、もちろん科学文献には、予測、理解、測定、説得など、異なる仕事に対するモデルの適合性の評価が豊富にあります。

    *   **Rethinking（再考）: デフレーション統計（Deflationary statistics）**
        ベイジアン推論は、既知の最も優れた汎用推論方法かもしれません。しかし、ベイジアン推論は、私たちが望むよりもはるかに強力ではありません。普遍的な保証を提供する推論アプローチは存在しません。応用数学のいかなる分野も、現実に制約なくアクセスできるわけではありません。なぜなら、数学はプロトン（陽子）のように「発見」されるものではなく、ショベルのように「発明」されるものだからです。

#### 2.3. モデルの構成要素（Components of the model）

*   **尤度（Likelihood）**: 「dbinom」の「d」は「density」を表します。このように命名された関数は、ほとんど常に「r」（random samples）や「p」（cumulative probabilities）で始まる対応する関数を持ちます。
    *   **Overthinking（深掘り）: 名前と確率分布（Names and probability distributions）**
        「dbinom」の「d」は密度（density）を意味します。この方式で命名された関数は、ほとんど常に「r」で始まる（ランダムサンプル用）関数と、「p」で始まる（累積確率用）関数を持っています。

    *   **Rethinking（再考）: 尤度（likelihood）の中心的役割（A central role for likelihood）**
        ベイジアンデータ分析と非ベイジアンデータ分析がどのように異なるかについて多くの議論がなされてきました。違いに焦点を当てることは有用ですが、時には根本的な類似点から注意をそらしてしまいます。特に、ベイジアンモデルと多くの非ベイジアンモデルの両方で最も影響力のある仮定は、データに割り当てられる分布、つまり「尤度関数（likelihood functions）」です。尤度はデータの各部分に推論に影響を与え、標本サイズが増加するにつれて、尤度はますます重要になります。これが、ベイジアン推論と非ベイジアン推論がしばしば非常に似ている理由を説明するのに役立ちます。もし「ベイジアン」をその一つの側面だけで定義しなければならないとしたら、事前分布ではなく、尤度を記述すべきです。

*   **事前分布（Priors）**: ベイジアン推論には、分析者の「信念」に基づいて事前分布を選択することを重視する学派もあります。このような「主観的ベイジアン」アプローチは一部の統計学、哲学、経済学のプログラムで盛んですが、科学では稀です。自然科学や社会科学におけるベイジアンデータ分析では、事前分布はモデルの一部と見なされ、モデルの他のすべての構成要素と同様に、選択、評価、修正されるべきです。実際には、主観主義者と非主観主義者は、ほとんど同じ方法でデータを分析することが多いでしょう。
    *   これらは、いかなる統計分析も本質的に主観的ではないという意味ではありません。もちろん、科学のあらゆる部分で多くの小さな主観的決定が関わっています。しかし、事前分布とベイジアンデータ分析は、尤度や有意性検定に必要な繰り返しサンプリングの仮定よりも本質的に主観的であるわけではありません。大学の統計ヘルプデスクを訪れたことのある人なら誰でも、この主観性を経験したことがあるでしょう。統計家は、最も単純な問題以外は、一般的にどのように分析するかについて厳密に同意しません。統計的推論が数学を使用するという事実は、分析を行う唯一の合理的または有用な方法があることを意味しません。工学も数学を使用しますが、橋を建設する方法はたくさんあります。

#### 2.4. モデルを動かす（Making the model go）

*   **Overthinking（深掘り）: 事前分布、事前分布は火を噴く（Prior, prior pants on fire）**
    歴史的に、ベイジアン推論の反対者の中には、事前分布の恣意性に異議を唱える人もいました。事前分布が非常に柔軟で、様々な情報状態を符号化できることは事実です。もし事前分布が何でもありなら、好きな答えを得られるのではないか？確かに可能です。それにもかかわらず、何百年にもわたるベイジアン計算の歴史において、人々が事前分布を使って嘘をつくことはありませんでした。もし統計で嘘をつくことが目的なら、そのような嘘は簡単に見破られるため、事前分布を使うのは愚かでしょう。尤度というより不透明な仕組みを使う方が良いです。あるいは、このアドバイスには従わない方が良いですが、データを加工したり、「外れ値」を削除したり、その他の意図的なデータ変換を行ったりする方が良いでしょう。

*   **ベイズの定理**: 「分岐するデータの庭」における各経路の総数は、事前の経路の数と新しい経路の数の積です。乗算は単なる圧縮されたカウントです。分母の平均確率は、カウントを合計して1になるように標準化しているだけです。したがって、ベイズの定理は複雑に見えますが、経路を数えることとの関係が不明瞭になっているだけで、論理が要求するカウントを表現しているにすぎません。
    *   **Rethinking（再考）: ベイジアンデータ分析はベイズの定理についてではない（Bayesian data analysis isn’t about Bayes’ theorem）**
        ベイジアンデータ分析、ひいてはベイジアン推論全般について、「ベイズの定理を使うことによって区別される」という共通の認識がありますが、これは間違いです。いかなる確率概念の下での推論も、最終的にはベイズの定理を使用することになります。「ベイジアン」分析の一般的な入門例（HIV検査やDNA検査など）は、独自にベイジアン的ではありません。計算の要素がすべて事象の頻度であるため、非ベイジアン分析でも全く同じことを行います。むしろ、ベイジアンアプローチは、パラメータやモデルのように、観測できない理論的実体に関する不確実性を定量化するために、より一般的にベイズの定理を使用できます。ベイジアンと非ベイジアンのどちらの確率概念の下でも強力な推論が生成されますが、異なる正当化と犠牲が必要です。

*   **モデルの適合方法**:
    *   **Rethinking（再考）: モデルをどのように適合させるかはモデルの一部である（How you fit the model is part of the model）**
        本章の冒頭で、モデルを事前分布と尤度の複合体として暗黙的に定義しました。この定義は典型的です。しかし、実際には、モデルをデータにどのように適合させるかもモデルの一部と考えるべきです。本章で扱っている地球儀投げの例のような非常に単純な問題では、事後分布の計算は自明で確実です。しかし、中程度に複雑な問題でさえ、モデルをデータに適合させる詳細なプロセスは、私たちの数値的手法が推論に影響を与えることを認識させます。これは、異なる手法で異なる間違いや妥協が生じるためです。同じモデルを同じデータに異なる手法で適合させると、異なる答えが生成される可能性があります。何かがうまくいかない場合、機械のあらゆる部分が疑わしい可能性があります。そして、私たちのゴーレムは更新エンジンを携えており、私たちがプログラムする事前分布や尤度と同様に、彼らの工学の奴隷なのです。

*   **近似手法**:
    *   **二次近似（Quadratic approximation）**: 地球儀投げの事後分布については、本章と次章ではグリッド近似に固執します。しかし、間もなく、より強い仮定をする別の近似に頼らざるを得なくなります。その理由は、モデルのパラメータ数が増えるにつれて、グリッドで考慮するユニークな値の数が急速に増加するためです。単一パラメータの地球儀投げモデルでは、100個または1000個の値のグリッドを計算しても問題ありません。しかし、2つのパラメータをそれぞれ100個の値で近似すると、すでに100^2 = 10000個の値の計算が必要です。10個のパラメータの場合、グリッドは数十億の値になります。今日では、数百または数千のパラメータを持つモデルが日常的にあります。グリッド近似戦略は、モデルの複雑さに対して非常にうまくスケールしないため、あまり遠くまで私たちを連れて行くことはできません。
        ベイジアン文脈で二次近似を使用すると、同じ懸念がすべて伴います。しかし、疑問がある場合は、二次近似以外のアルゴリズムに頼ることができます。実際、グリッド近似は小さな標本で非常にうまく機能します。なぜなら、そのような場合、モデルは単純でなければならず、計算は非常に高速だからです。

        *   **Rethinking（再考）: 最尤推定（Maximum likelihood estimation）**
            二次近似は、一様事前分布または大量のデータがある場合、最尤推定（MLE）とその標準誤差と等価であることがよくあります。MLEは非常に一般的な非ベイジアンのパラメータ推定値です。ベイジアン近似と一般的な非ベイジアン推定量とのこの対応関係は、祝福でもあり呪いでもあります。それは祝福です。なぜなら、幅広い公開されている非ベイジアンモデル適合をベイジアン的な観点から再解釈できるからです。それは呪いです。なぜなら、最尤推定にはいくつかの奇妙な欠点があり、二次近似もそれらを共有する可能性があるからです。これについては後の章で詳しく検討します。

    *   **マルコフ連鎖モンテカルロ（Markov chain Monte Carlo, MCMC）**: 多階層モデルのような重要なモデルタイプには、グリッド近似も二次近似も常に満足のいくものではありません。このようなモデルには、数百、数千、あるいは数万のパラメータが含まれることがあります。グリッド近似は、単純に時間がかかりすぎるため、通常は失敗します。特殊な形式の二次近似は、すべてが適切であれば機能するかもしれませんが、一般的にはそうではありません。さらに、多階層モデルでは、事後分布の単一の統一関数を記述することが常に可能とは限りません。これは、最大化する関数（MAPを見つける際）が不明であり、部分的に計算しなければならないことを意味します。
        結果として、様々な直感に反するモデル適合技術が登場しました。最も一般的なのは「マルコフ連鎖モンテカルロ（MCMC）」であり、これは非常に複雑なモデルを処理できる条件付けエンジンのファミリーです。MCMCは1990年代に始まったベイジアンデータ分析の台頭の大部分を担っていると言っても過言ではありません。MCMCは1990年代以前から存在しますが、手頃なコンピューターの力はそうではないため、エンジニアにも感謝しなければなりません。

        MCMCの概念的な課題は、その非常に非自明な戦略にあります。MCMC技術は、事後分布を直接計算または近似しようとするのではなく、単に事後分布からサンプルを抽出するだけです。最終的にはパラメータ値のコレクションが得られ、これらの値の頻度が事後 plausibility に対応します。これらのサンプルのヒストグラムから、事後分布の全体像を構築することができます。
        私たちは、これらのサンプルから直接作業することがほとんどであり、それらから何らかの数学的推定値を最初に構築することはありません。そして、これらのサンプルは、多くの点で事後分布そのものを持つよりも便利です。なぜなら、それらを使って考える方が簡単だからです。

#### 2.5. まとめ（Summary）

本章では、ベイジアン・データ分析の概念的メカニズムを導入しました。ベイジアン推論における推論の目標は**事後確率分布**です。事後確率は、データの各推測される原因がデータを生成しうる相対的な方法の数を示します。これらの相対的な**相性の良さ（plausibility）**は、観測結果に基づいて更新されます。このプロセスは「ベイジアン更新（Bayesian updating）」として知られています。

---

この詳細な説明で、第1章と第2章の「Rethinking」および「Overthinking」コラムの全内容が網羅されているかと思います。